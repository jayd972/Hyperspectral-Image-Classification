{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931e5f07",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This Jupyter notebook implements a Multilayer Perceptron (MLP) model for hyperspectral image classification. It consists of the following main sections:\n",
    "\n",
    "1. **Library Imports and Setup**  \n",
    "   The notebook begins by importing essential libraries such as PyTorch, NumPy, Matplotlib, and scikit-learn metrics. It also sets up reproducible results by fixing random seeds, and ensures output directories are created for storing artifacts, figures, and run logs.\n",
    "\n",
    "2. **Data Loading**  \n",
    "   The notebook loads the normalized hyperspectral data cube, label maps, train/validation/test masks, and scaling parameters saved from previous preprocessing steps. Basic information about the data shape is printed for verification.\n",
    "\n",
    "3. **Custom Dataset Definition**  \n",
    "   A custom PyTorch Dataset class is defined that returns individual pixel spectra and their corresponding labels to support per-pixel classification tasks needed for spectral models like MLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4777910d-7077-41d9-a3c1-340ce1a9638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "# This cell imports all needed libraries and creates folders to store figures and runs\n",
    "from pathlib import Path                                                                                          # import Path for file paths\n",
    "import json                                                                                                       # import json to read config if needed\n",
    "import pickle                                                                                                     # import pickle to load scaler saved earlier\n",
    "import time                                                                                                       # import time to measure training duration\n",
    "import numpy as np                                                                                                # import numpy for arrays\n",
    "import matplotlib.pyplot as plt                                                                                   # import matplotlib for simple plots\n",
    "\n",
    "import torch                                                                                                      # import torch for deep learning\n",
    "import torch.nn as nn                                                                                             # import torch neural network modules\n",
    "import torch.optim as optim                                                                                       # import optimizers\n",
    "from torch.utils.data import Dataset, DataLoader                                                                  # import dataset and dataloader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, cohen_kappa_score  # import metrics\n",
    "\n",
    "np.random.seed(42)                                                                                                # fix numpy seed for reproducibility\n",
    "torch.manual_seed(42)                                                                                             # fix torch seed for reproducibility\n",
    "\n",
    "ARTIFACTS = Path(\"outputs/artifacts_ip\")                                                                          # set path where notebook one saved arrays and masks\n",
    "FIGS = Path(\"outputs/figs\")                                                                                       # set path to save plots\n",
    "RUNS = Path(\"outputs/runs_mlp\")                                                                                   # set path to save run logs and checkpoints\n",
    "FIGS.mkdir(parents=True, exist_ok=True)                                                                           # create figs folder if missing\n",
    "RUNS.mkdir(parents=True, exist_ok=True)                                                                           # create runs folder if missing\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")                                             # choose gpu if available else cpu\n",
    "print(\"Device\", DEVICE)                                                                                           # show device choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2cb574-90c6-4f52-b094-6a17a0e3576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube (145, 145, 200) Labels (145, 145)\n"
     ]
    }
   ],
   "source": [
    "# This cell loads the normalized cube labels masks and scaler that we saved in the first notebook\n",
    "cube = np.load(ARTIFACTS / \"cube_clean_norm.npy\")           # load normalized cube saved earlier\n",
    "labels = np.load(ARTIFACTS / \"labels.npy\")                  # load label map saved earlier\n",
    "mask_train = np.load(ARTIFACTS / \"mask_train.npy\")          # load train mask\n",
    "mask_val = np.load(ARTIFACTS / \"mask_val.npy\")              # load val mask\n",
    "mask_test = np.load(ARTIFACTS / \"mask_test.npy\")            # load test mask\n",
    "with open(ARTIFACTS / \"scaler.pkl\", \"rb\") as f:             # open scaler file\n",
    "    scaler = pickle.load(f)                                 # load mean and std for reference\n",
    "H, W, B = cube.shape                                        # store spatial and band dims\n",
    "print(\"Cube\", cube.shape, \"Labels\", labels.shape)           # quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c543fee-61d3-45da-a9a3-4c27184ea341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 7686 Val 513 Test 2050 Classes 16\n"
     ]
    }
   ],
   "source": [
    "# This cell builds a dataset that returns one pixel spectrum and its label for spectral models\n",
    "class PixelDataset(Dataset):                                                                     # define dataset class\n",
    "    \"\"\"Returns spectral vector and label for each selected pixel\"\"\"                              # docstring\n",
    "    def __init__(self, cube: np.ndarray, labels: np.ndarray, mask: np.ndarray):                  # init with arrays and a mask\n",
    "        self.X = cube[mask]                                                                      # pick spectra for masked pixels\n",
    "        self.y = labels[mask]                                                                    # pick labels for masked pixels\n",
    "        idx = self.y > 0                                                                         # keep only labeled classes greater than zero\n",
    "        self.X = self.X[idx]                                                                     # filter features to labeled\n",
    "        self.y = self.y[idx].astype(np.int64)                                                    # filter labels to labeled and cast to long\n",
    "    def __len__(self) -> int:                                                                    # return number of items\n",
    "        return self.y.shape[0]                                                                   # length equals number of labeled pixels\n",
    "    def __getitem__(self, i: int):                                                               # get one item\n",
    "        x = self.X[i].astype(np.float32)                                                         # one spectrum as float\n",
    "        y = self.y[i] - 1                                                                        # convert labels from one based to zero based\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)                            # return tensors\n",
    "\n",
    "ds_train = PixelDataset(cube, labels, mask_train)                                                # create train dataset\n",
    "ds_val = PixelDataset(cube, labels, mask_val)                                                    # create val dataset\n",
    "ds_test = PixelDataset(cube, labels, mask_test)                                                  # create test dataset\n",
    "num_classes = int(max(labels.flatten()))                                                         # compute number of classes from labels\n",
    "print(\"Train\", len(ds_train), \"Val\", len(ds_val), \"Test\", len(ds_test), \"Classes\", num_classes)  # summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b78b627-5596-4e84-be5c-6ad0f9826eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches  train 31 val 3 test 9\n"
     ]
    }
   ],
   "source": [
    "# This cell builds data loaders for train val and test without class weights\n",
    "BATCH = 256                                                                       # set batch size\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH, shuffle=True, drop_last=False)  # build train loader with shuffle\n",
    "dl_val = DataLoader(ds_val, batch_size=BATCH, shuffle=False, drop_last=False)     # build val loader without shuffle\n",
    "dl_test = DataLoader(ds_test, batch_size=BATCH, shuffle=False, drop_last=False)   # build test loader without shuffle\n",
    "\n",
    "print(\"Batches  train\", len(dl_train), \"val\", len(dl_val), \"test\", len(dl_test))  # print loader sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db5fcf1-7563-4b2f-aa32-db5985beb695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input bands 200\n",
      "Params 86416\n"
     ]
    }
   ],
   "source": [
    "# This cell defines a small MLP that maps a spectrum to a class id\n",
    "class SpectralMLP(nn.Module):                                                                            # define model class\n",
    "    \"\"\"Two layer MLP for spectral classification\"\"\"                                                      # docstring explains model\n",
    "    def __init__(self, in_dim: int, hidden1: int, hidden2: int, num_classes: int, p_drop: float = 0.3):  # init with sizes\n",
    "        super().__init__()                                                                               # call base class init\n",
    "        self.net = nn.Sequential(                                                                        # create a simple stack of layers\n",
    "            nn.Linear(in_dim, hidden1),                                                                  # dense layer one\n",
    "            nn.ReLU(inplace=True),                                                                       # activation\n",
    "            nn.Dropout(p_drop),                                                                          # dropout for regularization\n",
    "            nn.Linear(hidden1, hidden2),                                                                 # dense layer two\n",
    "            nn.ReLU(inplace=True),                                                                       # activation\n",
    "            nn.Dropout(p_drop),                                                                          # dropout for regularization\n",
    "            nn.Linear(hidden2, num_classes),                                                             # final layer to logits for each class\n",
    "        )                                                                                                # end of layer stack\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:                                                  # define forward pass\n",
    "        return self.net(x)                                                                               # run data through the stack\n",
    "\n",
    "print(\"Input bands\", B)                                                                                  # print input dimension for context\n",
    "model = SpectralMLP(in_dim=B, hidden1=256, hidden2=128, num_classes=num_classes, p_drop=0.3).to(DEVICE)  # create model\n",
    "print(\"Params\", sum(p.numel() for p in model.parameters()))                                              # show parameter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d989da61-8090-4bfb-8202-7c3813b22e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  train_loss 1.8067  val_loss 1.3517  val_acc 0.5029  val_f1 0.2192\n",
      "Epoch 002  train_loss 1.3733  val_loss 1.2057  val_acc 0.5556  val_f1 0.3883\n",
      "Epoch 003  train_loss 1.2372  val_loss 1.0773  val_acc 0.5848  val_f1 0.3901\n",
      "Epoch 004  train_loss 1.1255  val_loss 0.9790  val_acc 0.6316  val_f1 0.4377\n",
      "Epoch 005  train_loss 1.0261  val_loss 0.9098  val_acc 0.6628  val_f1 0.4601\n",
      "Epoch 006  train_loss 0.9461  val_loss 0.8556  val_acc 0.6764  val_f1 0.5011\n",
      "Epoch 007  train_loss 0.9124  val_loss 0.8110  val_acc 0.7018  val_f1 0.5547\n",
      "Epoch 008  train_loss 0.8393  val_loss 0.7044  val_acc 0.7407  val_f1 0.5770\n",
      "Epoch 009  train_loss 0.7742  val_loss 0.6613  val_acc 0.7641  val_f1 0.6810\n",
      "Epoch 010  train_loss 0.7216  val_loss 0.6378  val_acc 0.7680  val_f1 0.6886\n",
      "Epoch 011  train_loss 0.7319  val_loss 0.6071  val_acc 0.7758  val_f1 0.6758\n",
      "Epoch 012  train_loss 0.6815  val_loss 0.5874  val_acc 0.7719  val_f1 0.6862\n",
      "Epoch 013  train_loss 0.6493  val_loss 0.5631  val_acc 0.7836  val_f1 0.6985\n",
      "Epoch 014  train_loss 0.6290  val_loss 0.5373  val_acc 0.7934  val_f1 0.7024\n",
      "Epoch 015  train_loss 0.5997  val_loss 0.5205  val_acc 0.8109  val_f1 0.7659\n",
      "Epoch 016  train_loss 0.5945  val_loss 0.5122  val_acc 0.7934  val_f1 0.7421\n",
      "Epoch 017  train_loss 0.5937  val_loss 0.5195  val_acc 0.7895  val_f1 0.7521\n",
      "Epoch 018  train_loss 0.5987  val_loss 0.5164  val_acc 0.8187  val_f1 0.7729\n",
      "Epoch 019  train_loss 0.6183  val_loss 0.4884  val_acc 0.8090  val_f1 0.7060\n",
      "Epoch 020  train_loss 0.5503  val_loss 0.4750  val_acc 0.8304  val_f1 0.7823\n",
      "Epoch 021  train_loss 0.5435  val_loss 0.4580  val_acc 0.8246  val_f1 0.7751\n",
      "Epoch 022  train_loss 0.5056  val_loss 0.4367  val_acc 0.8246  val_f1 0.7205\n",
      "Epoch 023  train_loss 0.5055  val_loss 0.4506  val_acc 0.8129  val_f1 0.7515\n",
      "Epoch 024  train_loss 0.4827  val_loss 0.4099  val_acc 0.8460  val_f1 0.7501\n",
      "Epoch 025  train_loss 0.4879  val_loss 0.4477  val_acc 0.8265  val_f1 0.7688\n",
      "Epoch 026  train_loss 0.4734  val_loss 0.4187  val_acc 0.8168  val_f1 0.7601\n",
      "Epoch 027  train_loss 0.4505  val_loss 0.3853  val_acc 0.8460  val_f1 0.7876\n",
      "Epoch 028  train_loss 0.4862  val_loss 0.3840  val_acc 0.8558  val_f1 0.8013\n",
      "Epoch 029  train_loss 0.4474  val_loss 0.4126  val_acc 0.8363  val_f1 0.7751\n",
      "Epoch 030  train_loss 0.4672  val_loss 0.3941  val_acc 0.8558  val_f1 0.7920\n",
      "Epoch 031  train_loss 0.4375  val_loss 0.3629  val_acc 0.8635  val_f1 0.7962\n",
      "Epoch 032  train_loss 0.4230  val_loss 0.3535  val_acc 0.8616  val_f1 0.8043\n",
      "Epoch 033  train_loss 0.4100  val_loss 0.4001  val_acc 0.8421  val_f1 0.7813\n",
      "Epoch 034  train_loss 0.4212  val_loss 0.3660  val_acc 0.8616  val_f1 0.8085\n",
      "Epoch 035  train_loss 0.3938  val_loss 0.3613  val_acc 0.8752  val_f1 0.8118\n",
      "Epoch 036  train_loss 0.3888  val_loss 0.3450  val_acc 0.8713  val_f1 0.8094\n",
      "Epoch 037  train_loss 0.4025  val_loss 0.3617  val_acc 0.8655  val_f1 0.8025\n",
      "Epoch 038  train_loss 0.3865  val_loss 0.3313  val_acc 0.8674  val_f1 0.8055\n",
      "Epoch 039  train_loss 0.3587  val_loss 0.3295  val_acc 0.8733  val_f1 0.8138\n",
      "Epoch 040  train_loss 0.3618  val_loss 0.3399  val_acc 0.8655  val_f1 0.8070\n",
      "Epoch 041  train_loss 0.3830  val_loss 0.3246  val_acc 0.8791  val_f1 0.8169\n",
      "Epoch 042  train_loss 0.3553  val_loss 0.3341  val_acc 0.8772  val_f1 0.8907\n",
      "Epoch 043  train_loss 0.3907  val_loss 0.3483  val_acc 0.8635  val_f1 0.8000\n",
      "Epoch 044  train_loss 0.3943  val_loss 0.3245  val_acc 0.8811  val_f1 0.8218\n",
      "Epoch 045  train_loss 0.3979  val_loss 0.5260  val_acc 0.8129  val_f1 0.8242\n",
      "Epoch 046  train_loss 0.4634  val_loss 0.3460  val_acc 0.8635  val_f1 0.7998\n",
      "Epoch 047  train_loss 0.3673  val_loss 0.3188  val_acc 0.8869  val_f1 0.8177\n",
      "Epoch 048  train_loss 0.3531  val_loss 0.3109  val_acc 0.8752  val_f1 0.8775\n",
      "Epoch 049  train_loss 0.3442  val_loss 0.3273  val_acc 0.8752  val_f1 0.8160\n",
      "Epoch 050  train_loss 0.3635  val_loss 0.3144  val_acc 0.8830  val_f1 0.8167\n",
      "Epoch 051  train_loss 0.3749  val_loss 0.3492  val_acc 0.8635  val_f1 0.8033\n",
      "Epoch 052  train_loss 0.3629  val_loss 0.3081  val_acc 0.8850  val_f1 0.8246\n",
      "Epoch 053  train_loss 0.3392  val_loss 0.2949  val_acc 0.8947  val_f1 0.7883\n",
      "Epoch 054  train_loss 0.3259  val_loss 0.3074  val_acc 0.8869  val_f1 0.8895\n",
      "Epoch 055  train_loss 0.3858  val_loss 0.3026  val_acc 0.8811  val_f1 0.7735\n",
      "Epoch 056  train_loss 0.3481  val_loss 0.2816  val_acc 0.8967  val_f1 0.8321\n",
      "Epoch 057  train_loss 0.3145  val_loss 0.2755  val_acc 0.9025  val_f1 0.8343\n",
      "Epoch 058  train_loss 0.3029  val_loss 0.2796  val_acc 0.8889  val_f1 0.8247\n",
      "Epoch 059  train_loss 0.3023  val_loss 0.3015  val_acc 0.8869  val_f1 0.8167\n",
      "Epoch 060  train_loss 0.3043  val_loss 0.2777  val_acc 0.9064  val_f1 0.9047\n",
      "Epoch 061  train_loss 0.3139  val_loss 0.2918  val_acc 0.8967  val_f1 0.8974\n",
      "Epoch 062  train_loss 0.3084  val_loss 0.2762  val_acc 0.8947  val_f1 0.8284\n",
      "Epoch 063  train_loss 0.2715  val_loss 0.2675  val_acc 0.9142  val_f1 0.9060\n",
      "Epoch 064  train_loss 0.2845  val_loss 0.2869  val_acc 0.8791  val_f1 0.8762\n",
      "Epoch 065  train_loss 0.2796  val_loss 0.2625  val_acc 0.9006  val_f1 0.8992\n",
      "Epoch 066  train_loss 0.2600  val_loss 0.2581  val_acc 0.9025  val_f1 0.8990\n",
      "Epoch 067  train_loss 0.2683  val_loss 0.2573  val_acc 0.9045  val_f1 0.8398\n",
      "Epoch 068  train_loss 0.2868  val_loss 0.2642  val_acc 0.8986  val_f1 0.8332\n",
      "Epoch 069  train_loss 0.2723  val_loss 0.2532  val_acc 0.9045  val_f1 0.8994\n",
      "Epoch 070  train_loss 0.2625  val_loss 0.2537  val_acc 0.9025  val_f1 0.9015\n",
      "Epoch 071  train_loss 0.2586  val_loss 0.2564  val_acc 0.9045  val_f1 0.9024\n",
      "Epoch 072  train_loss 0.2584  val_loss 0.2751  val_acc 0.8889  val_f1 0.8918\n",
      "Epoch 073  train_loss 0.2692  val_loss 0.2624  val_acc 0.9006  val_f1 0.8945\n",
      "Epoch 074  train_loss 0.2459  val_loss 0.2515  val_acc 0.9064  val_f1 0.9048\n",
      "Epoch 075  train_loss 0.2455  val_loss 0.2523  val_acc 0.9064  val_f1 0.9026\n",
      "Epoch 076  train_loss 0.2367  val_loss 0.2522  val_acc 0.9045  val_f1 0.9021\n",
      "Epoch 077  train_loss 0.2443  val_loss 0.2559  val_acc 0.9025  val_f1 0.9000\n",
      "Epoch 078  train_loss 0.2433  val_loss 0.2500  val_acc 0.9064  val_f1 0.9016\n",
      "Epoch 079  train_loss 0.2491  val_loss 0.2532  val_acc 0.9045  val_f1 0.9018\n",
      "Epoch 080  train_loss 0.2420  val_loss 0.2441  val_acc 0.9025  val_f1 0.9045\n",
      "Epoch 081  train_loss 0.2361  val_loss 0.2537  val_acc 0.9025  val_f1 0.8986\n",
      "Epoch 082  train_loss 0.2381  val_loss 0.2448  val_acc 0.9084  val_f1 0.9044\n",
      "Epoch 083  train_loss 0.2352  val_loss 0.2435  val_acc 0.9045  val_f1 0.9005\n",
      "Epoch 084  train_loss 0.2351  val_loss 0.2417  val_acc 0.9103  val_f1 0.9059\n",
      "Epoch 085  train_loss 0.2303  val_loss 0.2470  val_acc 0.9045  val_f1 0.9009\n",
      "Epoch 086  train_loss 0.2357  val_loss 0.2575  val_acc 0.8967  val_f1 0.8973\n",
      "Epoch 087  train_loss 0.2693  val_loss 0.2732  val_acc 0.8928  val_f1 0.8969\n",
      "Epoch 088  train_loss 0.2390  val_loss 0.2517  val_acc 0.8986  val_f1 0.8982\n",
      "Epoch 089  train_loss 0.2363  val_loss 0.2472  val_acc 0.9045  val_f1 0.9022\n",
      "Epoch 090  train_loss 0.2376  val_loss 0.2455  val_acc 0.9084  val_f1 0.9054\n",
      "Epoch 091  train_loss 0.2310  val_loss 0.2453  val_acc 0.9045  val_f1 0.8366\n",
      "Epoch 092  train_loss 0.2246  val_loss 0.2441  val_acc 0.9103  val_f1 0.9052\n",
      "Epoch 093  train_loss 0.2247  val_loss 0.2424  val_acc 0.9103  val_f1 0.9070\n",
      "Epoch 094  train_loss 0.2233  val_loss 0.2435  val_acc 0.9084  val_f1 0.9041\n",
      "Early stop at epoch 94 best epoch 84\n",
      "Train time seconds 32.71\n"
     ]
    }
   ],
   "source": [
    "                                                                                                                                                         # This cell sets up loss optimizer scheduler metrics and the training loop for one plain run\n",
    "criterion = nn.CrossEntropyLoss()                                                                                                                        # use plain cross entropy without class weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)                                                                                   # create adam optimizer\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True)                                            # reduce lr on plateau\n",
    "\n",
    "def metrics_from_logits(logits: torch.Tensor, targets: torch.Tensor, num_classes: int) -> dict:                                                          # define metrics helper\n",
    "    \"\"\"Compute accuracy precision recall f1 kappa and confusion matrix on cpu arrays\"\"\"                                                                  # docstring explains function\n",
    "    preds = logits.argmax(dim=1).cpu().numpy()                                                                                                           # predicted class ids\n",
    "    true = targets.cpu().numpy()                                                                                                                         # true class ids\n",
    "    acc = accuracy_score(true, preds)                                                                                                                    # accuracy\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true, preds, labels=np.arange(num_classes), average=\"macro\", zero_division=0)                     # macro metrics\n",
    "    kap = cohen_kappa_score(true, preds)                                                                                                                 # kappa\n",
    "    cm = confusion_matrix(true, preds, labels=np.arange(num_classes))                                                                                    # confusion matrix\n",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"kappa\": kap, \"cm\": cm}                                                                      # pack results\n",
    "\n",
    "EPOCHS = 100                                                                                                                                             # max epochs\n",
    "PATIENCE = 10                                                                                                                                            # early stopping patience\n",
    "best_val_loss = float(\"inf\")                                                                                                                             # best validation loss so far\n",
    "best_state = None                                                                                                                                        # best model weights\n",
    "history = []                                                                                                                                             # log per epoch\n",
    "bad_epochs = 0                                                                                                                                           # counter for early stop\n",
    "start_time = time.time()                                                                                                                                 # timer start\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):                                                                                                                       # loop epochs\n",
    "    model.train()                                                                                                                                        # train mode\n",
    "    train_loss_sum = 0.0                                                                                                                                 # sum loss\n",
    "    train_count = 0                                                                                                                                      # count samples\n",
    "    for xb, yb in dl_train:                                                                                                                              # loop train batches\n",
    "        xb = xb.to(DEVICE)                                                                                                                               # move features\n",
    "        yb = yb.to(DEVICE)                                                                                                                               # move labels\n",
    "        optimizer.zero_grad(set_to_none=True)                                                                                                            # clear grads\n",
    "        logits = model(xb)                                                                                                                               # forward\n",
    "        loss = criterion(logits, yb)                                                                                                                     # compute loss\n",
    "        loss.backward()                                                                                                                                  # backward\n",
    "        optimizer.step()                                                                                                                                 # update weights\n",
    "        train_loss_sum += loss.item() * xb.size(0)                                                                                                       # add batch loss\n",
    "        train_count += xb.size(0)                                                                                                                        # add batch count\n",
    "    train_loss = train_loss_sum / max(1, train_count)                                                                                                    # average train loss\n",
    "\n",
    "    model.eval()                                                                                                                                         # eval mode\n",
    "    with torch.no_grad():                                                                                                                                # no grads for val\n",
    "        val_logits_list = []                                                                                                                             # store logits\n",
    "        val_targets_list = []                                                                                                                            # store targets\n",
    "        val_loss_sum = 0.0                                                                                                                               # sum val loss\n",
    "        val_count = 0                                                                                                                                    # count val samples\n",
    "        for xb, yb in dl_val:                                                                                                                            # loop val batches\n",
    "            xb = xb.to(DEVICE)                                                                                                                           # move features\n",
    "            yb = yb.to(DEVICE)                                                                                                                           # move labels\n",
    "            logits = model(xb)                                                                                                                           # forward\n",
    "            loss = criterion(logits, yb)                                                                                                                 # compute loss\n",
    "            val_loss_sum += loss.item() * xb.size(0)                                                                                                     # add loss\n",
    "            val_count += xb.size(0)                                                                                                                      # add count\n",
    "            val_logits_list.append(logits)                                                                                                               # keep logits\n",
    "            val_targets_list.append(yb)                                                                                                                  # keep labels\n",
    "        val_loss = val_loss_sum / max(1, val_count)                                                                                                      # average val loss\n",
    "        val_logits = torch.cat(val_logits_list, dim=0)                                                                                                   # concat logits\n",
    "        val_targets = torch.cat(val_targets_list, dim=0)                                                                                                 # concat targets\n",
    "        val_metrics = metrics_from_logits(val_logits, val_targets, num_classes)                                                                          # compute metrics\n",
    "\n",
    "    scheduler.step(val_loss)                                                                                                                             # step scheduler with val loss\n",
    "    history.append({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss, \"val_acc\": val_metrics[\"acc\"], \"val_f1\": val_metrics[\"f1\"]})         # log epoch\n",
    "    print(f\"Epoch {epoch:03d}  train_loss {train_loss:.4f}  val_loss {val_loss:.4f}  val_acc {val_metrics['acc']:.4f}  val_f1 {val_metrics['f1']:.4f}\")  # progress print\n",
    "\n",
    "    if val_loss < best_val_loss:                                                                                                                         # check improvement\n",
    "        best_val_loss = val_loss                                                                                                                         # update best loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}                                                                         # snapshot weights\n",
    "        best_epoch = epoch                                                                                                                               # save epoch\n",
    "        bad_epochs = 0                                                                                                                                   # reset counter\n",
    "    else:                                                                                                                                                # no improvement\n",
    "        bad_epochs += 1                                                                                                                                  # add one bad epoch\n",
    "        if bad_epochs >= PATIENCE:                                                                                                                       # check patience\n",
    "            print(\"Early stop at epoch\", epoch, \"best epoch\", best_epoch)                                                                                # early stop info\n",
    "            break                                                                                                                                        # stop training\n",
    "\n",
    "train_time = time.time() - start_time                                                                                                                    # total time\n",
    "print(\"Train time seconds\", round(train_time, 2))                                                                                                        # print time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b681bb73-466f-4009-84ba-45ecda474dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs/runs_mlp/mlp_plain_best.pth\n",
      "Saved outputs/runs_mlp/mlp_plain_history.csv\n"
     ]
    }
   ],
   "source": [
    "# This cell saves the best checkpoint and the per epoch history to csv\n",
    "ckpt_path = RUNS / \"mlp_plain_best.pth\"                                                         # checkpoint path\n",
    "log_path = RUNS / \"mlp_plain_history.csv\"                                                       # history path\n",
    "\n",
    "if best_state is not None:                                                                      # check snapshot exists\n",
    "    torch.save({\"state_dict\": best_state, \"num_classes\": num_classes, \"in_dim\": B}, ckpt_path)  # save checkpoint\n",
    "\n",
    "import csv                                                                                      # import csv to write history\n",
    "with open(log_path, \"w\", newline=\"\") as f:                                                      # open csv\n",
    "    w = csv.DictWriter(f, fieldnames=[\"epoch\", \"train_loss\", \"val_loss\", \"val_acc\", \"val_f1\"])  # writer\n",
    "    w.writeheader()                                                                             # header\n",
    "    for row in history:                                                                         # rows\n",
    "        w.writerow(row)                                                                         # write\n",
    "\n",
    "print(\"Saved\", ckpt_path.as_posix())                                                            # confirm path\n",
    "print(\"Saved\", log_path.as_posix())                                                             # confirm path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0abf7737-0420-4174-b5f4-4616a08bddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.9103313840155945\n",
      "Val kappa 0.8977923883525422\n",
      "Val precision macro 0.9293670329490444\n",
      "Val recall macro 0.8971590325095261\n",
      "Val f1 macro 0.9059305612824555\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell evaluates the best model on the validation set and prints core metrics and a confusion matrix\n",
    "model.load_state_dict(best_state)                                   # load best weights\n",
    "model.to(DEVICE).eval()                                             # set eval mode\n",
    "with torch.no_grad():                                               # no grads\n",
    "    val_logits_list = []                                            # logits list\n",
    "    val_targets_list = []                                           # targets list\n",
    "    for xb, yb in dl_val:                                           # loop val\n",
    "        xb = xb.to(DEVICE)                                          # move features\n",
    "        yb = yb.to(DEVICE)                                          # move labels\n",
    "        val_logits_list.append(model(xb))                           # forward\n",
    "        val_targets_list.append(yb)                                 # store labels\n",
    "    val_logits = torch.cat(val_logits_list, dim=0)                  # stack logits\n",
    "    val_targets = torch.cat(val_targets_list, dim=0)                # stack targets\n",
    "    vm = metrics_from_logits(val_logits, val_targets, num_classes)  # compute metrics\n",
    "\n",
    "print(\"Val accuracy\", vm[\"acc\"])                                    # print accuracy\n",
    "print(\"Val kappa\", vm[\"kappa\"])                                     # print kappa\n",
    "print(\"Val precision macro\", vm[\"prec\"])                            # print precision\n",
    "print(\"Val recall macro\", vm[\"rec\"])                                # print recall\n",
    "print(\"Val f1 macro\", vm[\"f1\"])                                     # print f1\n",
    "\n",
    "cm = vm[\"cm\"]                                                       # confusion matrix\n",
    "plt.figure(figsize=(6, 5))                                          # figure\n",
    "plt.imshow(cm, cmap=\"Blues\")                                        # plot\n",
    "plt.title(\"Confusion matrix val plain MLP\")                         # title\n",
    "plt.xlabel(\"Predicted\")                                             # x label\n",
    "plt.ylabel(\"True\")                                                  # y label\n",
    "plt.colorbar()                                                      # color bar\n",
    "plt.tight_layout()                                                  # layout\n",
    "plt.savefig(FIGS / \"mlp_plain_confusion_val.png\", dpi=150)          # save figure\n",
    "plt.show()                                                          # show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa0e8e9-323a-4643-a8b4-a49c09e2c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.9219512195121952\n",
      "Test kappa 0.9111719907954684\n",
      "Test precision macro 0.9169264117162963\n",
      "Test recall macro 0.9395694425169847\n",
      "Test f1 macro 0.9260251741249226\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAH3CAYAAABHKH6HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJMElEQVR4nO3dCXgUVdbw8dMJJKxhlQBDWFRkkVVQRHwVBInIIAiOG0JEBgcGkEURcZRVCaIjCCIgLwKOIC4jLgyCyKoCsokKaBRFibLEjYTlJSzp7zk30/2lQxISqHR33fx/PmXS1dVV1Z0mfXLOubc8Xq/XKwAAAJaICPUJAAAAOIngBgAAWIXgBgAAWIXgBgAAWIXgBgAAWIXgBgAAWIXgBgAAWIXgBgAAWIXgBgAAWIXgBmHt22+/lY4dO0q5cuXE4/HI22+/7ej+f/jhB7Pf+fPnO7pfG9SuXVvuvffeUJ9GWND3h75P9P1SUPoa6msJIHgIbnBO3333nfztb3+Tiy++WEqUKCExMTHSpk0bee655+T//u//CvXYCQkJ8uWXX8qTTz4p//rXv6Rly5aFejwb7d69W8aOHXteH8xO2b9/vzmHHTt2FOpxFi1aJFOnThWbrV271gRaurzyyis5bqP/PvX+Ro0aBazXIOvPf/7zOYMx3/510X/vTZs2lX/+85+Snp7u6HMBCkuxQtszrPCf//xH/vKXv0h0dLT07t3b/LI8efKkfPzxxzJixAjZtWuXvPjii4VybA2cNm7cKP/4xz9k0KBBhXKMWrVqmeMUL15cbA5uxo0bJ23bti1QBiEpKUkiIiIcC270HPT4zZo1k8IMbnbu3ClDhw6VcDFnzhzJyMhwfL/6h4Y+33vuuSdgvQaxGzZsMPefL/33/r//+7/m+8OHD8u///1veeihh2TLli2yePHiCz53oLAR3CBXe/fulTvvvNMEAKtXr5Zq1ar57xs4cKDs2bPHBD+F5ZdffjFfy5cvX2jH0L9ML+RDwDZ6Hd0TJ05IyZIlzQccLlxhBc4333yzvPvuu/Lrr79K5cqV/es14ImNjZW6devKH3/8cV77LlasWEDQ9Pe//11atWolr732mjz77LNSvXp1R54DUFgoSyFXkydPlqNHj8rcuXMDAhufSy+9VIYMGeK/ffr0aZkwYYJccskl5oNR/0p/9NFHz0pl+1Ljmv256qqrTHChJa+XX37Zv42WMDSoUpoh0iDEl3XIrYdBH6PbZbVy5Uq59tprTYBUpkwZqVevnjmnc/XcaDD3P//zP1K6dGnz2K5du8pXX32V4/E0yNNz0u20N6hPnz5y/Pjxc76+mknRTNgXX3wh119/vZQqVcq8pm+++aa5f926deYDRQMNPe8PP/ww4PE//vij+dDR+3SbSpUqmSxb1vKTPi9dp9q1a+cvNWhpI+vPYsWKFabkp/uZPXv2WT03GvTo4y+66CJJSUnx71+zeI0bNzY/82PHjuX4PPVYV155pfleXxvfOWR9zT/99FO56aabzOunr4O+Hp988knAfo4cOWIyMnpe+v6qUqWK3HjjjbJ9+3b/66nBtr4uvmOcK1Ol22hWcOHCheZ11PdiixYtZP369ef8+b3zzjvSuXNn80Gv56Ovgb7/z5w5E7Bd9ver7z33zDPPmKyn79+LvkaaGckvfU/q4954442A9Rrc3H777RIZGSlO0Qyevr6+8wfCHcENcvXee++ZoOOaa67J1/Z//etfZfTo0XLFFVfIlClTzAdUYmKiyf5kpwHBbbfdZj6ctJZfoUIF8yGgZS7VvXt3sw911113mX6bgvZS6L70g1uDq/Hjx5vj3HLLLWd9aGanQUR8fLz5ENcAZvjw4SbNr30MOf1i1w8S/eDV56rf64e2lmDyQ/+y1nPUIEaDSf2w0tdL/0LWr/rX+aRJk0zgoK+XHsdHPwj1vHS7adOmSf/+/WXVqlXmQ8gXXF133XXywAMPmO81qNPXUZcGDRoElJ/0NdafhfZR5VQ20g/jl156yWR19Dg+Y8aMMa/zvHnzTCCYEz2Wvv7q/vvv95+DnpsvkNTv09LSzP4mTpxoSiE33HCDbN682b8fPe7MmTOlR48e8sILL5gyiQZjvqBTy5d67prF8B0jP+8ZDSI1aNJMhZ7nb7/9ZgItLW/lRX/OGjDr+0NfNw2K9P3/yCOPSH5oEPL000+bfrYnnnjCvLf0fX/q1Kl8PV6DQA1wXn31Vf+6zz//3Pw87r77bimM3julQTQQ9rxADlJTU7369ujatWu+tt+xY4fZ/q9//WvA+oceesisX716tX9drVq1zLr169f716WkpHijo6O9Dz74oH/d3r17zXZPP/10wD4TEhLMPrIbM2aM2d5nypQp5vYvv/yS63n7jjFv3jz/umbNmnmrVKni/e233/zrPv/8c29ERIS3d+/eZx3vvvvuC9jnrbfe6q1UqZL3XK6//nrz+EWLFvnXff3112adHmvTpk3+9StWrDjrPI8fP37WPjdu3Gi2e/nll/3r3njjDbNuzZo1Z23v+1ksX748x/v0tc5q9uzZZvtXXnnFnF9kZKR36NCh53yuW7ZsOev8VUZGhrdu3bre+Ph4833W51anTh3vjTfe6F9Xrlw578CBA/M8TufOnXN8b+RGz0mXrVu3+tf9+OOP3hIlSpifo4+et26n75es55jd3/72N2+pUqW8J06cyPX96nvP6Xvk999/969/5513zPr33nsvz3PWn6Nupz/XpUuXej0ej3ffvn3mvhEjRngvvvhi//vr8ssvD3isnoe+RnnR8y1durT5d6PLnj17vBMnTjTHadKkSZ6PBcIFmRvkSP+KVmXLls3X9suWLTNf9a/YrB588EHzNXtvTsOGDU3Zx0fLHVoW+P7778Upvl4dLR/kt6HzwIEDZkSPZpEqVqzoX9+kSROT2fA9z6yyZjKUPi/969/3GuZF//LPmtnS10DPW7Mdms3x8X2f9fXRrIWP/rWvx9Sylj7eV6rJjzp16phMVX5o5kW3HTx4sPTq1cuUVDTTcr70tdbh/ppp0PPX/hFdNFPVvn17Ux7y/ez0eWn5SpuTndS6dWuTdfGpWbOmyYhoqS57iSmrrK+/ZtT0vPVnr1mzr7/++pzHveOOO0zG0sf376Eg/wZ0mgR9n2qTr8Zq+lWzcBdKX3/9N6mLvqc066ev05IlSy5430AwENwgRzr8U2Utg+RF+xy0Lq+/CLOqWrWq+VDS+7PSD5Ds9Bf9+TZA5vbhoaUkLZdpg6UGEa+//nqegY7vPDXIyE4DDt8Hb17PxfeBlZ/nUqNGjbP6hLTvJC4u7qx12fepo7y0DKLbajlLyzH6YaQlndTUVClIcFMQ2oOlH+AalGhpJuuHfEHpPnxD/n0fpr5FR+toSdH3XLRsp6Uifb7aq6UlQyeCYW28ze6yyy4zz9HX1J4TLf/ceuut5mej/170nH1NuPl5/S/kfZO1WVl7qrTEpYFgcnKyIyUp7T3SfjVdfPvVcq6WqQE3YLQUcqS/rLVR8lx9B9ll/6DOTW7NjpmVgvM7Rva/svVDV38xr1mzxmSOli9fbnpZtJfjgw8+cKzh8kKeS26Pzc8+NXuivS7aL6J/VfsmOtQgriBDjwsanGiDsK9JXOcg0mOfL995au9JbkPENbultJ9JsxuaPdCfnz7mqaeekrfeeks6deokwaQBpPaU6b8T7dPRDJYGBJoxGzlyZL5e/wt532SlwcysWbNMsKfz0WhW9ELpuXXo0OGC9wOECsENcqWNrjqaQ+eaOdcHmI5s0l/o+pd41mbVQ4cOmQ8C38gnJ+hfuLrP7LJnh5Rmk7S8oYsOYdUSijaeasCT0y9v33lqk212WmrQ7EhujbPBpqOqNOOhjdI+2vCb/bXJb8CZ37KdBlVaDomKijJNvVqmOtfPN7dz0KBAaZCQnw9THbWnI8R00YZvbV7XCR59wc35PFdf9iirb775xjTsajYmtwBPy2gaWPkao33TJwSbjgbULJCekwZ7AChLIQ8PP/yw+SDXso4GKTmNntBRIkpH9ajso1M0oFA6ZNYp+oGoaX8dQp31Qzd7P8Dvv/9+1mN92YHcZlrVD0/dZsGCBQFBgmawNFvge57hQP+6zv5X/vTp08/KYPmCsZwCwoLq16+fCWK1NKWBr86H0rdv33NmG3I7B+110Z+nDovWaQey85WF9DllL/XoUHDNLmb9WepxClKSUxq8Z+1R0hKM9mlpAHeuzFrW563D4nUUV7BpQKej5XSkmfZBASBzgzzoh47W8rV3RbMxWWco1iHIOr+Gbx4UTYdrFkE/8Hwpex3Gq0FCt27dzBwpTtGyi6b+td9Bhzlrb4QOEdY+iawfUlou0LKUBlaaWdC/9PXDR/tc9K/d3Gi5QzMBmq3SD27tbdGgQcs+mvoPp8yaDnfW89JShH5I6zD27EN1NVjTD2P9q14/+LU/R0tzGhwUhJbAtLynfTb6Gip9XbTPRF9/zabk9V7S3istn2iTugYh2iSt/T7aW6Ov9+WXX27mwfnTn/4kP//8s8muaUZHpyTQ3i89pg6H1/ealqr0uepw+KyZKw2WtPSoje06b4xu16VLlzyfl76nNfuk7yV9bXwBSl7D+XV6BM0g6nteH6cBhv4sClpScoo2QOuSHzoNgw49z6558+aO/hEChFSoh2sh/H3zzTfefv36eWvXru2Nioryli1b1tumTRvv9OnTA4a8njp1yjtu3DgzhLd48eLeuLg476hRowK2yWs4qg5d1eVcQ8HVBx984G3UqJE5n3r16pmhydmHgq9atcoMZa9evbrZTr/edddd5vlkP0b2IcoffviheY4lS5b0xsTEeLt06eLdvXt3wDa+42Ufap7TsOGc5DRUN6/XR/eZdSj0H3/84e3Tp4+3cuXK3jJlypjh1DqUPKch3HPmzDFDhHXodtZh4XkNDc66n+TkZDMUW1+H7HTItA4d/v777/N8vjrUuWHDht5ixYqd9Zp/9tln3u7du5vh0TolgB779ttvNz9DlZ6eboY5N23a1Lz/9Hj6/QsvvBBwjKNHj3rvvvtub/ny5c0xzjUs3Pea6vtHh6TrsZs3b37WsPmcfqaffPKJ9+qrrzbvEX1vPfzww/4h+1kfn9tQ8Jze17pe31f5HQqel9yGgvuGv2df+vbt6z9ffX0BN/Po/0IbXgFAaGjGRS8l8vzzz4f6VAA4iJ4bAABgFYIbAABgFYIbAABgFUZLASiyaDkE7ETmBgAAWIXgBgAAWMX6spTOpqpXEdaJw5ychh4AgPyUPnUSSp1NWy8HU5j08is6yaqT9DIret00t7E+uNHAJvsVlgEACCa9rIdvZu/CCmxKlistcjL/F83Nj6pVq5prprktwLE+uNGMjUrau9v/fWGJjLD+5QQAFMCRtCNyae3LCv3zx2RsNLC5tqpIMYeqFKe9cvDjg2bfBDdhxleK0jeWXqemMBHcAAByErS2iOIRIsUcKn95nM0CBRMNxQAAwCqkGgAAsEWEg2kLF6c/CG4AALCFlr88DpXAXDzC2MVxGQAAwNnI3AAAYBNPqE8g9AhuAACwBWUp95SlZsyYIbVr1zbj7Fu1aiWbN28O9SkBAIAwFfbBzWuvvSbDhw+XMWPGyPbt26Vp06YSHx8vKSkpoT41AADCc7RUhEOLS4X9qT/77LPSr18/6dOnjzRs2FBmzZolpUqVkpdeeinUpwYAAMJQWAc3OuXztm3bpEOHDv51euExvb1x48YcH5Oeni5paWkBCwAARarnxuPQ4lJhHdz8+uuvcubMGYmNjQ1Yr7cPHjyY42MSExOlXLly/oWLZgIAigyPw4tLhXVwcz5GjRolqamp/kWvxAoAAIqOsB4KXrlyZYmMjJRDhw4FrNfbehn2nERHR5sFAIAiJ8KTuTi1L5cK68xNVFSUtGjRQlatWuVfl5GRYW63bt06pOcGAADCU1hnbpQOA09ISJCWLVvKVVddJVOnTpVjx46Z0VMAACALJ3tlPOJaYR/c3HHHHfLLL7/I6NGjTRNxs2bNZPny5Wc1GQMAUOQxQ7E7ghs1aNAgswAAAFgR3AAAgHygLBX+DcUAAAAFReYGAABbMBTcILgBAMAWlKUMylIAAMAqZG4AALAFQ8GLVnATGVHMLIWp+3vBGa7+Vpfng3Icr9cblON4XPwPCM464z0jNon0RIb6FFDU0HNjUJYCAABWKTKZGwAArEdDsUHmBgAAWIXMDQAAVmVuPM7ty6UIbgAAsIkn1CcQepSlAACAVQhuAACwbSh4hEPLBZg0aZKZ6mPo0KH+dSdOnJCBAwdKpUqVpEyZMtKjRw85dOhQwOP27dsnnTt3llKlSkmVKlVkxIgRcvr06YK9DBd05gAAANls2bJFZs+eLU2aNAlYP2zYMHnvvffkjTfekHXr1sn+/fule/fu/vvPnDljApuTJ0/Khg0bZMGCBTJ//nwZPXq0FATBDQAAtg0F9zi0nIejR49Kz549Zc6cOVKhQgX/+tTUVJk7d648++yzcsMNN0iLFi1k3rx5JojZtGmT2eaDDz6Q3bt3yyuvvCLNmjWTTp06yYQJE2TGjBkm4MkvghsAAGy7/ILHoUVE0tLSApb09PQ8T0HLTpp96dChQ8D6bdu2yalTpwLW169fX2rWrCkbN240t/Vr48aNJTY21r9NfHy8Oe6uXbvy/TIQ3AAAgFzFxcVJuXLl/EtiYmKu2y5evFi2b9+e4zYHDx6UqKgoKV++fMB6DWT0Pt82WQMb3/2++/KLoeAAANgiwsG0xX/3k5ycLDExMf7V0dHROW6u2w0ZMkRWrlwpJUqUkFAicwMAgC0KoSwVExMTsOQW3GjZKSUlRa644gopVqyYWbRpeNq0aeZ7zcBo38zhw4cDHqejpapWrWq+16/ZR0/5bvu2yQ+CGwAAcMHat28vX375pezYscO/tGzZ0jQX+74vXry4rFq1yv+YpKQkM/S7devW5rZ+1X1okOSjmSANqho2bJjvc6EsBQCALUJ44cyyZctKo0aNAtaVLl3azGnjW9+3b18ZPny4VKxY0QQsgwcPNgHN1Vdfbe7v2LGjCWJ69eolkydPNn02jz32mGlSzi1jlBOCGwAAEBRTpkyRiIgIM3mfjrrSkVAvvPCC//7IyEhZunSpDBgwwAQ9GhwlJCTI+PHjC3QcghsAAGyRpVfmgjmwn7Vr1wbc1kZjnbNGl9zUqlVLli1bdkHHJbgBAMAWhTBayo1cfOoAAABnI3MDAIAtwqwsFSpkbgAAgFXI3AAAYIsQDgUPJwQ3AADYIsKTuTi1L5eiLAUAAKxC5gYAAFvQUGwQ3DjorS7PB+U4H/60PCjHaVu9Q1COU8zD2xCZIj2RQTnO6YzTQTlOhmQE5TgRHpLwQFZ8qgAAYAsaig2CGwAArOERj0PlJK+LoxtymQAAwCpkbgAAsIRmbTwONhR7xZ0IbgAAsISTg6XEo6Upd6IsBQAArELmBgAAS0Q4WJbyejxBmszAeWRuAACAVcI6uElMTJQrr7xSypYtK1WqVJFu3bpJUlJSqE8LAICwbij2OLS4VVgHN+vWrZOBAwfKpk2bZOXKlXLq1Cnp2LGjHDt2LNSnBgBA2CG4cUHPzfLlgZcZmD9/vsngbNu2Ta677rqQnRcAAAhfYR3cZJeammq+VqxYMdSnAgCA9fPcuJVrgpuMjAwZOnSotGnTRho1apTrdunp6WbxSUtLC9IZAgCAcBDWPTdZae/Nzp07ZfHixedsQi5Xrpx/iYuLC9o5AgAQDpP4eRxa3MoVwc2gQYNk6dKlsmbNGqlRo0ae244aNcqUr3xLcnJy0M4TAIBQoqHYBWUpr9crgwcPliVLlsjatWulTp0653xMdHS0WQAAQNFULNxLUYsWLZJ33nnHzHVz8OBBs17LTSVLlgz16QEAEFZoKHZBWWrmzJmmtNS2bVupVq2af3nttddCfWoAAIQdj8P/uVXYl6UAAACsCW4AAED+UZZyQVkKAACgoMjcAABgCUfnp/GIaxHcAABgiQgT3Hgc2ZfXxcENZSkAAGAVMjcAAFiChuJMBDcu1P5P8UE5ztFTmVdhL2xlo8oH5Tg2CtZ0CW6ehj0nxSL41QfYjH/hAABYgsxNJnpuAACwhZNXBPcU/KoCTZo0kZiYGLO0bt1a3n//ff/9erWB7Bfm7N+/f8A+9u3bJ507d5ZSpUpJlSpVZMSIEXL69OkCvwxkbgAAwAWrUaOGTJo0SerWrWtK5gsWLJCuXbvKZ599JpdffrnZpl+/fjJ+/Hj/YzSI8Tlz5owJbKpWrSobNmyQAwcOSO/evaV48eIyceLEAp0LwQ0AAJZwsizlKeB+unTpEnD7ySefNNmcTZs2+YMbDWY0eMnJBx98ILt375YPP/xQYmNjpVmzZjJhwgQZOXKkjB07VqKiovJ9LpSlAACwRPayj+cCl/OlWZjFixfLsWPHTHnKZ+HChVK5cmVp1KiRjBo1So4fP+6/b+PGjdK4cWMT2PjEx8dLWlqa7Nq1q0DHJ3MDAABypcFFVtHR0WbJyZdffmmCmRMnTkiZMmVkyZIl0rBhQ3Pf3XffLbVq1ZLq1avLF198YTIySUlJ8tZbb5n7Dx48GBDYKN9tva8gCG4AALCERxwsS/23ozguLi5g/ZgxY0yZKCf16tWTHTt2SGpqqrz55puSkJAg69atMwHO/fff799OMzTVqlWT9u3by3fffSeXXHKJOIngBgAA5Co5OdmMfvLJLWujtC/m0ksvNd+3aNFCtmzZIs8995zMnj37rG1btWplvu7Zs8cEN9qLs3nz5oBtDh06ZL7m1qeTG3puAACwRGH03MT8d2i3b8kruMkuIyND0tPTc7xPMzxKMzhKy1la1kpJSfFvs3LlSnNMX2krv8jcAABgCSevCu4p4H60QbhTp05Ss2ZNOXLkiCxatEjWrl0rK1asMKUnvX3zzTdLpUqVTM/NsGHD5LrrrjNz46iOHTuaIKZXr14yefJk02fz2GOPycCBAwsUUCmCGwAAcME046Lz0uj8NOXKlTNBiwY2N954oylt6RDvqVOnmhFU2sfTo0cPE7z4REZGytKlS2XAgAEmi1O6dGnTs5N1Xpz8IrgBAMASoZznZu7cubnep8GMNhafi46mWrZsmVwoem4AAIBVyNwAAGCJUGZuwgnBDQAAlojweMziCBcHN5SlAACAVcjcAABgiVAOBQ8nZG4AAIBVyNwAAGAJGoozEdwAAGDThTPF2QtnuhFlKQAAYBUyNwAAWIKyVCaCGwAALEFwk4myFAAAsAqZGwAALME8N5kIblwoWKnCslHlg3Kcb1J3SbBcVu5ysYmb08ZFgdfrDcpxeB8AgQhuAACwBD03mQhuAACwBMFNJhqKAQCAVcjcAABgCwczN0LmBgAAIDyQuQEAwBIMBc9EcAMAgCVoKM5EWQoAAFjFVcHNpEmTTCQ5dOjQUJ8KAABhWpbyOLSIa7mmLLVlyxaZPXu2NGnSJNSnAgBAWKIs5aLMzdGjR6Vnz54yZ84cqVChQqhPBwAAhDFXBDcDBw6Uzp07S4cOHUJ9KgAAhC1PlhFTngtdxL3Cviy1ePFi2b59uylL5Ud6erpZfNLS0grx7AAAQLgJ68xNcnKyDBkyRBYuXCglSpTI12MSExOlXLly/iUuLq7QzxMAgHDgXDOxh56bwrJt2zZJSUmRK664QooVK2aWdevWybRp08z3Z86cOesxo0aNktTUVP+iARIAAEUBwY0LylLt27eXL7/8MmBdnz59pH79+jJy5EiJjIw86zHR0dFmAQAARVNYBzdly5aVRo0aBawrXbq0VKpU6az1AAAUdQwFd0FZCgAAwKrMTU7Wrl0b6lMAACAsceFMlwY3AAAgZ5SlMlGWAgAAViFzAwCALahLGWRuAACAVQhuAACwRCgn8Zs5c6Y0adJEYmJizNK6dWt5//33/fefOHHCXCtSp3MpU6aM9OjRQw4dOhSwj3379plrSZYqVUqqVKkiI0aMkNOnTxf4dSC4AQDAEo5dNNNT8KpUjRo1ZNKkSebqAlu3bpUbbrhBunbtKrt27TL3Dxs2TN577z154403zNUG9u/fL927d/c/Xq86oIHNyZMnZcOGDbJgwQKZP3++jB49uuCvg9fr9YrF9MKZeo2pQ78fMJEkws83qZlv/GC4rNzlQTsWEKxfr24e1WI7/QyKrVjNXA6oMD+DfJ91TZ7rLJElizuyzzP/d0q+GPKfCzr3ihUrytNPPy233XabXHTRRbJo0SLzvfr666+lQYMGsnHjRrn66qtNlufPf/6zCXpiY2PNNrNmzTJXJPjll18kKioq38eloRghF8yA4/197wXlOJ1qdgnKcRDeCDpgw1DwtLS0Al/mSLMwmqE5duyYKU9pNufUqVPSoUMH/zZ6KaWaNWv6gxv92rhxY39go+Lj42XAgAEm+9O8efN8nztlKQAALFEYPTdxcXEmK+RbEhMTcz2+Xg9S+2k0+Onfv78sWbJEGjZsKAcPHjSZl/Llywdsr4GM3qf0a9bAxne/776CIHMDAABylZycHFCWyitrU69ePdmxY4cpZb355puSkJBg+muCjeAGAABLFEZZKua/o5/yQ7Mzl156qfm+RYsWsmXLFnnuuefkjjvuMI3Chw8fDsje6GipqlWrmu/16+bNmwP25xtN5dsmvyhLAQCAQpGRkSHp6ekm0ClevLisWrXKf19SUpIZ+q09OUq/alkrJSXFv83KlStNYKWlrYIgcwMAgCVCOUHxqFGjpFOnTqZJ+MiRI2ZklF7sesWKFaZXp2/fvjJ8+HAzgkoDlsGDB5uARpuJVceOHU0Q06tXL5k8ebLps3nsscfM3DjnamDOjuAGAABLhPLCmSkpKdK7d285cOBA5rD0Jk1MYHPjjTea+6dMmSIRERFm8j7N5uhIqBdeeMH/+MjISFm6dKkZHaVBT+nSpU3Pzvjx4wt87gQ3AADggs2dOzfP+0uUKCEzZswwS25q1aoly5Ytu+BzIbgBAMAWDmZuxMXzNNFQDAAArELmBgAAS4Sy5yacENwAAGAJgptMlKUAAIBVyNwAAGCJUM5zE04IbgAAsIRHHCxLiXujG8pSAADAKmRuAACwBA3FmcjcAAAAq5C5AQDAEmRuMhHcAABgCUZLZaIsBQAArELmBgAAS1CWykTmBgAAWIXMDQAAttBki8epphtxLYIbAAAsQVkqE2UpAABgFTI3KFI61ewSlONkeDOCcpwID3+fAPj/IjyZi1P7ciuCGwAALEFZKhN/9gEAAKuQuQEAwBIRHo9ZnNqXW5G5AQAAViFzAwCAJei5yURwAwCAJSIcLMlEiHu5+dwBAADcF9z8/PPPcs8990ilSpWkZMmS0rhxY9m6dWuoTwsAgLCjpaQIhxbKUoXkjz/+kDZt2ki7du3k/fffl4suuki+/fZbqVChQqhPDQAAhKmwDm6eeuopiYuLk3nz5vnX1alTJ6TnBABAuKKh2AVlqXfffVdatmwpf/nLX6RKlSrSvHlzmTNnTqhPCwCAsORUSSrCwflyQiGsg5vvv/9eZs6cKXXr1pUVK1bIgAED5IEHHpAFCxbk+pj09HRJS0sLWAAAQNER1mWpjIwMk7mZOHGiua2Zm507d8qsWbMkISEhx8ckJibKuHHjgnymAACEHmUpF2RuqlWrJg0bNgxY16BBA9m3b1+ujxk1apSkpqb6l+Tk5CCcKQAACBdhnbnRkVJJSUkB67755hupVatWro+Jjo42CwAARQ2T+LkguBk2bJhcc801pix1++23y+bNm+XFF180CwAACMSFM10QmF155ZWyZMkSefXVV6VRo0YyYcIEmTp1qvTs2TPUpwYAAMJUWGdu1J///GezAACAvNFQ7ILMDQAAcMc8N4mJiabiUrZsWTM3Xbdu3c7qm23btq0/APMt/fv3D9hGBw117txZSpUqZfYzYsQIOX36tF2ZGwAAEP7WrVsnAwcONAGOBiOPPvqodOzYUXbv3i2lS5f2b9evXz8ZP368/7YGMT5nzpwxgU3VqlVlw4YNcuDAAendu7cUL17cPy1MfhDcAABgCc21eBzcV0EsX7484Pb8+fNN5mXbtm1y3XXXBQQzGrzk5IMPPjDB0IcffiixsbHSrFkz0287cuRIGTt2rERFReXrXChLAQCAXGWf9V+vBJAfOtecqlixYsD6hQsXSuXKlc1AIZ2b7vjx4/77Nm7cKI0bNzaBjU98fLw57q5duyS/yNwAAGCJwhgKHhcXF7B+zJgxJotyrisMDB061MxXp0GMz913323mqqtevbp88cUXJiOjfTlvvfWWuf/gwYMBgY3y3db78ovgBgAAS0SIg8HNfwtTOtN/TEyMf31+JsrV3hu9XNLHH38csP7+++/3f68ZGr0SQfv27eW7776TSy65xJHzzjx3AACAXGhgk3U5V3AzaNAgWbp0qaxZs0Zq1KiR57atWrUyX/fs2WO+ai/OoUOHArbx3c6tTycnZG6AQhDhCc7fDV8f/jIox6lfvnFQjgPAvfPceL1eGTx4sJl8d+3atVKnTp1zPmbHjh3mq2ZwVOvWreXJJ5+UlJQU04ysVq5caYKq7NeazAvBDQAAuGBailq0aJG88847Zq4bX49MuXLlpGTJkqb0pPfffPPNUqlSJdNzo5dZ0pFUTZo0Mdvq0HENYnr16iWTJ082+3jsscfMvgty3UiCGwAALKHZlogQZW5mzpzpn6gvq3nz5sm9995rhnHrEG+9jNKxY8dMo3KPHj1M8OITGRlpSloDBgwwWRydHychISFgXpz8ILgBAMASoZznxuv15nm/BjM60d+56GiqZcuWyYWgoRgAAFiFzA0AAJYojHlu3IjgBgAASxDcZKIsBQAArELmBgAAS2iyxePYaClxLTI3AADAKmRuAACwBD03mQhuAACwRCjnuQknlKUAAIBVziu4+eijj+See+4xUyP//PPPZt2//vWvsy5tDgAAgl+WinBoKTLBzb///W+Jj483F8H67LPPJD093axPTU2ViRMnFsY5AgAAFF5w88QTT8isWbNkzpw5Urx4cf/6Nm3ayPbt2wu6OwAA4BAyN+fZUJyUlGQuT56dXtL88OHDTp0XAAAoIJ3jxhOiq4K7OnNTtWpV2bNnz1nrtd/m4osvduq8AAAAghPc9OvXT4YMGSKffvqpier2798vCxculIceekgGDBhwfmcBAAAc+VCPcHApMmWpRx55RDIyMqR9+/Zy/PhxU6KKjo42wc3gwYML5ywBAAAKK7jRbM0//vEPGTFihClPHT16VBo2bChlypQp6K4AAICTHOy5kaI4Q3FUVJQJagAAQHjg8gvnGdy0a9cuz6hw9erVBd0lAABA6IKbZs2aBdw+deqU7NixQ3bu3CkJCQnOnRkAACgQMjfnGdxMmTIlx/Vjx441/TcAACA0mOcmk2MjvfRaUy+99JJTuwMAAAhuQ3F2GzdulBIlSji1OwD5UL9846AcJ8ObEZTjRHjcPLMGEHoR4jGLU/sqMsFN9+7dA257vV45cOCAbN26VR5//HEnzw0AAKDwgxu9hlRWERERUq9ePRk/frx07Nix4GcAAAAcQc/NeQQ3Z86ckT59+kjjxo2lQoUKBXkoAAAoZIyWylSgAndkZKTJznD1bwAAEK4K3L3XqFEj+f777wvnbAAAwHnzOPxfkQlunnjiCXORzKVLl5pG4rS0tIAFAADAFT032jD84IMPys0332xu33LLLQHNRjpqSm9rXw4AAAg+GooLGNyMGzdO+vfvL2vWrMnvQwAAQBDRUFzA4EYzM+r666+XYNEskF7W4ZVXXpGDBw9K9erV5d5775XHHnvM1RElAAAIk6HgwQ4onnrqKZk5c6YsWLBALr/8cjNRoA5F17l2HnjggaCeCwAA4S5zfuIIx/ZVJIKbyy677JwBzu+//y5O2bBhg3Tt2lU6d+5sbteuXVteffVV2bx5s2PHAADAFia08XD5hQIFN9p3k32G4sJ0zTXXyIsvvijffPONCaw+//xz+fjjj+XZZ5/N9THp6elm8WEEFwAARUuBgps777xTqlSpIsHyyCOPmOCkfv36ZgJB7cF58sknpWfPnrk+JjEx0QRhAAAUOR4HW0jcm7jJf0EtFA28r7/+uixcuFAWLVok27dvN703zzzzjPmam1GjRklqaqp/SU5ODuo5AwBQFCUmJsqVV14pZcuWNYmQbt26SVJSUsA2J06ckIEDB0qlSpWkTJky0qNHDzl06FDANvv27TPtKKVKlTL7GTFihJw+fbpwR0sFkz4hzd5oxkjpNa1+/PFH8wImJCTk+Jjo6GizAABQ1Dg5s7CngPtZt26dCVw0wNFg5NFHHzWXbNq9e7eULl3abDNs2DD5z3/+I2+88YZpcxk0aJB0795dPvnkE3O/Vmg0sKlatarpu9XJgnv37i3FixeXiRMnOh/cZGRkSLAdP37cXHU8Ky1PheJcAAAId6Gc52b58uUBt+fPn28yL9u2bZPrrrvOVFPmzp1rqjE33HCD2WbevHnSoEED2bRpk1x99dXywQcfmGDoww8/lNjYWGnWrJlMmDBBRo4caaaGiYqKyt+5Sxjr0qWL6bHRKO+HH36QJUuWmGbiW2+9NdSnBgAA8qDBjKpYsaL5qkHOqVOnpEOHDv5ttKe2Zs2asnHjRnNbv2qVRgMbn/j4eNN/u2vXLimUhuJgmz59ujz++OPy97//XVJSUswkfn/7299k9OjRoT41AADCTmFcfiEt26jj/LR/aIVl6NCh0qZNG3PBbaWT8WrmpXz58gHbaiCj9/m2yRrY+O733WdFcKNNSVOnTjULAAAIvri4uIDbY8aMMSWivGjvzc6dO830LaEQ1sENAADIv4j//ucE33501HFMTIx//bmyNtokvHTpUlm/fr3UqFHDv16bhE+ePCmHDx8OyN7oaCm9z7dN9ol6faOpfNvk79wBAIBVZSmPQ4vSwCbrkltwo6OqNbDR/tjVq1dLnTp1Au5v0aKFGfW0atUq/zodKq5Dv1u3bm1u69cvv/zStKL4rFy50hy3YcOG+X4dyNwAAIALpqUoHQn1zjvvmLYSX4+MDvkuWbKk+dq3b18ZPny4aTLWgGXw4MEmoNGRUkqHjmsQ06tXL5k8ebLZh14sW/ddkGleCG4AALBEYTQU55de6Fq1bds2YL0O97733nvN91OmTDFTvOjkfXqpJB0J9cILLwRM96IlrQEDBpigR+fH0Xntxo8fLwVBcAMAgCUyrwnucWxfBZGfyX5LlCghM2bMMEtuatWqJcuWLZMLQc8NAACwCpkbB4XiEhWFKRTXE0N4ivAE5++gObtnB+U4fRv0s+p1A8KhLBVO+JcHAACsQuYGAABLhPLaUuGE4AYAAEuE8qrg4YSyFAAAsAqZGwAALKFN7BEONbK7uSHevWcOAACQAzI3AABYgqHgmQhuAACwhnMNxbovt6IsBQAArELmBgAASzDPTSYyNwAAwCpkbgAAsAST+GUiuAEAwBIRHufKSbovt6IsBQAArELmBgAAS3g8EWZxal9uRXADAIAl6LnJ5N6wDAAAIAdkbgAAsATz3GQicwMAAKxC5gYAAEtw4cxMBDcAAFgiQjxmcWpfbkVZCgAAWIXMDQAAlqAslYnMDQAAsAqZGwAALMEMxZkIbhx0MiM9KMcpHhEVlOMEa3ZKr9crtnFzOjeUEurdG5TjlO5UPyjHOf5+UlCOw/sNPjQUZ3JvWAYAAJADMjcAAFiChuJMBDcAAFjDuQtn6r7cirIUAACwCpkbAABsytt4HCpLkbkBAAAID2RuAACwBEPBMxHcAABgCSbxyxTSM1+/fr106dJFqlevbmqEb7/99lmTu40ePVqqVasmJUuWlA4dOsi3334bsvMFAADhL6TBzbFjx6Rp06YyY8aMHO+fPHmyTJs2TWbNmiWffvqplC5dWuLj4+XEiRNBP1cAANwxENzj2H9OJy3uvfde/1w8vuWmm24K2Ob333+Xnj17SkxMjJQvX1769u0rR48edU9ZqlOnTmbJiWZtpk6dKo899ph07drVrHv55ZclNjbWvFh33nlnkM8WAADkJ2lx3333Sffu3XPcRoOZefPm+W9HR0cH3K+BzYEDB2TlypVy6tQp6dOnj9x///2yaNEicX3Pzd69e+XgwYOmFOVTrlw5adWqlWzcuDHX4CY9Pd0sPmlpaUE5XwAAQk1HgXscm6HY2aRF1mCmatWqOd731VdfyfLly2XLli3SsmVLs2769Oly8803yzPPPGMyQvkRtt1CGtgozdRkpbd99+UkMTHRBEG+JS4urtDPFQAAW8tSaWlpAUvWBML5WLt2rVSpUkXq1asnAwYMkN9++81/nyYvtBTlC2yUJjkiIiJMe0p+hW1wc75GjRolqamp/iU5OTnUpwQAgGvFxcUFJA00iXC+tCSlLSarVq2Sp556StatW2cyPWfOnDH3a/JCA5+sihUrJhUrVswzseGaspQvZXXo0CEzWspHbzdr1izPdFf2+h0AAEVBYVw4Mzk52TT3+lzIZ2zWlpLGjRtLkyZN5JJLLjHZnPbt24tTwjZzU6dOHRPgaHTno+kwTUu1bt06pOcGAEBRERMTE7A4mUC4+OKLpXLlyrJnzx5zWz/3U1JSArY5ffq0GUGVW59O2GVudGiX7wn5moh37Nhh0k81a9aUoUOHyhNPPCF169Y1wc7jjz9umom6desWytMGACAsuW2G4p9++sn03PgqNJq8OHz4sGzbtk1atGhh1q1evVoyMjLMgCJXBDdbt26Vdu3a+W8PHz7cfE1ISJD58+fLww8/bIaV6RAwfbLXXnut6aIuUaJECM8aAICiU5ZyKmmhy7hx46RHjx4mC/Pdd9+Zz/lLL73UzGGnGjRoYPpy+vXrZ+a406HggwYNMuWs/I6UCnlw07ZtWzOfTV4v7Pjx480CAADC29Y8khYzZ86UL774QhYsWGASFhqsdOzYUSZMmBBQ6lq4cKEJaLQHR0dJaTCkE/oWRNg2FAMAgILJLEpFOLYvp5MWK1asOOc+NMNTkAn7ckJwAwCAJUJdlgoXYTtaCgAA4HyQuQEAwBLne8HLnDi1n1AgcwMAAKxC5gYAAEtEeDxmcWpfbkVw46DoSObfKWpNa3BWVGRwLp1y/P2koBxn+6/5v9DfhWhx0dVBOQ7CH2WpTJSlAACAVcjcAABgCYaCZyJzAwAArELmBgAAazg3Q7Gb8x8ENwAAWIKylNvDMgAAgByQuQEAwKqilMexfbkVwQ0AAJagLJWJshQAALAKmRsAACzBDMWZyNwAAACrkLkBAMAS9NxkIrgBAMASmUWpCMf25VaUpQAAgFXI3AAAYIkIj8csTu3LrcjcAAAAq5C5AQDAEgwFz0RwAwCAJRgtlYmyFAAAsAqZGwAALEFZKhPBDQAAlqAslYmyFAAAsAqZGwAALBHx3/+c4NR+QsG9Zw4AAJADMjcAAFiCnptMBDcAipxg/dJucdHVQTnOkZOHJVjKRpUP2rFQcIyWykRZCgAAWIXMDQAAtnCwLCUuLkuRuQEAAFYhcwMAgCXouclE5gYAAMuCG49D/xXU+vXrpUuXLlK9enVTHnv77bcD7vd6vTJ69GipVq2alCxZUjp06CDffvttwDa///679OzZU2JiYqR8+fLSt29fOXr0aIHOg+AGAAA44tixY9K0aVOZMWNGjvdPnjxZpk2bJrNmzZJPP/1USpcuLfHx8XLixAn/NhrY7Nq1S1auXClLly41AdP9999foPOgLAUAgC20CdgTuobiTp06mSUnmrWZOnWqPPbYY9K1a1ez7uWXX5bY2FiT4bnzzjvlq6++kuXLl8uWLVukZcuWZpvp06fLzTffLM8884zJCOUHmRsAAFDo9u7dKwcPHjSlKJ9y5cpJq1atZOPGjea2ftVSlC+wUbp9RESEyfTkV0iDm7xqc6dOnZKRI0dK48aNTdpKt+ndu7fs378/lKcMAECR6rlJS0sLWNLT08/r3DSwUZqpyUpv++7Tr1WqVAm4v1ixYlKxYkX/NmEf3ORVmzt+/Lhs375dHn/8cfP1rbfekqSkJLnllltCcq4AALjl8gsehxYVFxdnMiy+JTExUcJdSHtu8qrN6QuozURZPf/883LVVVfJvn37pGbNmkE6SwAAiq7k5GQzcsknOjr6vPZTtWpV8/XQoUNmtJSP3m7WrJl/m5SUlIDHnT592oyg8j3eup6b1NRUE0lqPS43mi7LnkIDAKAoKIyyVExMTMByvsFNnTp1TICyatUq/zr9jNZemtatW5vb+vXw4cOybds2/zarV6+WjIwM05tj3WgpHSamPTh33XVXQASZnabLxo0bF9RzAwAgHGg44nFsEr+C0/lo9uzZE9BEvGPHDtMzoxWXoUOHyhNPPCF169Y1wY62nmhPbbdu3cz2DRo0kJtuukn69etnhotr/+2gQYPMSKr8jpRyTeZGn9ztt99uhpHNnDkzz21HjRplMjy+RdNpAACg8G3dulWaN29uFjV8+HDzvU7cpx5++GEZPHiwmbfmyiuvNMGQDv0uUaKEfx8LFy6U+vXrS/v27c0Q8GuvvVZefPHFAp1HMbcENj/++KNJTeWVtVGaLjvflBkAAG5mikme0F1+oW3btiYRkes+PR4ZP368WXKjWZ5FixbJhSjmhsBGp2Zes2aNVKpUKdSnBAAAwlxIg5u8anPaSX3bbbeZYeA6/fKZM2f8Y9z1/qioqBCeOQAA4YcLZ4ZBcKO1uXbt2vlva21OJSQkyNixY+Xdd981t31DxHw0i6OpLwAA8P8R3IRBcHOu2lxe9wEAALiu5wYAAORf1pmFL5RT+wkFVwwFBwAAyC8yNwAAWIKem0wENwAAWIKyVCbKUgAAwCpkbgAAsARlqUwENwAAWILgJhPBDQC4XNmo8kE71l9XPhSU47zYYXJQjhPhoTvDRgQ3AABYgobiTISsAADAKmRuAACwBD03mQhuAACwBMFNJspSAADAKmRuAACwhYMNxUJDMQAAQHggcwMAgDU02+JUxsW9mRuCGwAALME8N5koSwEAAKuQuQEAwBIMBc9E5gYAAFiFzA0AAJYgc5OJ4AYAAEvQUJyJshQAALAKmRsAAKya5cbj2L7ciuAGAABL0HOTibIUAACwCpkbAAAsQUNxJjI3AADAKmRuAACwBD03mQhuAACwBGWpTJSlAACAVcjcAABgCcpSmcjcAAAAq5C5Qch5vV6xjZtr1UBeXmg/MSjH+SP916Acp1KJKmLjHMXOKNh+xo4dK+PGjQtYV69ePfn666/N9ydOnJAHH3xQFi9eLOnp6RIfHy8vvPCCxMbGitPI3AAAYFlo43FoKajLL79cDhw44F8+/vhj/33Dhg2T9957T9544w1Zt26d7N+/X7p37y6FgcwNAABwRLFixaRq1apnrU9NTZW5c+fKokWL5IYbbjDr5s2bJw0aNJBNmzbJ1VdfLU4icwMAgGVDwT0OLSotLS1g0ZJSbr799lupXr26XHzxxdKzZ0/Zt2+fWb9t2zY5deqUdOjQwb9t/fr1pWbNmrJx40bHXweCGwAArOF8YSouLk7KlSvnXxITE3M8cqtWrWT+/PmyfPlymTlzpuzdu1f+53/+R44cOSIHDx6UqKgoKV++fMBjtN9G73MaZSkAAJCr5ORkiYmJ8d+Ojo7OcbtOnTr5v2/SpIkJdmrVqiWvv/66lCxZUoKJzA0AAJYojIbimJiYgCW34CY7zdJcdtllsmfPHtOHc/LkSTl8+HDANocOHcqxR+dCEdwAAADHHT16VL777jupVq2atGjRQooXLy6rVq3y35+UlGR6clq3bm1XcLN+/Xrp0qWLaT7SxqW3334712379+9vtpk6dWpQzxEAAPcI3WDwhx56yAzx/uGHH2TDhg1y6623SmRkpNx1112mV6dv374yfPhwWbNmjWkw7tOnjwlsnB4pFfKem2PHjknTpk3lvvvuy3Os+5IlS8xQMQ2CAABA+F0486effjKBzG+//SYXXXSRXHvtteazW79XU6ZMkYiICOnRo0fAJH6FIaTBjTYfZW1AysnPP/8sgwcPlhUrVkjnzp2Ddm4AACD/dObhvJQoUUJmzJhhlsIW1j03GRkZ0qtXLxkxYoSZ9RAAAMDVQ8GfeuopM9vhAw88kO/HaKor6wRDOuEQAAAoOsI2uNFmo+eee062b99eoLqfTi6U/cJdAAAUBZ7//ucEp/YTCmFblvroo48kJSXFTM2s2RtdfvzxR3NF0dq1a+f6uFGjRplrWPgWnXwIAICiFNx4HPrPrcI2c6O9NlmvQaG0s1rX6/Cx3OjkQvmdYAgAANinWKgn+NGZC330OhQ7duyQihUrmoxNpUqVArbXCYB0JsN69eqF4GwBAIAbhDS42bp1q7Rr185/Wyf3UQkJCebiWwAAwB3z3ISTkAY3bdu2Fa/Xm+/tddZDAAAAVzYUAwAAnA+CGwAAYJWwHS0FAAAKyskh3PTcAACAkCv41bzz3pc7UZYCAABWIXMDAIAlyNtkInMDAACsQuYGIefmiaKAoiYqIioox6lUokpQjpN+5oSr958dk/hlIrgBAMAaFKYUZSkAAGAVMjcAAFiCvE0mMjcAAMAqZG4AALCKR4o6ghsAACzBaKlMlKUAAIBVCG4AAIBVKEsBAGDVNcE9ju3LrcjcAAAAq5C5AQDAGsx0o8jcAAAAq5C5AQDAEuRtMhHcAABgCea5yURZCgAAWIXMDQAA1qAwpcjcAAAAq5C5AQDAEuRtMhHcAABgDcIbRVkKAABYheAGAADLhoJ7HFrOx4wZM6R27dpSokQJadWqlWzevFmCjeAGAAA44rXXXpPhw4fLmDFjZPv27dK0aVOJj4+XlJQUCSaCGwAA4Ihnn31W+vXrJ3369JGGDRvKrFmzpFSpUvLSSy9JMBHcAABgCY/D/xXEyZMnZdu2bdKhQwf/uoiICHN748aNEkzWj5byer3m65G0I6E+FQBAmEk/c6JQ93/kyJGAz6LClubgZ13af/eVlpYWsD46Otos2f36669y5swZiY2NDVivt7/++msJJuuDG98b69Lal4X6VAAARZR+FpUrV67Q9h8VFSVVq1aVug5/1pUpU0bi4uIC1mk/zdixYyWcWR/cVK9eXZKTk6Vs2bL57vzWKFV/mPq4mJgYcTueT3iz7fnY+Jx4PuEtnJ+PZmw0sNHPosKkI5P27t1rSkNOn3/2z86csjaqcuXKEhkZKYcOHQpYr7c18Aom64MbrffVqFHjvB6r/0jC7R/KheD5hDfbno+Nz4nnE97C9fkUZsYme4CjS6ho9qhFixayatUq6datm1mXkZFhbg8aNCio52J9cAMAAIJDh4EnJCRIy5Yt5aqrrpKpU6fKsWPHzOipYCK4AQAAjrjjjjvkl19+kdGjR8vBgwelWbNmsnz58rOajAsbwU0OtJ6oDVO51RXdhucT3mx7PjY+J55PeLPt+bjdoEGDgl6Gys7jDdb4NAAAgCBgEj8AAGAVghsAAGAVghsAAGAVgpswvFS7UxITE+XKK680ExhWqVLFzDuQlJQktpg0aZKZXGro0KHiVj///LPcc889UqlSJSlZsqQ0btxYtm7dKm6k064//vjjUqdOHfNcLrnkEpkwYULQpp13wvr166VLly5mwjV9b7399tsB9+tz0VEg1apVM89Rr5nz7bffihufz6lTp2TkyJHmPVe6dGmzTe/evWX//v3i1p9PVv379zfb6FBkFD0EN2F4qXanrFu3TgYOHCibNm2SlStXml9mHTt2NHMOuN2WLVtk9uzZ0qRJE3GrP/74Q9q0aSPFixeX999/X3bv3i3//Oc/pUKFCuJGTz31lMycOVOef/55+eqrr8ztyZMny/Tp08Ut9N+G/rvXP3Jyos9n2rRp5krHn376qQkK9HfEiROFe32iwng+x48fN7/nNCDVr2+99Zb54+eWW24Rt/58fJYsWWJ+7xX2rMAIYzpaCpmuuuoq78CBA/23z5w5461evbo3MTHRa4OUlBT9E9q7bt06r5sdOXLEW7duXe/KlSu9119/vXfIkCFeNxo5cqT32muv9dqic+fO3vvuuy9gXffu3b09e/b0upH+W1myZIn/dkZGhrdq1arep59+2r/u8OHD3ujoaO+rr77qddvzycnmzZvNdj/++KPXrc/np59+8v7pT3/y7ty501urVi3vlClTQnJ+CC0yN2F4qfbCkpqaar5WrFhR3EyzUZ07dw74WbnRu+++a2bx/Mtf/mLKhs2bN5c5c+aIW11zzTVmmvVvvvnG3P7888/l448/lk6dOokN9Lo9OilZ1vedTquv5WubfkdoKad8+fLiRjrVf69evWTEiBFy+eWXh/p0EEJM4heGl2ovrH/02puiZZBGjRqJWy1evNik0LUs5Xbff/+9KeNoKfTRRx81z+mBBx4w12fR6cvd5pFHHjEXMKxfv765eJ7+e3ryySelZ8+eYgMNbFROvyN897mZlta0B+euu+4Ky+sz5YeWQosVK2b+HaFoI7gpIjTbsXPnTvOXtFvpFX+HDBli+odCeXE4JwNOzdxMnDjR3NbMjf6MtJ/DjcHN66+/LgsXLpRFixaZv5p37NhhAmrte3Dj8ylKtB/v9ttvNw3TGnC7kWben3vuOfPHT/arWKPooSwVhpdqd5pOg7106VJZs2bNeV8hPVx+eWlz9xVXXGH+OtNFm6a1wVO/10yBm+iIm4YNGwasa9Cggezbt0/cSEsBmr258847zQgcLQ8MGzbMjNqzge/3gG2/I3yBzY8//mj+cHBr1uajjz4yvx9q1qzp//2gz+nBBx80I2BRtBDc5HCpdh/fpdpbt24tbqR/hWlgoyMHVq9ebYbouln79u3lyy+/NBkB36KZDy176PcanLqJlgizD83XfpVatWqJG+noG+1Ty0p/JvrvyAb670eDmKy/I7QMp6Om3Po7whfY6HD2Dz/80ExJ4FYaTH/xxRcBvx80a6hB94oVK0J9eggyylJheKl2J0tRWiJ45513zFw3vr4AbYLUOTrcRp9D9n4hHYqrv5Dd2EekWQ1twtWylH7A6JxKL774olncSOcf0R4b/ctZy1KfffaZPPvss3LfffeJWxw9elT27NkT0ESsH5LahK/PS8tsTzzxhNStW9cEOzqMWj9AdQ4ptz0fzRzedtttpoyjmV3NfPp+R+j9+gef234+2YMznWZBA9J69eqF4GwRUiEerRV2pk+f7q1Zs6Y3KirKDA3ftGmT1630x5vTMm/ePK8t3DwUXL333nveRo0ameHE9evX97744otet0pLSzM/C/33U6JECe/FF1/s/cc//uFNT0/3usWaNWty/DeTkJDgHw7++OOPe2NjY83PrH379t6kpCSvG5/P3r17c/0doY9z488nO4aCF11cFRwAAFiFnhsAAGAVghsAAGAVghsAAGAVghsAAGAVghsAAGAVghsAAGAVghsAAGAVghsAAGAVghsAfvfee2/ApQTatm1rLjkQbGvXrjVXdj58+HDQjw3A/QhuAJcEHfphr4te8+fSSy+V8ePHy+nTpwv1uG+99ZZMmDAhX9sSkAAIF1w4E3CJm266SebNmyfp6emybNkyc2FUvTDgqFGjArY7efKkYxc91AsSAoDbkLkBXCI6Otpc4bhWrVoyYMAA6dChg7z77rv+UpJekVuvUO27AnJycrK52nj58uVNkNK1a1f54Ycf/PvTq0APHz7c3K9XU3744Yf1QroBx8xeltLAauTIkRIXF2fORzNIc+fONftt166d2aZChQomg6PnpTIyMiQxMdFcRVuvRt+0aVN58803A46jwdpll11m7tf9ZD1PACgoghvApTQQ0CyNWrVqlSQlJcnKlStl6dKlcurUKYmPj5eyZcvKRx99JJ988omUKVPGZH98j/nnP/8p8+fPl5deekk+/vhj+f3332XJkiV5HrN3797y6quvyrRp0+Srr76S2bNnm/1qsPPvf//bbKPnceDAAXnuuefMbQ1sXn75ZZk1a5bs2rVLhg0bJvfcc4+sW7fOH4R1795dunTpIjt27JC//vWv8sgjjxTyqwfAaqG+LDmAc0tISPB27drVfJ+RkeFduXKlNzo62vvQQw+Z+2JjY73p6en+7f/1r39569WrZ7b10ftLlizpXbFihbldrVo17+TJk/33nzp1ylujRg3/cdT111/vHTJkiPk+KSlJ0zrm2DlZs2aNuf+PP/7wrztx4oS3VKlS3g0bNgRs27dvX+9dd91lvh81apS3YcOGAfePHDnyrH0BQH7RcwO4hGZkNEuiWRkt9dx9990yduxY03vTuHHjgD6bzz//XPbs2WMyN1mdOHFCvvvuO0lNTTXZlVatWvnvK1asmLRs2fKs0pSPZlUiIyPl+uuvz/c56zkcP35cbrzxxoD1mj1q3ry5+V4zQFnPQ7Vu3TrfxwCA7AhuAJfQXpSZM2eaIEZ7azQY8SldunTAtkePHpUWLVrIwoULz9rPRRdddN5lsILS81D/+c9/5E9/+lPAfdqzAwCFgeAGcAkNYLSBNz+uuOIKee2116RKlSoSExOT4zbVqlWTTz/9VK677jpzW4eVb9u2zTw2J5od0oyR9spoM3N2vsyRNir7NGzY0AQx+/btyzXj06BBA9MYndWmTZvy9TwBICc0FAMW6tmzp1SuXNmMkNKG4r1795p5aB544AH56aefzDZDhgyRSZMmydtvvy1ff/21/P3vf89zjpratWtLQkKC3HfffeYxvn2+/vrr5n4dxaWjpLR89ssvv5isjZbFHnroIdNEvGDBAlMS2759u0yfPt3cVv3795dvv/1WRowYYZqRFy1aZBqdAeB8EdwAFipVqpSsX79eatasaUYiaXakb9++pufGl8l58MEHpVevXiZg0R4XDURuvfXWPPerZbHbbrvNBEL169eXfv36ybFjx8x9WnYaN26cGekUGxsrgwYNMut1EsDHH3/cjJrS89ARW1qm0qHhSs9RR1ppwKTDxHVU1cSJEwv9NQJgL492FYf6JAAAAJxC5gYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAFiF4AYAAIhN/h/0dbCeK00qagAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell runs final test metrics and saves a confusion matrix figure\n",
    "with torch.no_grad():                                                 # no grads\n",
    "    test_logits_list = []                                             # logits list\n",
    "    test_targets_list = []                                            # targets list\n",
    "    for xb, yb in dl_test:                                            # loop test\n",
    "        xb = xb.to(DEVICE)                                            # move features\n",
    "        yb = yb.to(DEVICE)                                            # move labels\n",
    "        test_logits_list.append(model(xb))                            # forward\n",
    "        test_targets_list.append(yb)                                  # store labels\n",
    "    test_logits = torch.cat(test_logits_list, dim=0)                  # stack logits\n",
    "    test_targets = torch.cat(test_targets_list, dim=0)                # stack targets\n",
    "    tm = metrics_from_logits(test_logits, test_targets, num_classes)  # compute metrics\n",
    "\n",
    "print(\"Test accuracy\", tm[\"acc\"])                                     # print accuracy\n",
    "print(\"Test kappa\", tm[\"kappa\"])                                      # print kappa\n",
    "print(\"Test precision macro\", tm[\"prec\"])                             # print precision\n",
    "print(\"Test recall macro\", tm[\"rec\"])                                 # print recall\n",
    "print(\"Test f1 macro\", tm[\"f1\"])                                      # print f1\n",
    "\n",
    "cm = tm[\"cm\"]                                                         # confusion matrix\n",
    "plt.figure(figsize=(6, 5))                                            # figure\n",
    "plt.imshow(cm, cmap=\"Greens\")                                         # plot\n",
    "plt.title(\"Confusion matrix test plain MLP\")                          # title\n",
    "plt.xlabel(\"Predicted\")                                               # x label\n",
    "plt.ylabel(\"True\")                                                    # y label\n",
    "plt.colorbar()                                                        # color bar\n",
    "plt.tight_layout()                                                    # layout\n",
    "plt.savefig(FIGS / \"mlp_plain_confusion_test.png\", dpi=150)           # save figure\n",
    "plt.show()                                                            # show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2cdf6d-8c43-4185-a87f-220e28c54c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.9219512195121952\n",
      "Cohen kappa: 0.9111719907954684\n",
      "Macro precision: 0.9169264117162963\n",
      "Macro recall: 0.9395694425169847\n",
      "Macro f1: 0.9260251741249226\n",
      "Weighted precision: 0.9229830847864825\n",
      "Weighted recall: 0.9219512195121952\n",
      "Weighted f1: 0.9213260454486492\n",
      "\n",
      "Per class metrics\n",
      "Class 01: precision=0.9000, recall=1.0000, f1=0.9474, support=9\n",
      "Class 02: precision=0.9138, recall=0.9266, f1=0.9201, support=286\n",
      "Class 03: precision=0.9200, recall=0.8313, f1=0.8734, support=166\n",
      "Class 04: precision=0.7455, recall=0.8723, f1=0.8039, support=47\n",
      "Class 05: precision=0.9381, recall=0.9381, f1=0.9381, support=97\n",
      "Class 06: precision=0.9539, recall=0.9932, f1=0.9732, support=146\n",
      "Class 07: precision=1.0000, recall=1.0000, f1=1.0000, support=5\n",
      "Class 08: precision=0.9596, recall=0.9896, f1=0.9744, support=96\n",
      "Class 09: precision=0.8000, recall=1.0000, f1=0.8889, support=4\n",
      "Class 10: precision=0.8673, recall=0.9433, f1=0.9037, support=194\n",
      "Class 11: precision=0.9400, recall=0.8941, f1=0.9165, support=491\n",
      "Class 12: precision=0.9194, recall=0.9580, f1=0.9383, support=119\n",
      "Class 13: precision=0.9762, recall=1.0000, f1=0.9880, support=41\n",
      "Class 14: precision=0.9354, recall=0.9723, f1=0.9535, support=253\n",
      "Class 15: precision=0.9016, recall=0.7143, f1=0.7971, support=77\n",
      "Class 16: precision=1.0000, recall=1.0000, f1=1.0000, support=19\n",
      "\n",
      "Full classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.9000    1.0000    0.9474         9\n",
      "     class_2     0.9138    0.9266    0.9201       286\n",
      "     class_3     0.9200    0.8313    0.8734       166\n",
      "     class_4     0.7455    0.8723    0.8039        47\n",
      "     class_5     0.9381    0.9381    0.9381        97\n",
      "     class_6     0.9539    0.9932    0.9732       146\n",
      "     class_7     1.0000    1.0000    1.0000         5\n",
      "     class_8     0.9596    0.9896    0.9744        96\n",
      "     class_9     0.8000    1.0000    0.8889         4\n",
      "    class_10     0.8673    0.9433    0.9037       194\n",
      "    class_11     0.9400    0.8941    0.9165       491\n",
      "    class_12     0.9194    0.9580    0.9383       119\n",
      "    class_13     0.9762    1.0000    0.9880        41\n",
      "    class_14     0.9354    0.9723    0.9535       253\n",
      "    class_15     0.9016    0.7143    0.7971        77\n",
      "    class_16     1.0000    1.0000    1.0000        19\n",
      "\n",
      "    accuracy                         0.9220      2050\n",
      "   macro avg     0.9169    0.9396    0.9260      2050\n",
      "weighted avg     0.9230    0.9220    0.9213      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# move tensors to numpy arrays\n",
    "y_true = test_targets.cpu().numpy()\n",
    "y_pred = test_logits.argmax(1).cpu().numpy()\n",
    "\n",
    "# overall metrics\n",
    "overall_acc = accuracy_score(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=\"macro\", zero_division=0\n",
    ")\n",
    "prec_weighted, rec_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=\"weighted\", zero_division=0\n",
    ")\n",
    "\n",
    "# per class metrics\n",
    "prec_class, rec_class, f1_class, support_class = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "print(\"Overall accuracy:\", overall_acc)\n",
    "print(\"Cohen kappa:\", kappa)\n",
    "print(\"Macro precision:\", prec_macro)\n",
    "print(\"Macro recall:\", rec_macro)\n",
    "print(\"Macro f1:\", f1_macro)\n",
    "print(\"Weighted precision:\", prec_weighted)\n",
    "print(\"Weighted recall:\", rec_weighted)\n",
    "print(\"Weighted f1:\", f1_weighted)\n",
    "\n",
    "print(\"\\nPer class metrics\")\n",
    "for idx, (p, r, f1, s) in enumerate(\n",
    "    zip(prec_class, rec_class, f1_class, support_class), start=1\n",
    "):\n",
    "    print(\n",
    "        f\"Class {idx:02d}: \"\n",
    "        f\"precision={p:.4f}, recall={r:.4f}, f1={f1:.4f}, support={s}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nFull classification report\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=[f\"class_{i}\" for i in range(1, num_classes + 1)],\n",
    "        digits=4,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9c7532-f1a8-4a59-8b21-11af98cde69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     1.0000    0.5000    0.6667         2\n",
      "     class_2     0.9265    0.8873    0.9065        71\n",
      "     class_3     0.9677    0.7143    0.8219        42\n",
      "     class_4     0.8333    0.8333    0.8333        12\n",
      "     class_5     0.9565    0.9167    0.9362        24\n",
      "     class_6     0.9250    1.0000    0.9610        37\n",
      "     class_7     1.0000    1.0000    1.0000         1\n",
      "     class_8     0.9600    1.0000    0.9796        24\n",
      "     class_9     1.0000    1.0000    1.0000         1\n",
      "    class_10     0.8000    0.8980    0.8462        49\n",
      "    class_11     0.8889    0.9106    0.8996       123\n",
      "    class_12     0.8286    0.9667    0.8923        30\n",
      "    class_13     1.0000    1.0000    1.0000        10\n",
      "    class_14     0.8841    0.9683    0.9242        63\n",
      "    class_15     0.9091    0.5263    0.6667        19\n",
      "    class_16     1.0000    1.0000    1.0000         5\n",
      "\n",
      "    accuracy                         0.8967       513\n",
      "   macro avg     0.9300    0.8826    0.8959       513\n",
      "weighted avg     0.9006    0.8967    0.8938       513\n",
      "\n",
      "\n",
      "Test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.8889    0.8889    0.8889         9\n",
      "     class_2     0.8993    0.9056    0.9024       286\n",
      "     class_3     0.9291    0.7892    0.8534       166\n",
      "     class_4     0.7800    0.8298    0.8041        47\n",
      "     class_5     0.9388    0.9485    0.9436        97\n",
      "     class_6     0.9539    0.9932    0.9732       146\n",
      "     class_7     1.0000    1.0000    1.0000         5\n",
      "     class_8     0.9500    0.9896    0.9694        96\n",
      "     class_9     0.8000    1.0000    0.8889         4\n",
      "    class_10     0.8571    0.9278    0.8911       194\n",
      "    class_11     0.9115    0.9022    0.9069       491\n",
      "    class_12     0.9091    0.9244    0.9167       119\n",
      "    class_13     0.9535    1.0000    0.9762        41\n",
      "    class_14     0.9254    0.9802    0.9520       253\n",
      "    class_15     0.9273    0.6623    0.7727        77\n",
      "    class_16     0.9474    0.9474    0.9474        19\n",
      "\n",
      "    accuracy                         0.9117      2050\n",
      "   macro avg     0.9107    0.9181    0.9117      2050\n",
      "weighted avg     0.9124    0.9117    0.9104      2050\n",
      "\n",
      "Saved reports in outputs/figs\n"
     ]
    }
   ],
   "source": [
    "# This cell prints and saves per class precision recall f1 and support for val and test\n",
    "\n",
    "from sklearn.metrics import classification_report                                                                  # import the report function\n",
    "import pandas as pd                                                                                                # import pandas to save tables\n",
    "from pathlib import Path                                                                                           # import Path for file paths\n",
    "\n",
    "REPORT_DIR = Path(\"outputs/figs\")                                                                                  # choose a folder for text and csv files\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)                                                                      # create the folder if needed\n",
    "\n",
    "                                                                                                                   # Build y true and y pred for validation from tensors already in memory\n",
    "y_val_true = val_targets.cpu().numpy()                                                                             # true class ids for val in zero based\n",
    "y_val_pred = val_logits.argmax(1).cpu().numpy()                                                                    # predicted class ids for val in zero based\n",
    "\n",
    "                                                                                                                   # Build y true and y pred for test from tensors already in memory\n",
    "y_test_true = test_targets.cpu().numpy()                                                                           # true class ids for test in zero based\n",
    "y_test_pred = test_logits.argmax(1).cpu().numpy()                                                                  # predicted class ids for test in zero based\n",
    "\n",
    "                                                                                                                   # Human friendly names 1 to C since your labels are one based in the dataset\n",
    "target_names = [f\"class_{i}\" for i in range(1, num_classes + 1)]                                                   # make names\n",
    "\n",
    "# Text reports\n",
    "val_text = classification_report(y_val_true, y_val_pred, target_names=target_names, digits=4, zero_division=0)     # val text\n",
    "test_text = classification_report(y_test_true, y_test_pred, target_names=target_names, digits=4, zero_division=0)  # test text\n",
    "\n",
    "print(\"Validation classification report\")                                                                          # header\n",
    "print(val_text)                                                                                                    # show val report\n",
    "print(\"\\nTest classification report\")                                                                              # header\n",
    "print(test_text)                                                                                                   # show test report\n",
    "\n",
    "# Save text files\n",
    "(REPORT_DIR / \"mlp_plain_classification_report_val.txt\").write_text(val_text)                                      # save val text\n",
    "(REPORT_DIR / \"mlp_plain_classification_report_test.txt\").write_text(test_text)                                    # save test text\n",
    "\n",
    "# Also save as csv tables\n",
    "def report_to_df(y_true, y_pred, names):\n",
    "    \"\"\"Convert classification report dict to a dataframe\"\"\"                                                        # docstring\n",
    "    rep = classification_report(y_true, y_pred, target_names=names, output_dict=True, zero_division=0)             # dict form\n",
    "    df = pd.DataFrame(rep).T.reset_index().rename(columns={\"index\": \"label\"})                                      # to dataframe\n",
    "    return df                                                                                                      # return table\n",
    "\n",
    "df_val = report_to_df(y_val_true, y_val_pred, target_names)                                                        # val table\n",
    "df_test = report_to_df(y_test_true, y_test_pred, target_names)                                                     # test table\n",
    "\n",
    "df_val.to_csv(REPORT_DIR / \"mlp_plain_classification_report_val.csv\", index=False)                                 # save val csv\n",
    "df_test.to_csv(REPORT_DIR / \"mlp_plain_classification_report_test.csv\", index=False)                               # save test csv\n",
    "\n",
    "print(\"Saved reports in\", REPORT_DIR.as_posix())                                                                   # confirm save folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb3da4c-e588-4599-8c57-ab57e15485b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  Spectral MLP plain loss\n",
      "Params 86416\n",
      "Val  acc 0.8967 kappa 0.882 f1 0.8959\n",
      "Test acc 0.9117 kappa 0.8993 f1 0.9117\n",
      "Runs folder outputs/runs_mlp\n",
      "Figs folder outputs/figs\n"
     ]
    }
   ],
   "source": [
    "# This cell prints a short summary for the results section\n",
    "print(\"Model  Spectral MLP plain loss\")                                                           # model name\n",
    "print(\"Params\", sum(p.numel() for p in model.parameters()))                                       # parameter count\n",
    "print(\"Val  acc\", round(vm[\"acc\"], 4), \"kappa\", round(vm[\"kappa\"], 4), \"f1\", round(vm[\"f1\"], 4))  # val summary\n",
    "print(\"Test acc\", round(tm[\"acc\"], 4), \"kappa\", round(tm[\"kappa\"], 4), \"f1\", round(tm[\"f1\"], 4))  # test summary\n",
    "print(\"Runs folder\", RUNS.as_posix())                                                             # runs path\n",
    "print(\"Figs folder\", FIGS.as_posix())                                                             # figs path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7d94e7-54b9-4101-9466-5d85342d1867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top ANOVA bands [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 74, 100, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198]\n",
      "Params with K bands 73616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA K150  epoch 001  tl 1.9230  vl 1.5152  va 0.4990  vf 0.2033\n",
      "ANOVA K150  epoch 002  tl 1.4607  vl 1.2706  va 0.5302  vf 0.3024\n",
      "ANOVA K150  epoch 003  tl 1.2881  vl 1.1280  va 0.5887  vf 0.3894\n",
      "ANOVA K150  epoch 004  tl 1.1658  vl 1.0149  va 0.6160  vf 0.4069\n",
      "ANOVA K150  epoch 005  tl 1.0679  vl 0.9632  va 0.6238  vf 0.4496\n",
      "ANOVA K150  epoch 006  tl 1.0175  vl 0.8940  va 0.6628  vf 0.4903\n",
      "ANOVA K150  epoch 007  tl 0.9461  vl 0.8171  va 0.6901  vf 0.5171\n",
      "ANOVA K150  epoch 008  tl 0.9210  vl 0.7846  va 0.7115  vf 0.5551\n",
      "ANOVA K150  epoch 009  tl 0.8730  vl 0.7536  va 0.7368  vf 0.5864\n",
      "ANOVA K150  epoch 010  tl 0.8387  vl 0.7333  va 0.7135  vf 0.5634\n",
      "ANOVA K150  epoch 011  tl 0.8066  vl 0.7032  va 0.7212  vf 0.5690\n",
      "ANOVA K150  epoch 012  tl 0.7871  vl 0.6970  va 0.7388  vf 0.5768\n",
      "ANOVA K150  epoch 013  tl 0.7609  vl 0.6449  va 0.7622  vf 0.6262\n",
      "ANOVA K150  epoch 014  tl 0.7296  vl 0.6620  va 0.7466  vf 0.6835\n",
      "ANOVA K150  epoch 015  tl 0.7315  vl 0.6532  va 0.7368  vf 0.6560\n",
      "ANOVA K150  epoch 016  tl 0.7510  vl 0.6049  va 0.7583  vf 0.7157\n",
      "ANOVA K150  epoch 017  tl 0.6740  vl 0.5694  va 0.7856  vf 0.7381\n",
      "ANOVA K150  epoch 018  tl 0.6809  vl 0.6105  va 0.7583  vf 0.7132\n",
      "ANOVA K150  epoch 019  tl 0.6726  vl 0.5367  va 0.8090  vf 0.7526\n",
      "ANOVA K150  epoch 020  tl 0.6378  vl 0.5203  va 0.7973  vf 0.7339\n",
      "ANOVA K150  epoch 021  tl 0.6239  vl 0.5303  va 0.7875  vf 0.7350\n",
      "ANOVA K150  epoch 022  tl 0.6139  vl 0.5203  va 0.7895  vf 0.7303\n",
      "ANOVA K150  epoch 023  tl 0.6053  vl 0.4811  va 0.8129  vf 0.7644\n",
      "ANOVA K150  epoch 024  tl 0.5939  vl 0.5249  va 0.7856  vf 0.7559\n",
      "ANOVA K150  epoch 025  tl 0.5931  vl 0.4744  va 0.8187  vf 0.7663\n",
      "ANOVA K150  epoch 026  tl 0.5530  vl 0.4736  va 0.8109  vf 0.7582\n",
      "ANOVA K150  epoch 027  tl 0.5538  vl 0.4613  va 0.8207  vf 0.7581\n",
      "ANOVA K150  epoch 028  tl 0.5405  vl 0.4513  va 0.8187  vf 0.7563\n",
      "ANOVA K150  epoch 029  tl 0.5277  vl 0.5649  va 0.7641  vf 0.7206\n",
      "ANOVA K150  epoch 030  tl 0.6101  vl 0.4448  va 0.8246  vf 0.7766\n",
      "ANOVA K150  epoch 031  tl 0.5238  vl 0.4468  va 0.8109  vf 0.7481\n",
      "ANOVA K150  epoch 032  tl 0.5253  vl 0.4282  va 0.8324  vf 0.7833\n",
      "ANOVA K150  epoch 033  tl 0.5297  vl 0.4373  va 0.8226  vf 0.7653\n",
      "ANOVA K150  epoch 034  tl 0.5750  vl 0.4335  va 0.8343  vf 0.7676\n",
      "ANOVA K150  epoch 035  tl 0.5212  vl 0.4227  va 0.8480  vf 0.7972\n",
      "ANOVA K150  epoch 036  tl 0.5449  vl 0.4493  va 0.8187  vf 0.7558\n",
      "ANOVA K150  epoch 037  tl 0.4871  vl 0.4041  va 0.8441  vf 0.7783\n",
      "ANOVA K150  epoch 038  tl 0.4972  vl 0.3784  va 0.8480  vf 0.7917\n",
      "ANOVA K150  epoch 039  tl 0.4588  vl 0.3680  va 0.8635  vf 0.8037\n",
      "ANOVA K150  epoch 040  tl 0.4557  vl 0.3842  va 0.8558  vf 0.8034\n",
      "ANOVA K150  epoch 041  tl 0.4608  vl 0.3721  va 0.8558  vf 0.7864\n",
      "ANOVA K150  epoch 042  tl 0.4588  vl 0.3772  va 0.8713  vf 0.8757\n",
      "ANOVA K150  epoch 043  tl 0.4462  vl 0.3555  va 0.8596  vf 0.8697\n",
      "ANOVA K150  epoch 044  tl 0.4644  vl 0.3770  va 0.8538  vf 0.8383\n",
      "ANOVA K150  epoch 045  tl 0.4567  vl 0.3327  va 0.8869  vf 0.8837\n",
      "ANOVA K150  epoch 046  tl 0.4308  vl 0.3586  va 0.8733  vf 0.8312\n",
      "ANOVA K150  epoch 047  tl 0.4478  vl 0.3362  va 0.8733  vf 0.8058\n",
      "ANOVA K150  epoch 048  tl 0.4243  vl 0.3372  va 0.8850  vf 0.8898\n",
      "ANOVA K150  epoch 049  tl 0.4081  vl 0.3309  va 0.8850  vf 0.8784\n",
      "ANOVA K150  epoch 050  tl 0.4179  vl 0.3361  va 0.8733  vf 0.8648\n",
      "ANOVA K150  epoch 051  tl 0.4410  vl 0.3562  va 0.8791  vf 0.8949\n",
      "ANOVA K150  epoch 052  tl 0.4721  vl 0.3411  va 0.8830  vf 0.8771\n",
      "ANOVA K150  epoch 053  tl 0.4197  vl 0.3385  va 0.8869  vf 0.8946\n",
      "ANOVA K150  epoch 054  tl 0.3901  vl 0.3083  va 0.8947  vf 0.8860\n",
      "ANOVA K150  epoch 055  tl 0.3866  vl 0.3291  va 0.8713  vf 0.8869\n",
      "ANOVA K150  epoch 056  tl 0.3820  vl 0.3228  va 0.8869  vf 0.8825\n",
      "ANOVA K150  epoch 057  tl 0.4177  vl 0.3157  va 0.8752  vf 0.8642\n",
      "ANOVA K150  epoch 058  tl 0.3816  vl 0.3100  va 0.8908  vf 0.8850\n",
      "ANOVA K150  epoch 059  tl 0.3820  vl 0.3033  va 0.8869  vf 0.8819\n",
      "ANOVA K150  epoch 060  tl 0.3788  vl 0.3112  va 0.8908  vf 0.8781\n",
      "ANOVA K150  epoch 061  tl 0.3781  vl 0.3031  va 0.8869  vf 0.8824\n",
      "ANOVA K150  epoch 062  tl 0.3677  vl 0.2976  va 0.8908  vf 0.8836\n",
      "ANOVA K150  epoch 063  tl 0.3649  vl 0.2953  va 0.8908  vf 0.8836\n",
      "ANOVA K150  epoch 064  tl 0.3594  vl 0.2974  va 0.8869  vf 0.8797\n",
      "ANOVA K150  epoch 065  tl 0.3607  vl 0.2932  va 0.9025  vf 0.9066\n",
      "ANOVA K150  epoch 066  tl 0.3567  vl 0.2932  va 0.8947  vf 0.8970\n",
      "ANOVA K150  epoch 067  tl 0.3527  vl 0.2931  va 0.8928  vf 0.8985\n",
      "ANOVA K150  epoch 068  tl 0.3575  vl 0.2936  va 0.8869  vf 0.8941\n",
      "ANOVA K150  epoch 069  tl 0.3553  vl 0.2867  va 0.8908  vf 0.8948\n",
      "ANOVA K150  epoch 070  tl 0.3529  vl 0.2923  va 0.8967  vf 0.9055\n",
      "ANOVA K150  epoch 071  tl 0.3560  vl 0.3045  va 0.8908  vf 0.8880\n",
      "ANOVA K150  epoch 072  tl 0.3620  vl 0.2876  va 0.9006  vf 0.9077\n",
      "ANOVA K150  epoch 073  tl 0.3412  vl 0.2846  va 0.9006  vf 0.9078\n",
      "ANOVA K150  epoch 074  tl 0.3509  vl 0.2871  va 0.9006  vf 0.9010\n",
      "ANOVA K150  epoch 075  tl 0.3464  vl 0.2861  va 0.9025  vf 0.9007\n",
      "ANOVA K150  epoch 076  tl 0.3490  vl 0.2812  va 0.8986  vf 0.8961\n",
      "ANOVA K150  epoch 077  tl 0.3507  vl 0.2832  va 0.8947  vf 0.8914\n",
      "ANOVA K150  epoch 078  tl 0.3406  vl 0.2868  va 0.8908  vf 0.8783\n",
      "ANOVA K150  epoch 079  tl 0.3424  vl 0.2866  va 0.8967  vf 0.9044\n",
      "ANOVA K150  epoch 080  tl 0.3470  vl 0.2816  va 0.8967  vf 0.8968\n",
      "ANOVA K150  epoch 081  tl 0.3500  vl 0.2801  va 0.8967  vf 0.8848\n",
      "ANOVA K150  epoch 082  tl 0.3406  vl 0.2794  va 0.8967  vf 0.8873\n",
      "ANOVA K150  epoch 083  tl 0.3354  vl 0.2800  va 0.8928  vf 0.8986\n",
      "ANOVA K150  epoch 084  tl 0.3351  vl 0.2782  va 0.8967  vf 0.8938\n",
      "ANOVA K150  epoch 085  tl 0.3383  vl 0.2819  va 0.9025  vf 0.9006\n",
      "ANOVA K150  epoch 086  tl 0.3414  vl 0.2762  va 0.9025  vf 0.9012\n",
      "ANOVA K150  epoch 087  tl 0.3383  vl 0.2775  va 0.9025  vf 0.9035\n",
      "ANOVA K150  epoch 088  tl 0.3280  vl 0.2753  va 0.9025  vf 0.9010\n",
      "ANOVA K150  epoch 089  tl 0.3329  vl 0.2777  va 0.8908  vf 0.8916\n",
      "ANOVA K150  epoch 090  tl 0.3348  vl 0.2841  va 0.8967  vf 0.8870\n",
      "ANOVA K150  epoch 091  tl 0.3382  vl 0.2794  va 0.8967  vf 0.9079\n",
      "ANOVA K150  epoch 092  tl 0.3307  vl 0.2713  va 0.8986  vf 0.8963\n",
      "ANOVA K150  epoch 093  tl 0.3289  vl 0.2752  va 0.8947  vf 0.8941\n",
      "ANOVA K150  epoch 094  tl 0.3318  vl 0.2731  va 0.8947  vf 0.8940\n",
      "ANOVA K150  epoch 095  tl 0.3339  vl 0.2753  va 0.8986  vf 0.8962\n",
      "ANOVA K150  epoch 096  tl 0.3285  vl 0.2779  va 0.9025  vf 0.9100\n",
      "ANOVA K150  epoch 097  tl 0.3296  vl 0.2737  va 0.8986  vf 0.9069\n",
      "ANOVA K150  epoch 098  tl 0.3304  vl 0.2764  va 0.8986  vf 0.8947\n",
      "ANOVA K150  epoch 099  tl 0.3295  vl 0.2741  va 0.8928  vf 0.8901\n",
      "ANOVA K150  epoch 100  tl 0.3260  vl 0.2728  va 0.9045  vf 0.9067\n",
      "Test accuracy on ANOVA bands 0.9\n",
      "Test kappa 0.8859\n",
      "Test f1 macro 0.9031\n",
      "\n",
      "Classification report on test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.9000    1.0000    0.9474         9\n",
      "     class_2     0.8989    0.8706    0.8845       286\n",
      "     class_3     0.9306    0.8072    0.8645       166\n",
      "     class_4     0.8478    0.8298    0.8387        47\n",
      "     class_5     0.9271    0.9175    0.9223        97\n",
      "     class_6     0.9236    0.9932    0.9571       146\n",
      "     class_7     0.7143    1.0000    0.8333         5\n",
      "     class_8     0.9794    0.9896    0.9845        96\n",
      "     class_9     1.0000    1.0000    1.0000         4\n",
      "    class_10     0.8454    0.9021    0.8728       194\n",
      "    class_11     0.8810    0.8900    0.8855       491\n",
      "    class_12     0.8960    0.9412    0.9180       119\n",
      "    class_13     0.9535    1.0000    0.9762        41\n",
      "    class_14     0.9248    0.9723    0.9480       253\n",
      "    class_15     0.8704    0.6104    0.7176        77\n",
      "    class_16     0.8571    0.9474    0.9000        19\n",
      "\n",
      "    accuracy                         0.9000      2050\n",
      "   macro avg     0.8969    0.9170    0.9031      2050\n",
      "weighted avg     0.9002    0.9000    0.8985      2050\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at outputs/runs_mlp/mlp_anova_top150_best.pth\n"
     ]
    }
   ],
   "source": [
    "# This cell trains the plain MLP on the top ANOVA bands and reports results\n",
    "\n",
    "import numpy as np                                                                                               # import numpy for arrays\n",
    "import torch                                                                                                     # import torch for model work\n",
    "import matplotlib.pyplot as plt                                                                                  # import matplotlib for plots\n",
    "from pathlib import Path                                                                                         # import Path for file paths\n",
    "from sklearn.metrics import classification_report                                                                # import the report printer\n",
    "\n",
    "# Choose how many top bands to use\n",
    "K_TOP = 150                                                                                                      # number of bands to keep\n",
    "\n",
    "# Read the ANOVA ranking table if the sorted table is not in memory\n",
    "anova_csv = FIGS / \"anova_band_ranking_full.csv\"                                                                 # path where we saved the full ANOVA table\n",
    "if \"tab_anova_sorted\" not in globals():                                                                          # check if the table exists in memory\n",
    "    import pandas as pd                                                                                          # import pandas to read csv\n",
    "    tab_anova_sorted = pd.read_csv(anova_csv)                                                                    # read the table from disk\n",
    "\n",
    "# Pick the top K bands by ANOVA rank\n",
    "bands_sel = np.array(tab_anova_sorted.sort_values(\"rank_F\")[\"band\"].values[:K_TOP], dtype=int)                   # band indices\n",
    "bands_sel_sorted = np.sort(bands_sel)                                                                            # sorted copy for nice display\n",
    "print(\"Using top ANOVA bands\", bands_sel_sorted.tolist())                                                        # show selected bands\n",
    "\n",
    "# Slice the cube to only the selected bands\n",
    "cube_k = cube[:, :, bands_sel_sorted]                                                                            # reduce cube to K bands\n",
    "Bk = cube_k.shape[2]                                                                                             # new input dimension\n",
    "\n",
    "# Build fresh datasets on the reduced cube\n",
    "class PixelDatasetBands(PixelDataset):                                                                           # subclass to reuse the parent logic\n",
    "    \"\"\"Dataset that reads spectra from a reduced band cube\"\"\"                                                    # docstring\n",
    "    def __init__(self, cube_red: np.ndarray, labels_map: np.ndarray, mask_map: np.ndarray):                      # init method\n",
    "        super().__init__(cube_red, labels_map, mask_map)                                                         # call parent to fill X and y\n",
    "\n",
    "ds_train_k = PixelDatasetBands(cube_k, labels, mask_train)                                                       # train dataset with K bands\n",
    "ds_val_k = PixelDatasetBands(cube_k, labels, mask_val)                                                           # val dataset with K bands\n",
    "ds_test_k = PixelDatasetBands(cube_k, labels, mask_test)                                                         # test dataset with K bands\n",
    "\n",
    "# Make loaders\n",
    "BATCH = 256                                                                                                      # batch size\n",
    "dl_train_k = DataLoader(ds_train_k, batch_size=BATCH, shuffle=True, drop_last=False)                             # train loader\n",
    "dl_val_k = DataLoader(ds_val_k, batch_size=BATCH, shuffle=False, drop_last=False)                                # val loader\n",
    "dl_test_k = DataLoader(ds_test_k, batch_size=BATCH, shuffle=False, drop_last=False)                              # test loader\n",
    "\n",
    "# Define the same MLP with the new input size\n",
    "model_k = SpectralMLP(in_dim=Bk, hidden1=256, hidden2=128, num_classes=num_classes, p_drop=0.3).to(DEVICE)       # model\n",
    "print(\"Params with K bands\", sum(p.numel() for p in model_k.parameters()))                                       # parameter count\n",
    "\n",
    "# Set up loss optimizer and scheduler\n",
    "criterion_k = nn.CrossEntropyLoss()                                                                              # plain cross entropy\n",
    "optimizer_k = optim.Adam(model_k.parameters(), lr=1e-3, weight_decay=1e-4)                                       # adam optimizer\n",
    "scheduler_k = optim.lr_scheduler.ReduceLROnPlateau(optimizer_k, mode=\"min\", factor=0.5, patience=3, verbose=True)# scheduler\n",
    "\n",
    "# Train with early stopping on validation loss\n",
    "EPOCHS = 100                                                                                                     # max epochs\n",
    "PATIENCE = 10                                                                                                    # early stop patience\n",
    "best_val_loss = float(\"inf\")                                                                                     # track best val loss\n",
    "best_state_k = None                                                                                              # best weights\n",
    "bad_epochs = 0                                                                                                   # patience counter\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):                                                                                  # loop epochs\n",
    "    model_k.train()                                                                                              # train mode\n",
    "    tr_loss_sum = 0.0                                                                                            # sum of train loss\n",
    "    tr_count = 0                                                                                                 # count of samples\n",
    "    for xb, yb in dl_train_k:                                                                                    # loop train batches\n",
    "        xb = xb.to(DEVICE)                                                                                       # move features\n",
    "        yb = yb.to(DEVICE)                                                                                       # move labels\n",
    "        optimizer_k.zero_grad(set_to_none=True)                                                                  # clear grads\n",
    "        logits = model_k(xb)                                                                                     # forward pass\n",
    "        loss = criterion_k(logits, yb)                                                                           # compute loss\n",
    "        loss.backward()                                                                                          # backward pass\n",
    "        optimizer_k.step()                                                                                       # update weights\n",
    "        tr_loss_sum += loss.item() * xb.size(0)                                                                  # add batch loss\n",
    "        tr_count += xb.size(0)                                                                                   # add batch count\n",
    "    tr_loss = tr_loss_sum / max(1, tr_count)                                                                     # average train loss\n",
    "\n",
    "    model_k.eval()                                                                                               # eval mode\n",
    "    with torch.no_grad():                                                                                        # no grads\n",
    "        va_loss_sum = 0.0                                                                                        # sum val loss\n",
    "        va_count = 0                                                                                             # count val samples\n",
    "        v_logits = []                                                                                            # store logits\n",
    "        v_targets = []                                                                                           # store targets\n",
    "        for xb, yb in dl_val_k:                                                                                  # loop val batches\n",
    "            xb = xb.to(DEVICE)                                                                                   # move features\n",
    "            yb = yb.to(DEVICE)                                                                                   # move labels\n",
    "            logits = model_k(xb)                                                                                 # forward pass\n",
    "            loss = criterion_k(logits, yb)                                                                       # val loss\n",
    "            va_loss_sum += loss.item() * xb.size(0)                                                              # add loss\n",
    "            va_count += xb.size(0)                                                                               # add count\n",
    "            v_logits.append(logits)                                                                              # keep logits\n",
    "            v_targets.append(yb)                                                                                 # keep labels\n",
    "        val_loss_k = va_loss_sum / max(1, va_count)                                                              # average val loss\n",
    "        v_logits = torch.cat(v_logits, 0)                                                                        # stack logits\n",
    "        v_targets = torch.cat(v_targets, 0)                                                                      # stack labels\n",
    "        val_metrics_k = metrics_from_logits(v_logits, v_targets, num_classes)                                    # compute metrics\n",
    "\n",
    "    scheduler_k.step(val_loss_k)                                                                                 # step scheduler\n",
    "    print(f\"ANOVA K{K_TOP}  epoch {ep:03d}  tl {tr_loss:.4f}  vl {val_loss_k:.4f}  va {val_metrics_k['acc']:.4f}  vf {val_metrics_k['f1']:.4f}\")  # progress\n",
    "\n",
    "    if val_loss_k < best_val_loss:                                                                               # check improvement\n",
    "        best_val_loss = val_loss_k                                                                               # update best\n",
    "        best_state_k = {k: v.cpu().clone() for k, v in model_k.state_dict().items()}                             # snapshot weights\n",
    "        bad_epochs = 0                                                                                           # reset patience\n",
    "        best_epoch_k = ep                                                                                        # store best epoch\n",
    "    else:                                                                                                        # no improvement\n",
    "        bad_epochs += 1                                                                                          # count bad epoch\n",
    "        if bad_epochs >= PATIENCE:                                                                               # early stop\n",
    "            print(\"Early stop at\", ep, \"best epoch\", best_epoch_k)                                               # message\n",
    "            break                                                                                                # stop loop\n",
    "\n",
    "# Load best weights and evaluate on test\n",
    "model_k.load_state_dict(best_state_k)                                                                            # load best weights\n",
    "model_k.to(DEVICE).eval()                                                                                        # eval mode\n",
    "with torch.no_grad():                                                                                            # no grads\n",
    "    t_logits = []                                                                                                # test logits list\n",
    "    t_targets = []                                                                                               # test targets list\n",
    "    for xb, yb in dl_test_k:                                                                                     # loop test batches\n",
    "        xb = xb.to(DEVICE)                                                                                       # move features\n",
    "        yb = yb.to(DEVICE)                                                                                       # move labels\n",
    "        t_logits.append(model_k(xb))                                                                             # forward\n",
    "        t_targets.append(yb)                                                                                     # keep labels\n",
    "    t_logits = torch.cat(t_logits, 0)                                                                            # stack logits\n",
    "    t_targets = torch.cat(t_targets, 0)                                                                          # stack labels\n",
    "    tm_k = metrics_from_logits(t_logits, t_targets, num_classes)                                                 # compute metrics\n",
    "\n",
    "# Print test accuracy and report\n",
    "print(\"Test accuracy on ANOVA bands\", round(tm_k[\"acc\"], 4))                                                     # accuracy\n",
    "print(\"Test kappa\", round(tm_k[\"kappa\"], 4))                                                                     # kappa\n",
    "print(\"Test f1 macro\", round(tm_k[\"f1\"], 4))                                                                     # f1 macro\n",
    "\n",
    "y_true_test = t_targets.cpu().numpy()                                                                            # true ids\n",
    "y_pred_test = t_logits.argmax(1).cpu().numpy()                                                                   # predicted ids\n",
    "target_names = [f\"class_{i}\" for i in range(1, num_classes + 1)]                                                 # class names\n",
    "print(\"\\nClassification report on test\")                                                                         # header\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=target_names, digits=4, zero_division=0))     # report\n",
    "\n",
    "# Plot and save the test confusion matrix\n",
    "cm_k = tm_k[\"cm\"]                                                                                                # confusion matrix\n",
    "plt.figure(figsize=(6, 5))                                                                                       # figure\n",
    "plt.imshow(cm_k, cmap=\"Greens\")                                                                                  # plot matrix\n",
    "plt.title(f\"Confusion matrix test  ANOVA top {K_TOP} bands\")                                                     # title\n",
    "plt.xlabel(\"Predicted\")                                                                                          # x label\n",
    "plt.ylabel(\"True\")                                                                                               # y label\n",
    "plt.colorbar()                                                                                                   # color bar\n",
    "plt.tight_layout()                                                                                               # tidy layout\n",
    "plt.savefig(FIGS / f\"mlp_anova_top{K_TOP}_confusion_test.png\", dpi=150)                                          # save figure\n",
    "plt.show()                                                                                                       # show figure\n",
    "\n",
    "# Save the checkpoint for this run\n",
    "RUNS.mkdir(parents=True, exist_ok=True)                                                                          # ensure runs folder exists\n",
    "ckpt_anova = RUNS / f\"mlp_anova_top{K_TOP}_best.pth\"                                                             # checkpoint path\n",
    "torch.save({\"state_dict\": best_state_k, \"num_classes\": num_classes, \"in_dim\": Bk, \"bands_sel\": bands_sel_sorted}, ckpt_anova) # save weights and bands\n",
    "print(\"Saved checkpoint at\", ckpt_anova.as_posix())                                                              # done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f773814-f399-4133-8779-2d01efe6d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed 42\n"
     ]
    }
   ],
   "source": [
    "# Get a seed for PCA. Read from the saved config if it exists. Fall back to 42.\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "CFG_PATH = Path(\"outputs/artifacts_ip/config_clean_preprocess.json\")\n",
    "if CFG_PATH.exists():\n",
    "    with open(CFG_PATH, \"r\") as f:\n",
    "        _cfg = json.load(f)\n",
    "    SPLIT_SEED = int(_cfg.get(\"split_seed\", 42))\n",
    "else:\n",
    "    SPLIT_SEED = 42\n",
    "\n",
    "print(\"Using seed\", SPLIT_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c05c0b-bcbc-4b22-9a4e-509c6d69ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 PCA components out of 20\n",
      "Cumulative explained variance for these components 0.9765\n",
      "Params 40336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA K20  epoch 001  tl 1.7846  vl 1.3208  va 0.5302  vf 0.2992\n",
      "PCA K20  epoch 002  tl 1.3469  vl 1.1744  va 0.5653  vf 0.3781\n",
      "PCA K20  epoch 003  tl 1.2235  vl 1.0870  va 0.5867  vf 0.4025\n",
      "PCA K20  epoch 004  tl 1.1377  vl 1.0067  va 0.6277  vf 0.4501\n",
      "PCA K20  epoch 005  tl 1.0624  vl 0.9541  va 0.6238  vf 0.4640\n",
      "PCA K20  epoch 006  tl 1.0022  vl 0.9072  va 0.6511  vf 0.4893\n",
      "PCA K20  epoch 007  tl 0.9603  vl 0.8516  va 0.6784  vf 0.5391\n",
      "PCA K20  epoch 008  tl 0.9053  vl 0.8091  va 0.6920  vf 0.6250\n",
      "PCA K20  epoch 009  tl 0.8682  vl 0.7787  va 0.7057  vf 0.6380\n",
      "PCA K20  epoch 010  tl 0.8355  vl 0.7499  va 0.7193  vf 0.6522\n",
      "PCA K20  epoch 011  tl 0.8111  vl 0.7158  va 0.7329  vf 0.6689\n",
      "PCA K20  epoch 012  tl 0.7946  vl 0.7143  va 0.7349  vf 0.6660\n",
      "PCA K20  epoch 013  tl 0.7613  vl 0.6883  va 0.7407  vf 0.6638\n",
      "PCA K20  epoch 014  tl 0.7461  vl 0.6782  va 0.7349  vf 0.6666\n",
      "PCA K20  epoch 015  tl 0.7382  vl 0.6647  va 0.7368  vf 0.6589\n",
      "PCA K20  epoch 016  tl 0.7191  vl 0.6499  va 0.7524  vf 0.6746\n",
      "PCA K20  epoch 017  tl 0.6987  vl 0.6294  va 0.7602  vf 0.6810\n",
      "PCA K20  epoch 018  tl 0.6911  vl 0.6217  va 0.7700  vf 0.6865\n",
      "PCA K20  epoch 019  tl 0.6789  vl 0.6311  va 0.7641  vf 0.6803\n",
      "PCA K20  epoch 020  tl 0.6767  vl 0.6079  va 0.7563  vf 0.6803\n",
      "PCA K20  epoch 021  tl 0.6669  vl 0.6110  va 0.7641  vf 0.6839\n",
      "PCA K20  epoch 022  tl 0.6825  vl 0.5942  va 0.7797  vf 0.7001\n",
      "PCA K20  epoch 023  tl 0.6604  vl 0.6014  va 0.7719  vf 0.6905\n",
      "PCA K20  epoch 024  tl 0.6422  vl 0.5994  va 0.7836  vf 0.7045\n",
      "PCA K20  epoch 025  tl 0.6383  vl 0.5885  va 0.7856  vf 0.6980\n",
      "PCA K20  epoch 026  tl 0.6318  vl 0.5729  va 0.7836  vf 0.6996\n",
      "PCA K20  epoch 027  tl 0.6026  vl 0.5674  va 0.7778  vf 0.7335\n",
      "PCA K20  epoch 028  tl 0.6064  vl 0.5710  va 0.7953  vf 0.7513\n",
      "PCA K20  epoch 029  tl 0.6121  vl 0.5649  va 0.7836  vf 0.6974\n",
      "PCA K20  epoch 030  tl 0.5943  vl 0.5546  va 0.7914  vf 0.7085\n",
      "PCA K20  epoch 031  tl 0.5932  vl 0.5493  va 0.7953  vf 0.7466\n",
      "PCA K20  epoch 032  tl 0.5863  vl 0.5528  va 0.7992  vf 0.7489\n",
      "PCA K20  epoch 033  tl 0.5889  vl 0.5490  va 0.7836  vf 0.7430\n",
      "PCA K20  epoch 034  tl 0.5849  vl 0.5441  va 0.7953  vf 0.7478\n",
      "PCA K20  epoch 035  tl 0.5793  vl 0.5576  va 0.7934  vf 0.7504\n",
      "PCA K20  epoch 036  tl 0.5657  vl 0.5463  va 0.7953  vf 0.7069\n",
      "PCA K20  epoch 037  tl 0.5598  vl 0.5408  va 0.7895  vf 0.7014\n",
      "PCA K20  epoch 038  tl 0.5545  vl 0.5393  va 0.7953  vf 0.7105\n",
      "PCA K20  epoch 039  tl 0.5540  vl 0.5276  va 0.8090  vf 0.7172\n",
      "PCA K20  epoch 040  tl 0.5561  vl 0.5249  va 0.8070  vf 0.7597\n",
      "PCA K20  epoch 041  tl 0.5446  vl 0.5205  va 0.8090  vf 0.7580\n",
      "PCA K20  epoch 042  tl 0.5388  vl 0.5292  va 0.7992  vf 0.7509\n",
      "PCA K20  epoch 043  tl 0.5419  vl 0.5269  va 0.8070  vf 0.7578\n",
      "PCA K20  epoch 044  tl 0.5374  vl 0.5123  va 0.8070  vf 0.7542\n",
      "PCA K20  epoch 045  tl 0.5410  vl 0.5119  va 0.8090  vf 0.7158\n",
      "PCA K20  epoch 046  tl 0.5242  vl 0.5204  va 0.7934  vf 0.7347\n",
      "PCA K20  epoch 047  tl 0.5405  vl 0.5206  va 0.8109  vf 0.7612\n",
      "PCA K20  epoch 048  tl 0.5349  vl 0.5118  va 0.8070  vf 0.7577\n",
      "PCA K20  epoch 049  tl 0.5276  vl 0.5202  va 0.7973  vf 0.7531\n",
      "PCA K20  epoch 050  tl 0.5263  vl 0.5184  va 0.8109  vf 0.7574\n",
      "PCA K20  epoch 051  tl 0.5245  vl 0.5107  va 0.8012  vf 0.7470\n",
      "PCA K20  epoch 052  tl 0.5095  vl 0.5073  va 0.8129  vf 0.7625\n",
      "PCA K20  epoch 053  tl 0.5126  vl 0.5029  va 0.8070  vf 0.7589\n",
      "PCA K20  epoch 054  tl 0.5094  vl 0.5032  va 0.8070  vf 0.7145\n",
      "PCA K20  epoch 055  tl 0.5090  vl 0.4961  va 0.8070  vf 0.7482\n",
      "PCA K20  epoch 056  tl 0.5128  vl 0.4997  va 0.8051  vf 0.7546\n",
      "PCA K20  epoch 057  tl 0.4999  vl 0.5010  va 0.8109  vf 0.7528\n",
      "PCA K20  epoch 058  tl 0.4950  vl 0.4966  va 0.8129  vf 0.7584\n",
      "PCA K20  epoch 059  tl 0.5011  vl 0.5018  va 0.8109  vf 0.7598\n",
      "PCA K20  epoch 060  tl 0.4963  vl 0.4959  va 0.8070  vf 0.7588\n",
      "PCA K20  epoch 061  tl 0.4923  vl 0.4922  va 0.8051  vf 0.7553\n",
      "PCA K20  epoch 062  tl 0.4910  vl 0.4909  va 0.8168  vf 0.7641\n",
      "PCA K20  epoch 063  tl 0.4816  vl 0.4894  va 0.8168  vf 0.7635\n",
      "PCA K20  epoch 064  tl 0.4796  vl 0.4941  va 0.8148  vf 0.7635\n",
      "PCA K20  epoch 065  tl 0.4788  vl 0.4849  va 0.8168  vf 0.7646\n",
      "PCA K20  epoch 066  tl 0.4841  vl 0.4842  va 0.8187  vf 0.7673\n",
      "PCA K20  epoch 067  tl 0.4784  vl 0.4843  va 0.8168  vf 0.7647\n",
      "PCA K20  epoch 068  tl 0.4725  vl 0.4840  va 0.8168  vf 0.7628\n",
      "PCA K20  epoch 069  tl 0.4702  vl 0.4823  va 0.8226  vf 0.7680\n",
      "PCA K20  epoch 070  tl 0.4729  vl 0.4845  va 0.8246  vf 0.7685\n",
      "PCA K20  epoch 071  tl 0.4725  vl 0.4827  va 0.8265  vf 0.7704\n",
      "PCA K20  epoch 072  tl 0.4709  vl 0.4819  va 0.8226  vf 0.7643\n",
      "PCA K20  epoch 073  tl 0.4744  vl 0.4819  va 0.8148  vf 0.7606\n",
      "PCA K20  epoch 074  tl 0.4666  vl 0.4753  va 0.8207  vf 0.7569\n",
      "PCA K20  epoch 075  tl 0.4731  vl 0.4740  va 0.8168  vf 0.7664\n",
      "PCA K20  epoch 076  tl 0.4703  vl 0.4779  va 0.8187  vf 0.7655\n",
      "PCA K20  epoch 077  tl 0.4666  vl 0.4802  va 0.8148  vf 0.7612\n",
      "PCA K20  epoch 078  tl 0.4713  vl 0.4763  va 0.8226  vf 0.7671\n",
      "PCA K20  epoch 079  tl 0.4686  vl 0.4758  va 0.8148  vf 0.7601\n",
      "PCA K20  epoch 080  tl 0.4662  vl 0.4767  va 0.8168  vf 0.7628\n",
      "PCA K20  epoch 081  tl 0.4601  vl 0.4734  va 0.8109  vf 0.7582\n",
      "PCA K20  epoch 082  tl 0.4507  vl 0.4754  va 0.8129  vf 0.7582\n",
      "PCA K20  epoch 083  tl 0.4544  vl 0.4732  va 0.8090  vf 0.7570\n",
      "PCA K20  epoch 084  tl 0.4554  vl 0.4700  va 0.8168  vf 0.7601\n",
      "PCA K20  epoch 085  tl 0.4499  vl 0.4715  va 0.8187  vf 0.7628\n",
      "PCA K20  epoch 086  tl 0.4543  vl 0.4735  va 0.8207  vf 0.7632\n",
      "PCA K20  epoch 087  tl 0.4482  vl 0.4681  va 0.8168  vf 0.7619\n",
      "PCA K20  epoch 088  tl 0.4566  vl 0.4693  va 0.8246  vf 0.7692\n",
      "PCA K20  epoch 089  tl 0.4505  vl 0.4717  va 0.8187  vf 0.7643\n",
      "PCA K20  epoch 090  tl 0.4463  vl 0.4717  va 0.8168  vf 0.7637\n",
      "PCA K20  epoch 091  tl 0.4524  vl 0.4708  va 0.8207  vf 0.7671\n",
      "PCA K20  epoch 092  tl 0.4478  vl 0.4682  va 0.8207  vf 0.7646\n",
      "PCA K20  epoch 093  tl 0.4409  vl 0.4678  va 0.8168  vf 0.7626\n",
      "PCA K20  epoch 094  tl 0.4489  vl 0.4690  va 0.8207  vf 0.7656\n",
      "PCA K20  epoch 095  tl 0.4471  vl 0.4724  va 0.8207  vf 0.7641\n",
      "PCA K20  epoch 096  tl 0.4441  vl 0.4686  va 0.8168  vf 0.7624\n",
      "PCA K20  epoch 097  tl 0.4403  vl 0.4674  va 0.8226  vf 0.7651\n",
      "PCA K20  epoch 098  tl 0.4410  vl 0.4673  va 0.8187  vf 0.7617\n",
      "PCA K20  epoch 099  tl 0.4522  vl 0.4687  va 0.8148  vf 0.7604\n",
      "PCA K20  epoch 100  tl 0.4474  vl 0.4687  va 0.8226  vf 0.7661\n",
      "Test accuracy on PCA features 0.8546\n",
      "Test kappa 0.8341\n",
      "Test f1 macro 0.8619\n",
      "\n",
      "Classification report on test for PCA features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.7273    0.8889    0.8000         9\n",
      "     class_2     0.8041    0.8322    0.8179       286\n",
      "     class_3     0.8561    0.7169    0.7803       166\n",
      "     class_4     0.7347    0.7660    0.7500        47\n",
      "     class_5     0.9462    0.9072    0.9263        97\n",
      "     class_6     0.8924    0.9658    0.9276       146\n",
      "     class_7     1.0000    1.0000    1.0000         5\n",
      "     class_8     0.9694    0.9896    0.9794        96\n",
      "     class_9     1.0000    0.7500    0.8571         4\n",
      "    class_10     0.7727    0.8763    0.8213       194\n",
      "    class_11     0.8498    0.8411    0.8454       491\n",
      "    class_12     0.8241    0.7479    0.7841       119\n",
      "    class_13     0.9318    1.0000    0.9647        41\n",
      "    class_14     0.9114    0.9763    0.9427       253\n",
      "    class_15     0.8200    0.5325    0.6457        77\n",
      "    class_16     0.9474    0.9474    0.9474        19\n",
      "\n",
      "    accuracy                         0.8546      2050\n",
      "   macro avg     0.8742    0.8586    0.8619      2050\n",
      "weighted avg     0.8549    0.8546    0.8523      2050\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at outputs/runs_mlp/mlp_pca_top20_best.pth\n"
     ]
    }
   ],
   "source": [
    "# This cell trains the plain MLP on PCA components and reports results\n",
    "\n",
    "import numpy as np                                                                                                            # import numpy for arrays\n",
    "import pandas as pd                                                                                                           # import pandas for small tables\n",
    "import torch                                                                                                                  # import torch for model work\n",
    "import torch.nn as nn                                                                                                         # import torch modules\n",
    "import torch.optim as optim                                                                                                   # import optimizers\n",
    "import matplotlib.pyplot as plt                                                                                               # import matplotlib for plots\n",
    "from sklearn.decomposition import PCA                                                                                         # import PCA\n",
    "from sklearn.metrics import classification_report                                                                             # import report printer\n",
    "from pathlib import Path                                                                                                      # import Path for file paths\n",
    "\n",
    "# Choose how many PCA components to use\n",
    "K_PCA = 30                                                                                                                    # number of components to keep\n",
    "\n",
    "# Try to load PCA artifacts produced by notebook one\n",
    "pca_cube_path = ARTIFACTS / \"cube_pca.npy\"                                                                                    # path to PCA cube\n",
    "pca_obj_path = ARTIFACTS / \"pca.pkl\"                                                                                          # path to PCA object\n",
    "need_fit_pca_now = not pca_cube_path.exists()                                                                                 # check if we need to fit PCA now\n",
    "\n",
    "if not need_fit_pca_now:                                                                                                      # if PCA cube exists\n",
    "    cube_pca_full = np.load(pca_cube_path)                                                                                    # load full PCA cube of shape H W K_full\n",
    "    try:                                                                                                                      # try to read explained variance if saved\n",
    "        evr = np.load(ARTIFACTS / \"pca_explained_variance_ratio.npy\")                                                         # load explained variance ratio\n",
    "    except Exception:                                                                                                         # if not found\n",
    "        evr = None                                                                                                            # set to none\n",
    "else:                                                                                                                         # need to fit PCA now using normalized cube\n",
    "    print(\"PCA artifacts not found, fitting PCA now on train pixels\")                                                         # message\n",
    "    H, W, B = cube.shape                                                                                                      # read shape from normalized cube in memory\n",
    "    X_train_pixels = cube[mask_train].astype(np.float32)                                                                      # gather train pixels as N by B\n",
    "    K_fit = max(K_PCA, 1)                                                                                                     # ensure at least one component\n",
    "    pca_model = PCA(n_components=K_fit, svd_solver=\"auto\", whiten=False, random_state=SPLIT_SEED)\n",
    "    pca_model.fit(X_train_pixels)                                                                                             # fit PCA on train only\n",
    "    evr = pca_model.explained_variance_ratio_                                                                                 # explained variance ratio\n",
    "    X_all = cube.reshape(-1, B)                                                                                               # flatten full image\n",
    "    X_all_pca = pca_model.transform(X_all)                                                                                    # transform all pixels\n",
    "    cube_pca_full = X_all_pca.reshape(H, W, X_all_pca.shape[1])                                                               # reshape back to H W K_full\n",
    "    \n",
    "# save artifacts for reuse\n",
    "    with open(pca_obj_path, \"wb\") as f:                                                                                       # open file for pca object\n",
    "        import pickle as _pickle                                                                                              # local import for pickle\n",
    "        _pickle.dump({\"pca\": pca_model}, f)                                                                                   # save pca object\n",
    "    np.save(pca_cube_path, cube_pca_full.astype(np.float32))                                                                          # save pca cube\n",
    "    np.save(ARTIFACTS / \"pca_explained_variance_ratio.npy\", evr)                                                                      # save variance ratio\n",
    "\n",
    "# Select first K_PCA components\n",
    "K_full = cube_pca_full.shape[2]                                                                                                       # total components available\n",
    "K_use = min(K_PCA, K_full)                                                                                                            # cap by what we have\n",
    "cube_pca = cube_pca_full[:, :, :K_use]                                                                                                # slice first K components\n",
    "print(f\"Using {K_use} PCA components out of {K_full}\")                                                                                # show count\n",
    "if evr is not None:                                                                                                                   # if variance ratio available\n",
    "    cumvar = float(np.cumsum(evr[:K_use])[-1])                                                                                        # cumulative variance\n",
    "    print(\"Cumulative explained variance for these components\", round(cumvar, 4))                                                     # print share\n",
    "\n",
    "# Build datasets over PCA cube\n",
    "class PixelDatasetPCA(torch.utils.data.Dataset):                                                                                      # define dataset for PCA features\n",
    "    \"\"\"Returns PCA feature vector and label for each selected pixel\"\"\"                                                                # docstring\n",
    "    def __init__(self, cube_p: np.ndarray, labels_map: np.ndarray, mask_map: np.ndarray):                                             # init\n",
    "        X = cube_p[mask_map]                                                                                                          # select features for masked pixels\n",
    "        y = labels_map[mask_map]                                                                                                      # select labels for masked pixels\n",
    "        keep = y > 0                                                                                                                  # keep labeled classes only\n",
    "        self.X = X[keep].astype(np.float32)                                                                                           # features as float\n",
    "        self.y = (y[keep].astype(np.int64) - 1)                                                                                       # zero based labels\n",
    "    def __len__(self):                                                                                                                # length\n",
    "        return self.y.shape[0]                                                                                                        # number of items\n",
    "    def __getitem__(self, i):                                                                                                         # get one\n",
    "        return torch.from_numpy(self.X[i]), torch.tensor(self.y[i], dtype=torch.long)                                                 # tensors\n",
    "\n",
    "ds_train_p = PixelDatasetPCA(cube_pca, labels, mask_train)                                                                            # train dataset\n",
    "ds_val_p = PixelDatasetPCA(cube_pca, labels, mask_val)                                                                                # val dataset\n",
    "ds_test_p = PixelDatasetPCA(cube_pca, labels, mask_test)                                                                              # test dataset\n",
    "\n",
    "                                                                                                                                      # Make loaders\n",
    "BATCH = 256                                                                                                                           # batch size\n",
    "dl_train_p = torch.utils.data.DataLoader(ds_train_p, batch_size=BATCH, shuffle=True, drop_last=False)                                 # train loader\n",
    "dl_val_p = torch.utils.data.DataLoader(ds_val_p, batch_size=BATCH, shuffle=False, drop_last=False)                                    # val loader\n",
    "dl_test_p = torch.utils.data.DataLoader(ds_test_p, batch_size=BATCH, shuffle=False, drop_last=False)                                  # test loader\n",
    "\n",
    "                                                                                                                                      # Define the same MLP but with input size equal to K_use\n",
    "class SpectralMLP(nn.Module):                                                                                                         # define model\n",
    "    \"\"\"Two layer MLP for classification of PCA features\"\"\"                                                                            # docstring\n",
    "    def __init__(self, in_dim: int, hidden1: int, hidden2: int, num_classes: int, p_drop: float = 0.3):                               # init\n",
    "        super().__init__()                                                                                                            # parent init\n",
    "        self.net = nn.Sequential(                                                                                                     # layer stack\n",
    "            nn.Linear(in_dim, hidden1),                                                                                               # dense layer one\n",
    "            nn.ReLU(inplace=True),                                                                                                    # activation\n",
    "            nn.Dropout(p_drop),                                                                                                       # dropout\n",
    "            nn.Linear(hidden1, hidden2),                                                                                              # dense layer two\n",
    "            nn.ReLU(inplace=True),                                                                                                    # activation\n",
    "            nn.Dropout(p_drop),                                                                                                       # dropout\n",
    "            nn.Linear(hidden2, num_classes),                                                                                          # output layer\n",
    "        )                                                                                                                             # end stack\n",
    "    def forward(self, x):                                                                                                             # forward pass\n",
    "        return self.net(x)                                                                                                            # run through stack\n",
    "\n",
    "model_p = SpectralMLP(in_dim=K_use, hidden1=256, hidden2=128, num_classes=num_classes, p_drop=0.3).to(DEVICE)                         # model\n",
    "print(\"Params\", sum(p.numel() for p in model_p.parameters()))                                                                         # parameter count\n",
    "\n",
    "                                                                                                                                      # Loss optimizer and scheduler\n",
    "criterion_p = nn.CrossEntropyLoss()                                                                                                   # plain cross entropy\n",
    "optimizer_p = optim.Adam(model_p.parameters(), lr=1e-3, weight_decay=1e-4)                                                            # adam optimizer\n",
    "scheduler_p = optim.lr_scheduler.ReduceLROnPlateau(optimizer_p, mode=\"min\", factor=0.5, patience=3, verbose=True)                     # scheduler\n",
    "\n",
    "                                                                                                                                      # Helper for metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, cohen_kappa_score                      # import metrics\n",
    "def metrics_from_logits(logits: torch.Tensor, targets: torch.Tensor, C: int) -> dict:                                                 # define helper\n",
    "    \"\"\"Return accuracy macro precision macro recall macro f1 kappa and confusion matrix\"\"\"                                            # docstring\n",
    "    preds = logits.argmax(1).cpu().numpy()                                                                                            # predicted ids\n",
    "    true = targets.cpu().numpy()                                                                                                      # true ids\n",
    "    acc = accuracy_score(true, preds)                                                                                                 # accuracy\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true, preds, labels=np.arange(C), average=\"macro\", zero_division=0)            # macro stats\n",
    "    kap = cohen_kappa_score(true, preds)                                                                                              # kappa\n",
    "    cm = confusion_matrix(true, preds, labels=np.arange(C))                                                                           # confusion matrix\n",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"kappa\": kap, \"cm\": cm}                                                   # pack results\n",
    "\n",
    "                                                                                                                                      # Train with early stopping on validation loss\n",
    "EPOCHS = 100                                                                                                                          # max epochs\n",
    "PATIENCE = 10                                                                                                                         # early stopping patience\n",
    "best_val_loss = float(\"inf\")                                                                                                          # best val loss\n",
    "best_state_p = None                                                                                                                   # best weights\n",
    "bad_epochs = 0                                                                                                                        # counter for patience\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):                                                                                                       # loop epochs\n",
    "    model_p.train()                                                                                                                   # train mode\n",
    "    tr_sum = 0.0                                                                                                                      # loss sum\n",
    "    tr_cnt = 0                                                                                                                        # sample count\n",
    "    for xb, yb in dl_train_p:                                                                                                         # train batches\n",
    "        xb = xb.to(DEVICE)                                                                                                            # move features\n",
    "        yb = yb.to(DEVICE)                                                                                                            # move labels\n",
    "        optimizer_p.zero_grad(set_to_none=True)                                                                                       # clear grads\n",
    "        logits = model_p(xb)                                                                                                          # forward\n",
    "        loss = criterion_p(logits, yb)                                                                                                # loss\n",
    "        loss.backward()                                                                                                               # backward\n",
    "        optimizer_p.step()                                                                                                            # step\n",
    "        tr_sum += loss.item() * xb.size(0)                                                                                            # add weighted loss\n",
    "        tr_cnt += xb.size(0)                                                                                                          # add count\n",
    "    tr_loss = tr_sum / max(1, tr_cnt)                                                                                                 # average train loss\n",
    "\n",
    "    model_p.eval()                                                                                                                    # eval mode\n",
    "    with torch.no_grad():                                                                                                             # no grads\n",
    "        va_sum = 0.0                                                                                                                  # val loss sum\n",
    "        va_cnt = 0                                                                                                                    # val count\n",
    "        v_logits = []                                                                                                                 # logits list\n",
    "        v_targets = []                                                                                                                # targets list\n",
    "        for xb, yb in dl_val_p:                                                                                                       # val batches\n",
    "            xb = xb.to(DEVICE)                                                                                                        # move features\n",
    "            yb = yb.to(DEVICE)                                                                                                        # move labels\n",
    "            logits = model_p(xb)                                                                                                      # forward\n",
    "            loss = criterion_p(logits, yb)                                                                                            # loss\n",
    "            va_sum += loss.item() * xb.size(0)                                                                                        # add loss\n",
    "            va_cnt += xb.size(0)                                                                                                      # add count\n",
    "            v_logits.append(logits)                                                                                                   # keep logits\n",
    "            v_targets.append(yb)                                                                                                      # keep targets\n",
    "        val_loss = va_sum / max(1, va_cnt)                                                                                            # average val loss\n",
    "        v_logits = torch.cat(v_logits, 0)                                                                                             # stack logits\n",
    "        v_targets = torch.cat(v_targets, 0)                                                                                           # stack targets\n",
    "        v_metrics = metrics_from_logits(v_logits, v_targets, num_classes)                                                             # compute metrics\n",
    "\n",
    "    scheduler_p.step(val_loss)                                                                                                        # step scheduler\n",
    "    print(f\"PCA K{K_use}  epoch {ep:03d}  tl {tr_loss:.4f}  vl {val_loss:.4f}  va {v_metrics['acc']:.4f}  vf {v_metrics['f1']:.4f}\")  # progress\n",
    "\n",
    "    if val_loss < best_val_loss:                                                                                                      # improvement\n",
    "        best_val_loss = val_loss                                                                                                      # update best loss\n",
    "        best_state_p = {k: v.cpu().clone() for k, v in model_p.state_dict().items()}                                                  # snapshot weights\n",
    "        bad_epochs = 0                                                                                                                # reset patience\n",
    "        best_epoch_p = ep                                                                                                             # best epoch\n",
    "    else:                                                                                                                             # no improvement\n",
    "        bad_epochs += 1                                                                                                               # inc patience\n",
    "        if bad_epochs >= PATIENCE:                                                                                                    # early stop\n",
    "            print(\"Early stop at\", ep, \"best epoch\", best_epoch_p)                                                                    # message\n",
    "            break                                                                                                                     # stop training\n",
    "\n",
    "                                                                                                                                      # Load best model and evaluate on test\n",
    "model_p.load_state_dict(best_state_p)                                                                                                 # load best weights\n",
    "model_p.to(DEVICE).eval()                                                                                                             # eval mode\n",
    "with torch.no_grad():                                                                                                                 # no grads\n",
    "    t_logits = []                                                                                                                     # test logits\n",
    "    t_targets = []                                                                                                                    # test targets\n",
    "    for xb, yb in dl_test_p:                                                                                                          # test batches\n",
    "        xb = xb.to(DEVICE)                                                                                                            # move features\n",
    "        yb = yb.to(DEVICE)                                                                                                            # move labels\n",
    "        t_logits.append(model_p(xb))                                                                                                  # forward\n",
    "        t_targets.append(yb)                                                                                                          # keep labels\n",
    "    t_logits = torch.cat(t_logits, 0)                                                                                                 # stack logits\n",
    "    t_targets = torch.cat(t_targets, 0)                                                                                               # stack targets\n",
    "    tm_p = metrics_from_logits(t_logits, t_targets, num_classes)                                                                      # compute metrics\n",
    "\n",
    "                                                                                                                                      # Print test accuracy kappa and f1 macro\n",
    "print(\"Test accuracy on PCA features\", round(tm_p[\"acc\"], 4))                                                                         # accuracy\n",
    "print(\"Test kappa\", round(tm_p[\"kappa\"], 4))                                                                                          # kappa\n",
    "print(\"Test f1 macro\", round(tm_p[\"f1\"], 4))                                                                                          # f1 macro\n",
    "\n",
    "                                                                                                                                      # Print classification report\n",
    "y_true_test = t_targets.cpu().numpy()                                                                                                 # true ids\n",
    "y_pred_test = t_logits.argmax(1).cpu().numpy()                                                                                        # predicted ids\n",
    "target_names = [f\"class_{i}\" for i in range(1, num_classes + 1)]                                                                      # class names\n",
    "print(\"\\nClassification report on test for PCA features\")                                                                             # header\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=target_names, digits=4, zero_division=0))                          # report\n",
    "\n",
    "                                                                                                                                      # Plot and save test confusion matrix\n",
    "cm_p = tm_p[\"cm\"]                                                                                                                     # confusion matrix\n",
    "plt.figure(figsize=(6, 5))                                                                                                            # figure\n",
    "plt.imshow(cm_p, cmap=\"Greens\")                                                                                                       # plot matrix\n",
    "plt.title(f\"Confusion matrix test  PCA top {K_use} components\")                                                                       # title\n",
    "plt.xlabel(\"Predicted\")                                                                                                               # x label\n",
    "plt.ylabel(\"True\")                                                                                                                    # y label\n",
    "plt.colorbar()                                                                                                                        # color bar\n",
    "plt.tight_layout()                                                                                                                    # tidy layout\n",
    "plt.savefig(FIGS / f\"mlp_pca_top{K_use}_confusion_test.png\", dpi=150)                                                                 # save figure\n",
    "plt.show()                                                                                                                            # show figure\n",
    "\n",
    "                                                                                                                                      # Save checkpoint for this PCA run\n",
    "RUNS.mkdir(parents=True, exist_ok=True)                                                                                               # ensure runs folder exists\n",
    "ckpt_pca = RUNS / f\"mlp_pca_top{K_use}_best.pth\"                                                                                      # checkpoint path\n",
    "torch.save({\"state_dict\": best_state_p, \"num_classes\": num_classes, \"in_dim\": K_use}, ckpt_pca)                                       # save weights\n",
    "print(\"Saved checkpoint at\", ckpt_pca.as_posix())                                                                                     # confirm save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2797672-ce9a-4507-9252-911d0c995e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1  acc 0.9116  f1 0.9007  kappa 0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2  acc 0.9079  f1 0.9111  kappa 0.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3  acc 0.9037  f1 0.9022  kappa 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4  acc 0.9201  f1 0.9115  kappa 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5  acc 0.9225  f1 0.8936  kappa 0.9115\n",
      "\n",
      "CV mean acc 0.9132 std 0.0072\n",
      "CV mean f1 0.9038 std 0.0068\n",
      "CV mean kappa 0.9009 std 0.0081\n"
     ]
    }
   ],
   "source": [
    "# This cell runs 5 fold stratified cross validation on train plus val and keeps test untouched\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score\n",
    "\n",
    "# Build train plus val arrays from your datasets\n",
    "X_tv = np.concatenate([ds_train.X, ds_val.X], axis=0).astype(np.float32)                                                    # features for train plus val\n",
    "y_tv = np.concatenate([ds_train.y, ds_val.y], axis=0).astype(np.int64) - 1                                                  # zero based labels\n",
    "\n",
    "# Helper to compute metrics from logits and targets\n",
    "def metrics_from_logits(logits, targets, C):\n",
    "    preds = logits.argmax(1).cpu().numpy()\n",
    "    true = targets.cpu().numpy()\n",
    "    acc = accuracy_score(true, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true, preds, labels=np.arange(C), average=\"macro\", zero_division=0)\n",
    "    kap = cohen_kappa_score(true, preds)\n",
    "    return acc, f1, kap\n",
    "\n",
    "# Training function for one fold\n",
    "def train_one_fold(X_tr, y_tr, X_va, y_va, in_dim, num_classes, device):\n",
    "    model = SpectralMLP(in_dim=in_dim, hidden1=256, hidden2=128, num_classes=num_classes, p_drop=0.3).to(device)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=3, verbose=False)\n",
    "\n",
    "    dl_tr = DataLoader(TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr)), batch_size=256, shuffle=True)\n",
    "    dl_va = DataLoader(TensorDataset(torch.from_numpy(X_va), torch.from_numpy(y_va)), batch_size=256, shuffle=False)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    for ep in range(1, 101):\n",
    "        model.train()\n",
    "        run = 0.0\n",
    "        n = 0\n",
    "        for xb, yb in dl_tr:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            run += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "        tr_loss = run / max(1, n)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_loss = 0.0\n",
    "            m = 0\n",
    "            all_logits = []\n",
    "            all_tgts = []\n",
    "            for xb, yb in dl_va:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                lg = model(xb)\n",
    "                loss = crit(lg, yb)\n",
    "                v_loss += loss.item() * xb.size(0)\n",
    "                m += xb.size(0)\n",
    "                all_logits.append(lg)\n",
    "                all_tgts.append(yb)\n",
    "            v_loss = v_loss / max(1, m)\n",
    "        sched.step(v_loss)\n",
    "\n",
    "        if v_loss < best_loss:\n",
    "            best_loss = v_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= 10:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_logits = []\n",
    "        all_tgts = []\n",
    "        for xb, yb in dl_va:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            all_logits.append(model(xb))\n",
    "            all_tgts.append(yb)\n",
    "        logits = torch.cat(all_logits, 0)\n",
    "        tgts = torch.cat(all_tgts, 0)\n",
    "    acc, f1, kap = metrics_from_logits(logits, tgts, num_classes)\n",
    "    return acc, f1, kap\n",
    "\n",
    "# Run 5 fold CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, f1s, kaps = [], [], []\n",
    "for fold, (idx_tr, idx_va) in enumerate(skf.split(X_tv, y_tv), 1):\n",
    "    X_tr, y_tr = X_tv[idx_tr], y_tv[idx_tr]\n",
    "    X_va, y_va = X_tv[idx_va], y_tv[idx_va]\n",
    "    acc, f1, kap = train_one_fold(X_tr, y_tr, X_va, y_va, in_dim=X_tv.shape[1], num_classes=num_classes, device=DEVICE)\n",
    "    print(f\"Fold {fold}  acc {acc:.4f}  f1 {f1:.4f}  kappa {kap:.4f}\")\n",
    "    accs.append(acc); f1s.append(f1); kaps.append(kap)\n",
    "\n",
    "print(\"\\nCV mean acc\", np.mean(accs).round(4), \"std\", np.std(accs).round(4))\n",
    "print(\"CV mean f1\", np.mean(f1s).round(4), \"std\", np.std(f1s).round(4))\n",
    "print(\"CV mean kappa\", np.mean(kaps).round(4), \"std\", np.std(kaps).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93ed379-4912-40fe-9375-a1d5891347df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 PCA components out of 20\n",
      "Cumulative explained variance for these components 0.9765\n",
      "Params 40336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA K20  epoch 001  tl 1.7777  vl 1.3171  va 0.5302  vf 0.2687\n",
      "PCA K20  epoch 002  tl 1.3378  vl 1.1590  va 0.5634  vf 0.3754\n",
      "PCA K20  epoch 003  tl 1.1982  vl 1.0675  va 0.5867  vf 0.4259\n",
      "PCA K20  epoch 004  tl 1.1114  vl 0.9771  va 0.6413  vf 0.4740\n",
      "PCA K20  epoch 005  tl 1.0311  vl 0.9145  va 0.6550  vf 0.4918\n",
      "PCA K20  epoch 006  tl 0.9737  vl 0.8588  va 0.6745  vf 0.5295\n",
      "PCA K20  epoch 007  tl 0.9262  vl 0.8229  va 0.6940  vf 0.5609\n",
      "PCA K20  epoch 008  tl 0.8721  vl 0.7724  va 0.7076  vf 0.5811\n",
      "PCA K20  epoch 009  tl 0.8470  vl 0.7411  va 0.7173  vf 0.6558\n",
      "PCA K20  epoch 010  tl 0.8082  vl 0.7173  va 0.7212  vf 0.6479\n",
      "PCA K20  epoch 011  tl 0.7774  vl 0.6964  va 0.7310  vf 0.6538\n",
      "PCA K20  epoch 012  tl 0.7492  vl 0.6731  va 0.7505  vf 0.6792\n",
      "PCA K20  epoch 013  tl 0.7432  vl 0.6635  va 0.7544  vf 0.6745\n",
      "PCA K20  epoch 014  tl 0.7372  vl 0.6607  va 0.7524  vf 0.6832\n",
      "PCA K20  epoch 015  tl 0.7265  vl 0.6555  va 0.7368  vf 0.7107\n",
      "PCA K20  epoch 016  tl 0.6980  vl 0.6350  va 0.7466  vf 0.6699\n",
      "PCA K20  epoch 017  tl 0.6843  vl 0.6280  va 0.7661  vf 0.6907\n",
      "PCA K20  epoch 018  tl 0.6712  vl 0.6144  va 0.7641  vf 0.7365\n",
      "PCA K20  epoch 019  tl 0.6579  vl 0.6108  va 0.7641  vf 0.7275\n",
      "PCA K20  epoch 020  tl 0.6487  vl 0.6189  va 0.7602  vf 0.6911\n",
      "PCA K20  epoch 021  tl 0.6486  vl 0.5963  va 0.7641  vf 0.7235\n",
      "PCA K20  epoch 022  tl 0.6335  vl 0.5929  va 0.7622  vf 0.7277\n",
      "PCA K20  epoch 023  tl 0.6602  vl 0.5986  va 0.7641  vf 0.6952\n",
      "PCA K20  epoch 024  tl 0.6205  vl 0.5843  va 0.7778  vf 0.7410\n",
      "PCA K20  epoch 025  tl 0.6077  vl 0.5729  va 0.7875  vf 0.7089\n",
      "PCA K20  epoch 026  tl 0.6003  vl 0.5610  va 0.7797  vf 0.7441\n",
      "PCA K20  epoch 027  tl 0.5927  vl 0.5627  va 0.7875  vf 0.7430\n",
      "PCA K20  epoch 028  tl 0.5897  vl 0.5503  va 0.7856  vf 0.7424\n",
      "PCA K20  epoch 029  tl 0.5884  vl 0.5524  va 0.7934  vf 0.7508\n",
      "PCA K20  epoch 030  tl 0.5826  vl 0.5602  va 0.7817  vf 0.7377\n",
      "PCA K20  epoch 031  tl 0.5784  vl 0.5476  va 0.7895  vf 0.7470\n",
      "PCA K20  epoch 032  tl 0.5900  vl 0.5539  va 0.7778  vf 0.7386\n",
      "PCA K20  epoch 033  tl 0.5837  vl 0.5509  va 0.7934  vf 0.7486\n",
      "PCA K20  epoch 034  tl 0.5691  vl 0.5461  va 0.7914  vf 0.7526\n",
      "PCA K20  epoch 035  tl 0.5433  vl 0.5538  va 0.7895  vf 0.7041\n",
      "PCA K20  epoch 036  tl 0.5624  vl 0.5535  va 0.7875  vf 0.7492\n",
      "PCA K20  epoch 037  tl 0.5529  vl 0.5405  va 0.7895  vf 0.7471\n",
      "PCA K20  epoch 038  tl 0.5508  vl 0.5340  va 0.7934  vf 0.7483\n",
      "PCA K20  epoch 039  tl 0.5378  vl 0.5267  va 0.7973  vf 0.7537\n",
      "PCA K20  epoch 040  tl 0.5398  vl 0.5277  va 0.7953  vf 0.7517\n",
      "PCA K20  epoch 041  tl 0.5428  vl 0.5286  va 0.8012  vf 0.7958\n",
      "PCA K20  epoch 042  tl 0.5280  vl 0.5226  va 0.7992  vf 0.7497\n",
      "PCA K20  epoch 043  tl 0.5402  vl 0.5120  va 0.8031  vf 0.7607\n",
      "PCA K20  epoch 044  tl 0.5313  vl 0.5248  va 0.7992  vf 0.8014\n",
      "PCA K20  epoch 045  tl 0.5330  vl 0.5260  va 0.8012  vf 0.7522\n",
      "PCA K20  epoch 046  tl 0.5221  vl 0.5280  va 0.7934  vf 0.7481\n",
      "PCA K20  epoch 047  tl 0.5190  vl 0.5332  va 0.7934  vf 0.7452\n",
      "PCA K20  epoch 048  tl 0.5068  vl 0.5153  va 0.7953  vf 0.7537\n",
      "PCA K20  epoch 049  tl 0.5089  vl 0.5082  va 0.8012  vf 0.7572\n",
      "PCA K20  epoch 050  tl 0.5026  vl 0.5095  va 0.8012  vf 0.7545\n",
      "PCA K20  epoch 051  tl 0.5002  vl 0.5063  va 0.8051  vf 0.7625\n",
      "PCA K20  epoch 052  tl 0.4918  vl 0.5028  va 0.8051  vf 0.8040\n",
      "PCA K20  epoch 053  tl 0.4983  vl 0.5029  va 0.8129  vf 0.8119\n",
      "PCA K20  epoch 054  tl 0.5040  vl 0.5105  va 0.8109  vf 0.8040\n",
      "PCA K20  epoch 055  tl 0.4925  vl 0.5032  va 0.8031  vf 0.7569\n",
      "PCA K20  epoch 056  tl 0.4942  vl 0.4974  va 0.8051  vf 0.8043\n",
      "PCA K20  epoch 057  tl 0.4860  vl 0.5031  va 0.8051  vf 0.8023\n",
      "PCA K20  epoch 058  tl 0.4989  vl 0.4940  va 0.8090  vf 0.8064\n",
      "PCA K20  epoch 059  tl 0.4817  vl 0.4951  va 0.8051  vf 0.7559\n",
      "PCA K20  epoch 060  tl 0.4821  vl 0.4906  va 0.8129  vf 0.7656\n",
      "PCA K20  epoch 061  tl 0.4926  vl 0.4970  va 0.8051  vf 0.7621\n",
      "PCA K20  epoch 062  tl 0.4763  vl 0.4903  va 0.8070  vf 0.7579\n",
      "PCA K20  epoch 063  tl 0.4893  vl 0.4975  va 0.8129  vf 0.8148\n",
      "PCA K20  epoch 064  tl 0.4799  vl 0.4893  va 0.8168  vf 0.7677\n",
      "PCA K20  epoch 065  tl 0.4766  vl 0.4884  va 0.8051  vf 0.7602\n",
      "PCA K20  epoch 066  tl 0.4841  vl 0.4881  va 0.8109  vf 0.7634\n",
      "PCA K20  epoch 067  tl 0.4725  vl 0.4875  va 0.8051  vf 0.7587\n",
      "PCA K20  epoch 068  tl 0.4739  vl 0.4860  va 0.8070  vf 0.7642\n",
      "PCA K20  epoch 069  tl 0.4729  vl 0.4939  va 0.8148  vf 0.7714\n",
      "PCA K20  epoch 070  tl 0.4633  vl 0.4851  va 0.8187  vf 0.7707\n",
      "PCA K20  epoch 071  tl 0.4724  vl 0.4820  va 0.8148  vf 0.7667\n",
      "PCA K20  epoch 072  tl 0.4682  vl 0.4819  va 0.8148  vf 0.8118\n",
      "PCA K20  epoch 073  tl 0.4647  vl 0.4925  va 0.7992  vf 0.7542\n",
      "PCA K20  epoch 074  tl 0.4765  vl 0.4883  va 0.8051  vf 0.7911\n",
      "PCA K20  epoch 075  tl 0.4643  vl 0.4802  va 0.8129  vf 0.7482\n",
      "PCA K20  epoch 076  tl 0.4668  vl 0.4871  va 0.8168  vf 0.8054\n",
      "PCA K20  epoch 077  tl 0.4723  vl 0.4821  va 0.8168  vf 0.8121\n",
      "PCA K20  epoch 078  tl 0.4646  vl 0.4906  va 0.8129  vf 0.8104\n",
      "PCA K20  epoch 079  tl 0.4557  vl 0.4841  va 0.8129  vf 0.8114\n",
      "PCA K20  epoch 080  tl 0.4580  vl 0.4917  va 0.8051  vf 0.7615\n",
      "PCA K20  epoch 081  tl 0.4575  vl 0.4859  va 0.8090  vf 0.7646\n",
      "PCA K20  epoch 082  tl 0.4546  vl 0.4795  va 0.8109  vf 0.8107\n",
      "PCA K20  epoch 083  tl 0.4551  vl 0.4805  va 0.8207  vf 0.8169\n",
      "PCA K20  epoch 084  tl 0.4548  vl 0.4816  va 0.8109  vf 0.7679\n",
      "PCA K20  epoch 085  tl 0.4511  vl 0.4796  va 0.8168  vf 0.8110\n",
      "PCA K20  epoch 086  tl 0.4527  vl 0.4785  va 0.8207  vf 0.8140\n",
      "PCA K20  epoch 087  tl 0.4568  vl 0.4798  va 0.8070  vf 0.7457\n",
      "PCA K20  epoch 088  tl 0.4498  vl 0.4784  va 0.8109  vf 0.7621\n",
      "PCA K20  epoch 089  tl 0.4484  vl 0.4807  va 0.8090  vf 0.7583\n",
      "PCA K20  epoch 090  tl 0.4522  vl 0.4763  va 0.8187  vf 0.7662\n",
      "PCA K20  epoch 091  tl 0.4569  vl 0.4780  va 0.8187  vf 0.8136\n",
      "PCA K20  epoch 092  tl 0.4565  vl 0.4777  va 0.8129  vf 0.8062\n",
      "PCA K20  epoch 093  tl 0.4615  vl 0.4725  va 0.8168  vf 0.8075\n",
      "PCA K20  epoch 094  tl 0.4451  vl 0.4767  va 0.8109  vf 0.7987\n",
      "PCA K20  epoch 095  tl 0.4484  vl 0.4764  va 0.8148  vf 0.8133\n",
      "PCA K20  epoch 096  tl 0.4461  vl 0.4787  va 0.8031  vf 0.7462\n",
      "PCA K20  epoch 097  tl 0.4488  vl 0.4733  va 0.8051  vf 0.7583\n",
      "PCA K20  epoch 098  tl 0.4417  vl 0.4733  va 0.8070  vf 0.8022\n",
      "PCA K20  epoch 099  tl 0.4412  vl 0.4738  va 0.8090  vf 0.7495\n",
      "PCA K20  epoch 100  tl 0.4404  vl 0.4716  va 0.8168  vf 0.7976\n",
      "Test accuracy on PCA features 0.8532\n",
      "Test kappa 0.8325\n",
      "Test f1 macro 0.8721\n",
      "\n",
      "Classification report on test for PCA features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.8000    0.8889    0.8421         9\n",
      "     class_2     0.8021    0.8077    0.8049       286\n",
      "     class_3     0.8380    0.7169    0.7727       166\n",
      "     class_4     0.7347    0.7660    0.7500        47\n",
      "     class_5     0.9474    0.9278    0.9375        97\n",
      "     class_6     0.9216    0.9658    0.9431       146\n",
      "     class_7     1.0000    1.0000    1.0000         5\n",
      "     class_8     0.9694    0.9896    0.9794        96\n",
      "     class_9     1.0000    1.0000    1.0000         4\n",
      "    class_10     0.7544    0.8866    0.8152       194\n",
      "    class_11     0.8509    0.8371    0.8439       491\n",
      "    class_12     0.8142    0.7731    0.7931       119\n",
      "    class_13     0.9535    1.0000    0.9762        41\n",
      "    class_14     0.9081    0.9763    0.9410       253\n",
      "    class_15     0.8163    0.5195    0.6349        77\n",
      "    class_16     0.9444    0.8947    0.9189        19\n",
      "\n",
      "    accuracy                         0.8532      2050\n",
      "   macro avg     0.8784    0.8719    0.8721      2050\n",
      "weighted avg     0.8534    0.8532    0.8509      2050\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at outputs/runs_mlp/mlp_pca_top20_best.pth\n"
     ]
    }
   ],
   "source": [
    "# This cell trains the plain MLP on PCA components and reports results\n",
    "\n",
    "import numpy as np                                                                                                                    # import numpy for arrays\n",
    "import pandas as pd                                                                                                                   # import pandas for small tables\n",
    "import torch                                                                                                                          # import torch for model work\n",
    "import torch.nn as nn                                                                                                                 # import torch modules\n",
    "import torch.optim as optim                                                                                                           # import optimizers\n",
    "import matplotlib.pyplot as plt                                                                                                       # import matplotlib for plots\n",
    "from sklearn.decomposition import PCA                                                                                                 # import PCA\n",
    "from sklearn.metrics import classification_report                                                                                     # import report printer\n",
    "from pathlib import Path                                                                                                              # import Path for file paths\n",
    "\n",
    "# Choose how many PCA components to use\n",
    "K_PCA = 20                                                                                                                            # number of components to keep\n",
    "\n",
    "# Try to load PCA artifacts produced by notebook one\n",
    "pca_cube_path = ARTIFACTS / \"cube_pca.npy\"                                                                                            # path to PCA cube\n",
    "pca_obj_path = ARTIFACTS / \"pca.pkl\"                                                                                                  # path to PCA object\n",
    "need_fit_pca_now = not pca_cube_path.exists()                                                                                         # check if we need to fit PCA now\n",
    "\n",
    "if not need_fit_pca_now:                                                                                                              # if PCA cube exists\n",
    "    cube_pca_full = np.load(pca_cube_path)                                                                                            # load full PCA cube of shape H W K_full\n",
    "    try:                                                                                                                              # try to read explained variance if saved\n",
    "        evr = np.load(ARTIFACTS / \"pca_explained_variance_ratio.npy\")                                                                 # load explained variance ratio\n",
    "    except Exception:                                                                                                                 # if not found\n",
    "        evr = None                                                                                                                    # set to none\n",
    "else:                                                                                                                                 # need to fit PCA now using normalized cube\n",
    "    print(\"PCA artifacts not found, fitting PCA now on train pixels\")                                                                 # message\n",
    "    H, W, B = cube.shape                                                                                                              # read shape from normalized cube in memory\n",
    "    X_train_pixels = cube[mask_train].astype(np.float32)                                                                              # gather train pixels as N by B\n",
    "    K_fit = max(K_PCA, 1)                                                                                                             # ensure at least one component\n",
    "    pca_model = PCA(n_components=K_fit, svd_solver=\"auto\", whiten=False, random_state=cfg.split_seed)                                 # create PCA object\n",
    "    pca_model.fit(X_train_pixels)                                                                                                     # fit PCA on train only\n",
    "    evr = pca_model.explained_variance_ratio_                                                                                         # explained variance ratio\n",
    "    X_all = cube.reshape(-1, B)                                                                                                       # flatten full image\n",
    "    X_all_pca = pca_model.transform(X_all)                                                                                            # transform all pixels\n",
    "    cube_pca_full = X_all_pca.reshape(H, W, X_all_pca.shape[1])                                                                       # reshape back to H W K_full\n",
    "                                                                                                                                      # save artifacts for reuse\n",
    "    with open(pca_obj_path, \"wb\") as f:                                                                                               # open file for pca object\n",
    "        import pickle as _pickle                                                                                                      # local import for pickle\n",
    "        _pickle.dump({\"pca\": pca_model}, f)                                                                                           # save pca object\n",
    "    np.save(pca_cube_path, cube_pca_full.astype(np.float32))                                                                          # save pca cube\n",
    "    np.save(ARTIFACTS / \"pca_explained_variance_ratio.npy\", evr)                                                                      # save variance ratio\n",
    "\n",
    "# Select first K_PCA components\n",
    "K_full = cube_pca_full.shape[2]                                                                                                       # total components available\n",
    "K_use = min(K_PCA, K_full)                                                                                                            # cap by what we have\n",
    "cube_pca = cube_pca_full[:, :, :K_use]                                                                                                # slice first K components\n",
    "print(f\"Using {K_use} PCA components out of {K_full}\")                                                                                # show count\n",
    "if evr is not None:                                                                                                                   # if variance ratio available\n",
    "    cumvar = float(np.cumsum(evr[:K_use])[-1])                                                                                        # cumulative variance\n",
    "    print(\"Cumulative explained variance for these components\", round(cumvar, 4))                                                     # print share\n",
    "\n",
    "# Build datasets over PCA cube\n",
    "class PixelDatasetPCA(torch.utils.data.Dataset):                                                                                      # define dataset for PCA features\n",
    "    \"\"\"Returns PCA feature vector and label for each selected pixel\"\"\"                                                                # docstring\n",
    "    def __init__(self, cube_p: np.ndarray, labels_map: np.ndarray, mask_map: np.ndarray):                                             # init\n",
    "        X = cube_p[mask_map]                                                                                                          # select features for masked pixels\n",
    "        y = labels_map[mask_map]                                                                                                      # select labels for masked pixels\n",
    "        keep = y > 0                                                                                                                  # keep labeled classes only\n",
    "        self.X = X[keep].astype(np.float32)                                                                                           # features as float\n",
    "        self.y = (y[keep].astype(np.int64) - 1)                                                                                       # zero based labels\n",
    "    def __len__(self):                                                                                                                # length\n",
    "        return self.y.shape[0]                                                                                                        # number of items\n",
    "    def __getitem__(self, i):                                                                                                         # get one\n",
    "        return torch.from_numpy(self.X[i]), torch.tensor(self.y[i], dtype=torch.long)                                                 # tensors\n",
    "\n",
    "ds_train_p = PixelDatasetPCA(cube_pca, labels, mask_train)                                                                            # train dataset\n",
    "ds_val_p = PixelDatasetPCA(cube_pca, labels, mask_val)                                                                                # val dataset\n",
    "ds_test_p = PixelDatasetPCA(cube_pca, labels, mask_test)                                                                              # test dataset\n",
    "\n",
    "                                                                                                                                      # Make loaders\n",
    "BATCH = 256                                                                                                                           # batch size\n",
    "dl_train_p = torch.utils.data.DataLoader(ds_train_p, batch_size=BATCH, shuffle=True, drop_last=False)                                 # train loader\n",
    "dl_val_p = torch.utils.data.DataLoader(ds_val_p, batch_size=BATCH, shuffle=False, drop_last=False)                                    # val loader\n",
    "dl_test_p = torch.utils.data.DataLoader(ds_test_p, batch_size=BATCH, shuffle=False, drop_last=False)                                  # test loader\n",
    "\n",
    "# Define the same MLP but with input size equal to K_use\n",
    "class SpectralMLP(nn.Module):                                                                                                         # define model\n",
    "    \"\"\"Two layer MLP for classification of PCA features\"\"\"                                                                            # docstring\n",
    "    def __init__(self, in_dim: int, hidden1: int, hidden2: int, num_classes: int, p_drop: float = 0.3):                               # init\n",
    "        super().__init__()                                                                                                            # parent init\n",
    "        self.net = nn.Sequential(                                                                                                     # layer stack\n",
    "            nn.Linear(in_dim, hidden1),                                                                                               # dense layer one\n",
    "            nn.ReLU(inplace=True),                                                                                                    # activation\n",
    "            nn.Dropout(p_drop),                                                                                                       # dropout\n",
    "            nn.Linear(hidden1, hidden2),                                                                                              # dense layer two\n",
    "            nn.ReLU(inplace=True),                                                                                                    # activation\n",
    "            nn.Dropout(p_drop),                                                                                                       # dropout\n",
    "            nn.Linear(hidden2, num_classes),                                                                                          # output layer\n",
    "        )                                                                                                                             # end stack\n",
    "    def forward(self, x):                                                                                                             # forward pass\n",
    "        return self.net(x)                                                                                                            # run through stack\n",
    "\n",
    "model_p = SpectralMLP(in_dim=K_use, hidden1=256, hidden2=128, num_classes=num_classes, p_drop=0.3).to(DEVICE)                         # model\n",
    "print(\"Params\", sum(p.numel() for p in model_p.parameters()))                                                                         # parameter count\n",
    "\n",
    "# Loss optimizer and scheduler\n",
    "criterion_p = nn.CrossEntropyLoss()                                                                                                   # plain cross entropy\n",
    "optimizer_p = optim.Adam(model_p.parameters(), lr=1e-3, weight_decay=1e-4)                                                            # adam optimizer\n",
    "scheduler_p = optim.lr_scheduler.ReduceLROnPlateau(optimizer_p, mode=\"min\", factor=0.5, patience=3, verbose=True)                     # scheduler\n",
    "\n",
    "# Helper for metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, cohen_kappa_score                      # import metrics\n",
    "def metrics_from_logits(logits: torch.Tensor, targets: torch.Tensor, C: int) -> dict:                                                 # define helper\n",
    "    \"\"\"Return accuracy macro precision macro recall macro f1 kappa and confusion matrix\"\"\"                                            # docstring\n",
    "    preds = logits.argmax(1).cpu().numpy()                                                                                            # predicted ids\n",
    "    true = targets.cpu().numpy()                                                                                                      # true ids\n",
    "    acc = accuracy_score(true, preds)                                                                                                 # accuracy\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true, preds, labels=np.arange(C), average=\"macro\", zero_division=0)            # macro stats\n",
    "    kap = cohen_kappa_score(true, preds)                                                                                              # kappa\n",
    "    cm = confusion_matrix(true, preds, labels=np.arange(C))                                                                           # confusion matrix\n",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"kappa\": kap, \"cm\": cm}                                                   # pack results\n",
    "\n",
    "# Train with early stopping on validation loss\n",
    "EPOCHS = 100                                                                                                                          # max epochs\n",
    "PATIENCE = 10                                                                                                                         # early stopping patience\n",
    "best_val_loss = float(\"inf\")                                                                                                          # best val loss\n",
    "best_state_p = None                                                                                                                   # best weights\n",
    "bad_epochs = 0                                                                                                                        # counter for patience\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):                                                                                                       # loop epochs\n",
    "    model_p.train()                                                                                                                   # train mode\n",
    "    tr_sum = 0.0                                                                                                                      # loss sum\n",
    "    tr_cnt = 0                                                                                                                        # sample count\n",
    "    for xb, yb in dl_train_p:                                                                                                         # train batches\n",
    "        xb = xb.to(DEVICE)                                                                                                            # move features\n",
    "        yb = yb.to(DEVICE)                                                                                                            # move labels\n",
    "        optimizer_p.zero_grad(set_to_none=True)                                                                                       # clear grads\n",
    "        logits = model_p(xb)                                                                                                          # forward\n",
    "        loss = criterion_p(logits, yb)                                                                                                # loss\n",
    "        loss.backward()                                                                                                               # backward\n",
    "        optimizer_p.step()                                                                                                            # step\n",
    "        tr_sum += loss.item() * xb.size(0)                                                                                            # add weighted loss\n",
    "        tr_cnt += xb.size(0)                                                                                                          # add count\n",
    "    tr_loss = tr_sum / max(1, tr_cnt)                                                                                                 # average train loss\n",
    "\n",
    "    model_p.eval()                                                                                                                    # eval mode\n",
    "    with torch.no_grad():                                                                                                             # no grads\n",
    "        va_sum = 0.0                                                                                                                  # val loss sum\n",
    "        va_cnt = 0                                                                                                                    # val count\n",
    "        v_logits = []                                                                                                                 # logits list\n",
    "        v_targets = []                                                                                                                # targets list\n",
    "        for xb, yb in dl_val_p:                                                                                                       # val batches\n",
    "            xb = xb.to(DEVICE)                                                                                                        # move features\n",
    "            yb = yb.to(DEVICE)                                                                                                        # move labels\n",
    "            logits = model_p(xb)                                                                                                      # forward\n",
    "            loss = criterion_p(logits, yb)                                                                                            # loss\n",
    "            va_sum += loss.item() * xb.size(0)                                                                                        # add loss\n",
    "            va_cnt += xb.size(0)                                                                                                      # add count\n",
    "            v_logits.append(logits)                                                                                                   # keep logits\n",
    "            v_targets.append(yb)                                                                                                      # keep targets\n",
    "        val_loss = va_sum / max(1, va_cnt)                                                                                            # average val loss\n",
    "        v_logits = torch.cat(v_logits, 0)                                                                                             # stack logits\n",
    "        v_targets = torch.cat(v_targets, 0)                                                                                           # stack targets\n",
    "        v_metrics = metrics_from_logits(v_logits, v_targets, num_classes)                                                             # compute metrics\n",
    "\n",
    "    scheduler_p.step(val_loss)                                                                                                        # step scheduler\n",
    "    print(f\"PCA K{K_use}  epoch {ep:03d}  tl {tr_loss:.4f}  vl {val_loss:.4f}  va {v_metrics['acc']:.4f}  vf {v_metrics['f1']:.4f}\")  # progress\n",
    "\n",
    "    if val_loss < best_val_loss:                                                                                                      # improvement\n",
    "        best_val_loss = val_loss                                                                                                      # update best loss\n",
    "        best_state_p = {k: v.cpu().clone() for k, v in model_p.state_dict().items()}                                                  # snapshot weights\n",
    "        bad_epochs = 0                                                                                                                # reset patience\n",
    "        best_epoch_p = ep                                                                                                             # best epoch\n",
    "    else:                                                                                                                             # no improvement\n",
    "        bad_epochs += 1                                                                                                               # inc patience\n",
    "        if bad_epochs >= PATIENCE:                                                                                                    # early stop\n",
    "            print(\"Early stop at\", ep, \"best epoch\", best_epoch_p)                                                                    # message\n",
    "            break                                                                                                                     # stop training\n",
    "\n",
    "# Load best model and evaluate on test\n",
    "model_p.load_state_dict(best_state_p)                                                                                                 # load best weights\n",
    "model_p.to(DEVICE).eval()                                                                                                             # eval mode\n",
    "with torch.no_grad():                                                                                                                 # no grads\n",
    "    t_logits = []                                                                                                                     # test logits\n",
    "    t_targets = []                                                                                                                    # test targets\n",
    "    for xb, yb in dl_test_p:                                                                                                          # test batches\n",
    "        xb = xb.to(DEVICE)                                                                                                            # move features\n",
    "        yb = yb.to(DEVICE)                                                                                                            # move labels\n",
    "        t_logits.append(model_p(xb))                                                                                                  # forward\n",
    "        t_targets.append(yb)                                                                                                          # keep labels\n",
    "    t_logits = torch.cat(t_logits, 0)                                                                                                 # stack logits\n",
    "    t_targets = torch.cat(t_targets, 0)                                                                                               # stack targets\n",
    "    tm_p = metrics_from_logits(t_logits, t_targets, num_classes)                                                                      # compute metrics\n",
    "\n",
    "# Print test accuracy kappa and f1 macro\n",
    "print(\"Test accuracy on PCA features\", round(tm_p[\"acc\"], 4))                                                                         # accuracy\n",
    "print(\"Test kappa\", round(tm_p[\"kappa\"], 4))                                                                                          # kappa\n",
    "print(\"Test f1 macro\", round(tm_p[\"f1\"], 4))                                                                                          # f1 macro\n",
    "\n",
    "# Print classification report\n",
    "y_true_test = t_targets.cpu().numpy()                                                                                                 # true ids\n",
    "y_pred_test = t_logits.argmax(1).cpu().numpy()                                                                                        # predicted ids\n",
    "target_names = [f\"class_{i}\" for i in range(1, num_classes + 1)]                                                                      # class names\n",
    "print(\"\\nClassification report on test for PCA features\")                                                                             # header\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=target_names, digits=4, zero_division=0))                          # report\n",
    "\n",
    "                                                                                                                                      # Plot and save test confusion matrix\n",
    "cm_p = tm_p[\"cm\"]                                                                                                                     # confusion matrix\n",
    "plt.figure(figsize=(6, 5))                                                                                                            # figure\n",
    "plt.imshow(cm_p, cmap=\"Greens\")                                                                                                       # plot matrix\n",
    "plt.title(f\"Confusion matrix test  PCA top {K_use} components\")                                                                       # title\n",
    "plt.xlabel(\"Predicted\")                                                                                                               # x label\n",
    "plt.ylabel(\"True\")                                                                                                                    # y label\n",
    "plt.colorbar()                                                                                                                        # color bar\n",
    "plt.tight_layout()                                                                                                                    # tidy layout\n",
    "plt.savefig(FIGS / f\"mlp_pca_top{K_use}_confusion_test.png\", dpi=150)                                                                 # save figure\n",
    "plt.show()                                                                                                                            # show figure\n",
    "\n",
    "# Save checkpoint for this PCA run\n",
    "RUNS.mkdir(parents=True, exist_ok=True)                                                                                               # ensure runs folder exists\n",
    "ckpt_pca = RUNS / f\"mlp_pca_top{K_use}_best.pth\"                                                                                      # checkpoint path\n",
    "torch.save({\"state_dict\": best_state_p, \"num_classes\": num_classes, \"in_dim\": K_use}, ckpt_pca)                                       # save weights\n",
    "print(\"Saved checkpoint at\", ckpt_pca.as_posix())                                                                                     # confirm save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01e984-dce6-4eb1-b9d3-daf7b10fe262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
