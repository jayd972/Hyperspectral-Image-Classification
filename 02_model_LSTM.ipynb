{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1013a60",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is focused on hyperspectral image classification using a Long Short-Term Memory (LSTM) deep learning model.\n",
    "\n",
    "- Data handling: The preprocessed hyperspectral cube and label data are loaded from files. The data is split into training, validation, and test sets using binary masks.\n",
    "\n",
    "- Reproducibility: Random seeds for both NumPy and PyTorch are set for consistent results across runs. The script automatically selects GPU if available, otherwise defaults to CPU.\n",
    "\n",
    "- Directory setup: Output directories are defined for storing artifacts, figures, and experiment records, which assists in organizing results.\n",
    "\n",
    "- Modeling: An LSTM network is employed to process the spectral sequence of each pixel, aiming to classify them according to ground truth labels.\n",
    "\n",
    "- Evaluation: The notebook uses common machine learning metrics (accuracy, F1-score, Cohen's Kappa) and utilities for model analysis, including options to generate performance plots.\n",
    "\n",
    "This setup provides a reproducible workflow for sequence-based hyperspectral classification, from data loading and model training to evaluation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1081dc66-c4b6-4411-8868-be40d806d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path                                                   # import from pathlib",
    "import time                                                                # import time library",
    "import numpy as np                                                         # import numpy library",
    "import matplotlib.pyplot as plt                                            # import matplotlib.pyplot library",
    "# empty line",
    "import torch                                                               # import torch library",
    "import torch.nn as nn                                                      # import torch.nn library",
    "import torch.optim as optim                                                # import torch.optim library",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler  # import from torch.utils.data",
    "# empty line",
    "from sklearn.metrics import (                                              # import from sklearn.metrics",
    "    confusion_matrix,",
    "    accuracy_score,",
    "    precision_recall_fscore_support,",
    "    cohen_kappa_score,",
    "    classification_report,",
    ")",
    "# empty line",
    "np.random.seed(42)",
    "torch.manual_seed(42)",
    "# empty line",
    "ARTIFACTS = Path(\"outputs/artifacts_ip\")                                   # define path for ARTIFACTS",
    "FIGS = Path(\"outputs/figs\")                                                # define path for FIGS",
    "RUNS = Path(\"outputs/runs_lstm\")                                           # define path for RUNS",
    "FIGS.mkdir(parents=True, exist_ok=True)                                    # create directory FIGS.mkdir(parents",
    "RUNS.mkdir(parents=True, exist_ok=True)                                    # create directory RUNS.mkdir(parents",
    "# empty line",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")      # set computation device (GPU/CPU)",
    "print(\"Device\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d1d519-56e4-4996-8164-bb492f15139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube (145, 145, 200) Classes 16\n"
     ]
    }
   ],
   "source": [
    "cube = np.load(ARTIFACTS / \"cube_clean_norm.npy\")           # H W B",
    "labels = np.load(ARTIFACTS / \"labels.npy\")                  # H W with 1..C and 0 as background",
    "mask_train = np.load(ARTIFACTS / \"mask_train.npy\")          # assign value to mask_train",
    "mask_val   = np.load(ARTIFACTS / \"mask_val.npy\")            # assign value to mask_val",
    "mask_test  = np.load(ARTIFACTS / \"mask_test.npy\")           # assign value to mask_test",
    "# empty line",
    "H, W, B = cube.shape                                        # assign value to H, W, B",
    "num_classes = int(labels.max())                             # assign value to num_classes",
    "print(\"Cube\", cube.shape, \"Classes\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb11634-c4cf-435e-b0d7-9be7052b59ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 7686 Val 513 Test 2050\n"
     ]
    }
   ],
   "source": [
    "class PixelDatasetSeq(Dataset):                                            # define class PixelDatasetSeq",
    "    \"\"\"Return one spectrum as a sequence and its zero based class id.\"\"\"",
    "    def __init__(self, cube_arr: np.ndarray, lab_map: np.ndarray, mask_map: np.ndarray):  # define function __init__",
    "        X = cube_arr[mask_map]                                             # N by B",
    "        y = lab_map[mask_map]                                              # N",
    "        keep = y > 0                                                       # drop background",
    "        self.X = X[keep].astype(np.float32)                                # N by B",
    "        self.y = (y[keep].astype(np.int64) - 1)                            # zero based",
    "    def __len__(self):                                                     # define function __len__",
    "        return self.y.shape[0]                                             # return value from function",
    "    def __getitem__(self, i):                                              # define function __getitem__",
    "        x = torch.from_numpy(self.X[i]).unsqueeze(1)                       # B by 1",
    "        y = torch.tensor(self.y[i], dtype=torch.long)                      # assign value to y",
    "        return x, y                                                        # return value from function",
    "# empty line",
    "ds_train = PixelDatasetSeq(cube, labels, mask_train)                       # assign value to ds_train",
    "ds_val   = PixelDatasetSeq(cube, labels, mask_val)                         # assign value to ds_val",
    "ds_test  = PixelDatasetSeq(cube, labels, mask_test)                        # assign value to ds_test",
    "# empty line",
    "print(\"Train\", len(ds_train), \"Val\", len(ds_val), \"Test\", len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769cb2c6-9fd5-4160-8f42-4cf197b59a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches  train 31 val 3 test 9\n"
     ]
    }
   ],
   "source": [
    "BATCH = 256                                                                # assign value to BATCH",
    "# empty line",
    "y_tr = ds_train.y                                                          # assign value to y_tr",
    "counts = np.bincount(y_tr, minlength=num_classes).astype(np.float32)       # assign value to counts",
    "class_w = 1.0 / np.maximum(counts, 1.0)                                    # assign value to class_w",
    "sample_w = class_w[y_tr]                                                   # assign value to sample_w",
    "# empty line",
    "sampler = WeightedRandomSampler(                                           # assign value to sampler",
    "    weights=torch.from_numpy(sample_w),                                    # assign value to weights",
    "    num_samples=len(sample_w),                                             # assign value to num_samples",
    "    replacement=True,                                                      # assign value to replacement",
    ")",
    "# empty line",
    "dl_train = DataLoader(ds_train, batch_size=BATCH, sampler=sampler, drop_last=False)  # assign value to dl_train",
    "dl_val   = DataLoader(ds_val,   batch_size=BATCH, shuffle=False, drop_last=False)  # assign value to dl_val",
    "dl_test  = DataLoader(ds_test,  batch_size=BATCH, shuffle=False, drop_last=False)  # assign value to dl_test",
    "# empty line",
    "print(\"Batches  train\", len(dl_train), \"val\", len(dl_val), \"test\", len(dl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1846b16-f98b-403c-b9ca-ce5c235cf3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params 2506001\n"
     ]
    }
   ],
   "source": [
    "class SpectralLSTM_Attn(nn.Module):                                        # define class SpectralLSTM_Attn",
    "    \"\"\"",
    "    Input is batch by B by 1",
    "    LSTM encodes along bands",
    "    Attention pools across time steps",
    "    \"\"\"",
    "    def __init__(self, input_size: int, hidden: int, layers: int, num_classes: int, p_drop: float = 0.3, bidir: bool = True, mean_pool: bool = False):  # assign value to def __init__(self, input_size: int, hidden: int, layers: int, num_classes: int, p_drop: float",
    "        super().__init__()",
    "        self.mean_pool = mean_pool                                         # assign value to self.mean_pool",
    "        self.lstm = nn.LSTM(                                               # assign value to self.lstm",
    "            input_size=input_size,                                         # assign value to input_size",
    "            hidden_size=hidden,                                            # assign value to hidden_size",
    "            num_layers=layers,                                             # assign value to num_layers",
    "            batch_first=True,                                              # assign value to batch_first",
    "            bidirectional=bidir,                                           # assign value to bidirectional",
    "            dropout=p_drop if layers > 1 else 0.0,                         # assign value to dropout",
    "        )",
    "        d = hidden * (2 if bidir else 1)                                   # assign value to d",
    "        self.attn = nn.Sequential(                                         # assign value to self.attn",
    "            nn.Linear(d, d),",
    "            nn.Tanh(),",
    "            nn.Linear(d, 1),",
    "        )",
    "        self.head = nn.Sequential(                                         # assign value to self.head",
    "            nn.Dropout(p_drop),",
    "            nn.Linear(d, 256),",
    "            nn.ReLU(inplace=True),                                         # assign value to nn.ReLU(inplace",
    "            nn.Dropout(p_drop),",
    "            nn.Linear(256, num_classes),",
    "        )",
    "# empty line",
    "    def forward(self, x):                                                  # x shape batch by B by 1",
    "        seq, _ = self.lstm(x)                                              # batch by B by d",
    "        if self.mean_pool:                                                 # conditional statement",
    "            z = seq.mean(dim=1)                                            # simple mean",
    "        else:                                                              # conditional statement",
    "            w = self.attn(seq).squeeze(-1)                                 # batch by B",
    "            w = torch.softmax(w, dim=1)                                    # weights over bands",
    "            z = (seq * w.unsqueeze(-1)).sum(1)                             # assign value to z",
    "        return self.head(z)                                                # return value from function",
    "# empty line",
    "HIDDEN = 256                                                               # assign value to HIDDEN",
    "LAYERS = 2                                                                 # assign value to LAYERS",
    "P_DROP = 0.3                                                               # assign value to P_DROP",
    "BIDIR = True                                                               # assign value to BIDIR",
    "MEAN_POOL = False                                                          # assign value to MEAN_POOL",
    "# empty line",
    "model = SpectralLSTM_Attn(input_size=1, hidden=HIDDEN, layers=LAYERS, num_classes=num_classes, p_drop=P_DROP, bidir=BIDIR, mean_pool=MEAN_POOL).to(DEVICE)  # assign value to model",
    "print(\"Params\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a8fa68-1720-4f0d-b95b-168cc882dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()                                          # assign value to criterion",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=5e-5)    # assign value to optimizer",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=40)      # assign value to scheduler",
    "# empty line",
    "def metrics_from_logits(logits: torch.Tensor, targets: torch.Tensor, C: int) -> dict:  # define function metrics_from_logits",
    "    preds = logits.argmax(1).cpu().numpy()                                 # assign value to preds",
    "    true = targets.cpu().numpy()                                           # assign value to true",
    "    acc = accuracy_score(true, preds)                                      # assign value to acc",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true, preds, labels=np.arange(C), average=\"macro\", zero_division=0)  # assign value to prec, rec, f1, _",
    "    kap = cohen_kappa_score(true, preds)                                   # assign value to kap",
    "    cm = confusion_matrix(true, preds, labels=np.arange(C))                # assign value to cm",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"kappa\": kap, \"cm\": cm}  # return value from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d278e37-92ee-4def-85e5-ec26bc9e58a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  tl 2.4137  va 0.0799  vf 0.0316\n",
      "Epoch 002  tl 1.8529  va 0.2671  vf 0.1682\n",
      "Epoch 003  tl 1.6869  va 0.1969  vf 0.1620\n",
      "Epoch 004  tl 1.6107  va 0.2729  vf 0.1942\n",
      "Epoch 005  tl 1.4989  va 0.2222  vf 0.1858\n",
      "Epoch 006  tl 1.4813  va 0.2904  vf 0.2423\n",
      "Epoch 007  tl 1.3737  va 0.3450  vf 0.2660\n",
      "Epoch 008  tl 1.3637  va 0.2554  vf 0.2839\n",
      "Epoch 009  tl 1.7545  va 0.2476  vf 0.1901\n",
      "Epoch 010  tl 1.4843  va 0.3060  vf 0.2763\n",
      "Epoch 011  tl 1.3720  va 0.4035  vf 0.3393\n",
      "Epoch 012  tl 1.3450  va 0.3353  vf 0.3583\n",
      "Epoch 013  tl 1.2967  va 0.4191  vf 0.3263\n",
      "Epoch 014  tl 1.2439  va 0.3197  vf 0.3659\n",
      "Epoch 015  tl 1.1540  va 0.4211  vf 0.3829\n",
      "Epoch 016  tl 1.1113  va 0.4483  vf 0.4810\n",
      "Epoch 017  tl 1.0819  va 0.4581  vf 0.4259\n",
      "Epoch 018  tl 1.0557  va 0.4912  vf 0.4802\n",
      "Epoch 019  tl 0.9874  va 0.4717  vf 0.4855\n",
      "Epoch 020  tl 0.9629  va 0.5244  vf 0.5106\n",
      "Epoch 021  tl 0.9726  va 0.4464  vf 0.4177\n",
      "Epoch 022  tl 1.0174  va 0.5322  vf 0.5285\n",
      "Epoch 023  tl 0.9120  va 0.5556  vf 0.5470\n",
      "Epoch 024  tl 0.8469  va 0.5731  vf 0.5420\n",
      "Epoch 025  tl 0.8236  va 0.6082  vf 0.5881\n",
      "Epoch 026  tl 0.8050  va 0.5926  vf 0.5860\n",
      "Epoch 027  tl 0.7747  va 0.5517  vf 0.5534\n",
      "Epoch 028  tl 0.8358  va 0.5575  vf 0.5100\n",
      "Epoch 029  tl 0.8110  va 0.5984  vf 0.5615\n",
      "Epoch 030  tl 0.7636  va 0.5984  vf 0.6301\n",
      "Epoch 031  tl 0.8370  va 0.5750  vf 0.5752\n",
      "Epoch 032  tl 0.8205  va 0.6004  vf 0.6422\n",
      "Epoch 033  tl 0.8049  va 0.5945  vf 0.6378\n",
      "Epoch 034  tl 0.7939  va 0.6257  vf 0.6748\n",
      "Epoch 035  tl 0.8187  va 0.5945  vf 0.6530\n",
      "Epoch 036  tl 0.7971  va 0.6160  vf 0.6496\n",
      "Epoch 037  tl 0.7941  va 0.5809  vf 0.6333\n",
      "Epoch 038  tl 0.8015  va 0.5945  vf 0.6369\n",
      "Epoch 039  tl 0.7950  va 0.5965  vf 0.6376\n",
      "Epoch 040  tl 0.8093  va 0.6004  vf 0.6429\n",
      "Epoch 041  tl 0.7926  va 0.6004  vf 0.6429\n",
      "Epoch 042  tl 0.7986  va 0.5984  vf 0.6464\n",
      "Epoch 043  tl 0.7961  va 0.5984  vf 0.6455\n",
      "Epoch 044  tl 0.7965  va 0.5906  vf 0.6394\n",
      "Epoch 045  tl 0.7852  va 0.5828  vf 0.6563\n",
      "Epoch 046  tl 0.7706  va 0.5731  vf 0.6287\n",
      "Epoch 047  tl 0.7931  va 0.5731  vf 0.6254\n",
      "Epoch 048  tl 0.7745  va 0.6160  vf 0.6840\n",
      "Epoch 049  tl 0.7786  va 0.6121  vf 0.6384\n",
      "Epoch 050  tl 0.7630  va 0.5809  vf 0.6513\n",
      "Epoch 051  tl 0.8402  va 0.5400  vf 0.6070\n",
      "Epoch 052  tl 0.8835  va 0.5068  vf 0.5834\n",
      "Epoch 053  tl 0.8644  va 0.5478  vf 0.6018\n",
      "Epoch 054  tl 0.8517  va 0.5750  vf 0.5847\n",
      "Epoch 055  tl 0.7618  va 0.5400  vf 0.5953\n",
      "Epoch 056  tl 0.7782  va 0.5692  vf 0.6201\n",
      "Epoch 057  tl 0.7923  va 0.6160  vf 0.6099\n",
      "Epoch 058  tl 0.7007  va 0.5945  vf 0.6748\n",
      "Epoch 059  tl 0.7467  va 0.5400  vf 0.5941\n",
      "Epoch 060  tl 0.7567  va 0.5712  vf 0.6095\n",
      "Epoch 061  tl 0.7192  va 0.6179  vf 0.6506\n",
      "Epoch 062  tl 0.9893  va 0.2846  vf 0.1904\n",
      "Epoch 063  tl 1.4168  va 0.3548  vf 0.3565\n",
      "Early stop at epoch 63 best epoch 48 best F1 0.684\n",
      "Train time seconds 644.12\n",
      "Saved outputs/runs_lstm/lstm_attn_best.pth\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 120                                                               # assign value to EPOCHS",
    "PATIENCE = 15                                                              # assign value to PATIENCE",
    "best_score = float(\"-inf\")                                                 # assign value to best_score",
    "best_state = None                                                          # assign value to best_state",
    "best_epoch = 0                                                             # assign value to best_epoch",
    "bad_epochs = 0                                                             # assign value to bad_epochs",
    "history = []                                                               # assign value to history",
    "# empty line",
    "t0 = time.time()                                                           # assign value to t0",
    "# empty line",
    "for ep in range(1, EPOCHS + 1):                                            # loop iteration",
    "                                                                           # train",
    "    model.train()",
    "    run = 0.0                                                              # assign value to run",
    "    n = 0                                                                  # assign value to n",
    "    for xb, yb in dl_train:                                                # loop iteration",
    "        xb = xb.to(DEVICE)                                                 # batch by B by 1",
    "        yb = yb.to(DEVICE)                                                 # assign value to yb",
    "        optimizer.zero_grad(set_to_none=True)                              # assign value to optimizer.zero_grad(set_to_none",
    "        lg = model(xb)                                                     # assign value to lg",
    "        ls = criterion(lg, yb)                                             # assign value to ls",
    "        ls.backward()",
    "        optimizer.step()",
    "        run += ls.item() * xb.size(0)                                      # assign value to run +",
    "        n += xb.size(0)                                                    # assign value to n +",
    "    tr_loss = run / max(1, n)                                              # assign value to tr_loss",
    "# empty line",
    "                                                                           # val",
    "    model.eval()",
    "    with torch.no_grad():",
    "        all_lg, all_y = [], []                                             # assign value to all_lg, all_y",
    "        for xb, yb in dl_val:                                              # loop iteration",
    "            lg = model(xb.to(DEVICE))                                      # assign value to lg",
    "            all_lg.append(lg)",
    "            all_y.append(yb.to(DEVICE))",
    "        lg_cat = torch.cat(all_lg, 0)                                      # assign value to lg_cat",
    "        y_cat  = torch.cat(all_y, 0)                                       # assign value to y_cat",
    "        v_metrics = metrics_from_logits(lg_cat, y_cat, num_classes)        # assign value to v_metrics",
    "    scheduler.step()",
    "# empty line",
    "    history.append({\"epoch\": ep, \"train_loss\": tr_loss, \"val_acc\": v_metrics[\"acc\"], \"val_f1\": v_metrics[\"f1\"]})",
    "    print(f\"Epoch {ep:03d}  tl {tr_loss:.4f}  va {v_metrics['acc']:.4f}  vf {v_metrics['f1']:.4f}\")",
    "# empty line",
    "    if v_metrics[\"f1\"] > best_score:                                       # conditional statement",
    "        best_score = v_metrics[\"f1\"]                                       # assign value to best_score",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}  # assign value to best_state",
    "        best_epoch = ep                                                    # assign value to best_epoch",
    "        bad_epochs = 0                                                     # assign value to bad_epochs",
    "    else:                                                                  # conditional statement",
    "        bad_epochs += 1                                                    # assign value to bad_epochs +",
    "        if bad_epochs >= PATIENCE:                                         # assign value to if bad_epochs >",
    "            print(\"Early stop at epoch\", ep, \"best epoch\", best_epoch, \"best F1\", round(best_score, 4))",
    "            break",
    "# empty line",
    "train_time = time.time() - t0                                              # assign value to train_time",
    "print(\"Train time seconds\", round(train_time, 2))",
    "# empty line",
    "ckpt_path = RUNS / \"lstm_attn_best.pth\"                                    # assign value to ckpt_path",
    "torch.save({\"state_dict\": best_state, \"num_classes\": num_classes, \"B\": B}, ckpt_path)",
    "print(\"Saved\", ckpt_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4371d61d-8cc2-4a57-bdee-a5ec1995fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.6159844054580896\n",
      "Val kappa 0.5679399756311323\n",
      "Val f1 macro 0.6839635039930498\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(best_state)",
    "model.to(DEVICE).eval()",
    "# empty line",
    "with torch.no_grad():",
    "    v_logits, v_targets = [], []                                # assign value to v_logits, v_targets",
    "    for xb, yb in dl_val:                                       # loop iteration",
    "        v_logits.append(model(xb.to(DEVICE)))",
    "        v_targets.append(yb.to(DEVICE))",
    "    v_logits = torch.cat(v_logits, 0)                           # assign value to v_logits",
    "    v_targets = torch.cat(v_targets, 0)                         # assign value to v_targets",
    "    vm = metrics_from_logits(v_logits, v_targets, num_classes)  # assign value to vm",
    "# empty line",
    "print(\"Val accuracy\", vm[\"acc\"])",
    "print(\"Val kappa\", vm[\"kappa\"])",
    "print(\"Val f1 macro\", vm[\"f1\"])",
    "# empty line",
    "plt.figure(figsize=(6, 5))                                      # assign value to plt.figure(figsize",
    "plt.imshow(vm[\"cm\"], cmap=\"Blues\")                              # assign value to plt.imshow(vm[\"cm\"], cmap",
    "plt.title(\"Confusion matrix val  LSTM attention\")",
    "plt.xlabel(\"Predicted\")",
    "plt.ylabel(\"True\")",
    "plt.colorbar()",
    "plt.tight_layout()",
    "plt.savefig(FIGS / \"lstm_attn_confusion_val.png\", dpi=150)      # assign value to plt.savefig(FIGS / \"lstm_attn_confusion_val.png\", dpi",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7558e0-e345-4238-8bb0-0a32b70aabf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.5629268292682926\n",
      "Test kappa 0.5092348440054537\n",
      "Test f1 macro 0.5999787340896469\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report on test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.2727    1.0000    0.4286         9\n",
      "     class_2     0.4871    0.3951    0.4363       286\n",
      "     class_3     0.2790    0.3916    0.3258       166\n",
      "     class_4     0.3043    0.7447    0.4321        47\n",
      "     class_5     0.7600    0.7835    0.7716        97\n",
      "     class_6     0.8082    0.8082    0.8082       146\n",
      "     class_7     0.5000    1.0000    0.6667         5\n",
      "     class_8     0.9726    0.7396    0.8402        96\n",
      "     class_9     0.4000    1.0000    0.5714         4\n",
      "    class_10     0.4585    0.5979    0.5190       194\n",
      "    class_11     0.5787    0.4420    0.5012       491\n",
      "    class_12     0.3864    0.2857    0.3285       119\n",
      "    class_13     0.8837    0.9268    0.9048        41\n",
      "    class_14     0.8879    0.8142    0.8495       253\n",
      "    class_15     0.3415    0.3636    0.3522        77\n",
      "    class_16     0.7600    1.0000    0.8636        19\n",
      "\n",
      "    accuracy                         0.5629      2050\n",
      "   macro avg     0.5675    0.7058    0.6000      2050\n",
      "weighted avg     0.5913    0.5629    0.5676      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():",
    "    t_logits, t_targets = [], []                                           # assign value to t_logits, t_targets",
    "    for xb, yb in dl_test:                                                 # loop iteration",
    "        t_logits.append(model(xb.to(DEVICE)))",
    "        t_targets.append(yb.to(DEVICE))",
    "    t_logits = torch.cat(t_logits, 0)                                      # assign value to t_logits",
    "    t_targets = torch.cat(t_targets, 0)                                    # assign value to t_targets",
    "    tm = metrics_from_logits(t_logits, t_targets, num_classes)             # assign value to tm",
    "# empty line",
    "print(\"Test accuracy\", tm[\"acc\"])",
    "print(\"Test kappa\", tm[\"kappa\"])",
    "print(\"Test f1 macro\", tm[\"f1\"])",
    "# empty line",
    "plt.figure(figsize=(6, 5))                                                 # assign value to plt.figure(figsize",
    "plt.imshow(tm[\"cm\"], cmap=\"Greens\")                                        # assign value to plt.imshow(tm[\"cm\"], cmap",
    "plt.title(\"Confusion matrix test  LSTM attention\")",
    "plt.xlabel(\"Predicted\")",
    "plt.ylabel(\"True\")",
    "plt.colorbar()",
    "plt.tight_layout()",
    "plt.savefig(FIGS / \"lstm_attn_confusion_test.png\", dpi=150)                # assign value to plt.savefig(FIGS / \"lstm_attn_confusion_test.png\", dpi",
    "plt.show()",
    "# empty line",
    "names = [f\"class_{i}\" for i in range(1, num_classes + 1)]                  # assign value to names",
    "print(\"\\nClassification report on test\")",
    "print(classification_report(t_targets.cpu().numpy(), t_logits.argmax(1).cpu().numpy(), target_names=names, digits=4, zero_division=0))  # print output message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722646e2-0a3a-438d-84ef-936a46903b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.5629268292682926\n",
      "Cohen kappa: 0.5092348440054537\n",
      "Macro precision: 0.567536227832276\n",
      "Macro recall: 0.7058101363594651\n",
      "Macro f1: 0.5999787340896469\n",
      "Weighted precision: 0.5913280530535108\n",
      "Weighted recall: 0.5629268292682926\n",
      "Weighted f1: 0.5675836796618149\n",
      "\n",
      "Per class metrics\n",
      "Class 01: precision=0.2727, recall=1.0000, f1=0.4286, support=9\n",
      "Class 02: precision=0.4871, recall=0.3951, f1=0.4363, support=286\n",
      "Class 03: precision=0.2790, recall=0.3916, f1=0.3258, support=166\n",
      "Class 04: precision=0.3043, recall=0.7447, f1=0.4321, support=47\n",
      "Class 05: precision=0.7600, recall=0.7835, f1=0.7716, support=97\n",
      "Class 06: precision=0.8082, recall=0.8082, f1=0.8082, support=146\n",
      "Class 07: precision=0.5000, recall=1.0000, f1=0.6667, support=5\n",
      "Class 08: precision=0.9726, recall=0.7396, f1=0.8402, support=96\n",
      "Class 09: precision=0.4000, recall=1.0000, f1=0.5714, support=4\n",
      "Class 10: precision=0.4585, recall=0.5979, f1=0.5190, support=194\n",
      "Class 11: precision=0.5787, recall=0.4420, f1=0.5012, support=491\n",
      "Class 12: precision=0.3864, recall=0.2857, f1=0.3285, support=119\n",
      "Class 13: precision=0.8837, recall=0.9268, f1=0.9048, support=41\n",
      "Class 14: precision=0.8879, recall=0.8142, f1=0.8495, support=253\n",
      "Class 15: precision=0.3415, recall=0.3636, f1=0.3522, support=77\n",
      "Class 16: precision=0.7600, recall=1.0000, f1=0.8636, support=19\n",
      "\n",
      "Full classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_1     0.2727    1.0000    0.4286         9\n",
      "     class_2     0.4871    0.3951    0.4363       286\n",
      "     class_3     0.2790    0.3916    0.3258       166\n",
      "     class_4     0.3043    0.7447    0.4321        47\n",
      "     class_5     0.7600    0.7835    0.7716        97\n",
      "     class_6     0.8082    0.8082    0.8082       146\n",
      "     class_7     0.5000    1.0000    0.6667         5\n",
      "     class_8     0.9726    0.7396    0.8402        96\n",
      "     class_9     0.4000    1.0000    0.5714         4\n",
      "    class_10     0.4585    0.5979    0.5190       194\n",
      "    class_11     0.5787    0.4420    0.5012       491\n",
      "    class_12     0.3864    0.2857    0.3285       119\n",
      "    class_13     0.8837    0.9268    0.9048        41\n",
      "    class_14     0.8879    0.8142    0.8495       253\n",
      "    class_15     0.3415    0.3636    0.3522        77\n",
      "    class_16     0.7600    1.0000    0.8636        19\n",
      "\n",
      "    accuracy                         0.5629      2050\n",
      "   macro avg     0.5675    0.7058    0.6000      2050\n",
      "weighted avg     0.5913    0.5629    0.5676      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (                                              # import from sklearn.metrics",
    "    accuracy_score,",
    "    cohen_kappa_score,",
    "    precision_recall_fscore_support,",
    "    classification_report,",
    "    confusion_matrix,",
    ")",
    "# empty line",
    "                                                                           # convert tensors to numpy",
    "y_true = t_targets.cpu().numpy()                                           # assign value to y_true",
    "y_pred = t_logits.argmax(1).cpu().numpy()                                  # assign value to y_pred",
    "# empty line",
    "                                                                           # global metrics",
    "oa = accuracy_score(y_true, y_pred)                                        # assign value to oa",
    "kappa = cohen_kappa_score(y_true, y_pred)                                  # assign value to kappa",
    "# empty line",
    "prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(      # assign value to prec_macro, rec_macro, f1_macro, _",
    "    y_true, y_pred, average=\"macro\", zero_division=0                       # assign value to y_true, y_pred, average",
    ")",
    "prec_weighted, rec_weighted, f1_weighted, _ = precision_recall_fscore_support(  # assign value to prec_weighted, rec_weighted, f1_weighted, _",
    "    y_true, y_pred, average=\"weighted\", zero_division=0                    # assign value to y_true, y_pred, average",
    ")",
    "# empty line",
    "                                                                           # per class metrics",
    "prec_class, rec_class, f1_class, support_class = precision_recall_fscore_support(  # assign value to prec_class, rec_class, f1_class, support_class",
    "    y_true, y_pred, average=None, zero_division=0                          # assign value to y_true, y_pred, average",
    ")",
    "# empty line",
    "print(\"Overall accuracy:\", oa)",
    "print(\"Cohen kappa:\", kappa)",
    "print(\"Macro precision:\", prec_macro)",
    "print(\"Macro recall:\", rec_macro)",
    "print(\"Macro f1:\", f1_macro)",
    "print(\"Weighted precision:\", prec_weighted)",
    "print(\"Weighted recall:\", rec_weighted)",
    "print(\"Weighted f1:\", f1_weighted)",
    "# empty line",
    "print(\"\\nPer class metrics\")",
    "for i, (p, r, f1, s) in enumerate(                                         # loop iteration",
    "    zip(prec_class, rec_class, f1_class, support_class), start=1           # assign value to zip(prec_class, rec_class, f1_class, support_class), start",
    "):",
    "    print(",
    "        f\"Class {i:02d}: \"",
    "        f\"precision={p:.4f}, recall={r:.4f}, f1={f1:.4f}, support={s}\"     # assign value to f\"precision",
    "    )",
    "# empty line",
    "print(\"\\nFull classification report\")",
    "print(",
    "    classification_report(",
    "        y_true,",
    "        y_pred,",
    "        target_names=[f\"class_{i}\" for i in range(1, num_classes + 1)],    # assign value to target_names",
    "        digits=4,                                                          # assign value to digits",
    "        zero_division=0,                                                   # assign value to zero_division",
    "    )",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5978f5c-73b7-432d-a896-4cb6769e53c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV set (8199, 200) labels (8199,) classes 16\n"
     ]
    }
   ],
   "source": [
    "X_tv = np.concatenate([ds_train.X, ds_val.X], axis=0).astype(np.float32)  # assign value to X_tv",
    "y_tv = np.concatenate([ds_train.y, ds_val.y], axis=0).astype(np.int64)    # assign value to y_tv",
    "C_tv = int(y_tv.max()) + 1                                                # assign value to C_tv",
    "print(\"TV set\", X_tv.shape, \"labels\", y_tv.shape, \"classes\", C_tv)",
    "assert y_tv.min() >= 0 and y_tv.max() < C_tv                              # assign value to assert y_tv.min() >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b747d7-6523-4f0d-8bd0-bec8da898273",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     84\u001b[39m X_tr, y_tr = X_tv[i_tr], y_tv[i_tr]\n\u001b[32m     85\u001b[39m X_va, y_va = X_tv[i_va], y_tv[i_va]\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m acc, f1, kap = \u001b[43mtrain_one_fold_lstm_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_drop\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbidir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  f1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  kappa \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkap\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m accs.append(acc); f1s.append(f1); kaps.append(kap)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mtrain_one_fold_lstm_cpu\u001b[39m\u001b[34m(X_tr, y_tr, X_va, y_va, hidden, layers, p_drop, bidir, mean_pool, epochs, patience)\u001b[39m\n\u001b[32m     39\u001b[39m     lg = model_f(xb.to(CV_DEVICE))\n\u001b[32m     40\u001b[39m     ls = crit(lg, yb.to(CV_DEVICE))\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43mls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     opt.step()\n\u001b[32m     43\u001b[39m sch.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold                        # import from sklearn.model_selection",
    "# empty line",
    "CV_DEVICE = torch.device(\"cpu\")                                            # set computation device (GPU/CPU)",
    "torch.backends.cudnn.enabled = False                                       # assign value to torch.backends.cudnn.enabled",
    "# empty line",
    "class LSTMFold(nn.Module):                                                 # define class LSTMFold",
    "    def __init__(self, input_size, hidden, layers, C, p_drop=0.3, bidir=True, mean_pool=False):  # assign value to def __init__(self, input_size, hidden, layers, C, p_drop",
    "        super().__init__()",
    "        self.mean_pool = mean_pool                                         # assign value to self.mean_pool",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden, num_layers=layers,  # assign value to self.lstm",
    "                            batch_first=True, bidirectional=bidir, dropout=p_drop if layers > 1 else 0.0)  # assign value to batch_first",
    "        d = hidden * (2 if bidir else 1)                                   # assign value to d",
    "        self.attn = nn.Sequential(nn.Linear(d, d), nn.Tanh(), nn.Linear(d, 1))  # assign value to self.attn",
    "        self.head = nn.Sequential(nn.Dropout(p_drop), nn.Linear(d, 256), nn.ReLU(inplace=True),  # assign value to self.head",
    "                                  nn.Dropout(p_drop), nn.Linear(256, C))",
    "    def forward(self, x):                                                  # define function forward",
    "        seq, _ = self.lstm(x)                                              # assign value to seq, _",
    "        if self.mean_pool:                                                 # conditional statement",
    "            z = seq.mean(1)                                                # assign value to z",
    "        else:                                                              # conditional statement",
    "            w = torch.softmax(self.attn(seq).squeeze(-1), dim=1)           # assign value to w",
    "            z = (seq * w.unsqueeze(-1)).sum(1)                             # assign value to z",
    "        return self.head(z)                                                # return value from function",
    "# empty line",
    "def train_one_fold_lstm_cpu(X_tr, y_tr, X_va, y_va, hidden=256, layers=2, p_drop=0.3, bidir=True, mean_pool=False, epochs=80, patience=10):  # assign value to def train_one_fold_lstm_cpu(X_tr, y_tr, X_va, y_va, hidden",
    "    model_f = LSTMFold(1, hidden, layers, C_tv, p_drop, bidir, mean_pool).to(CV_DEVICE)  # assign value to model_f",
    "    crit = nn.CrossEntropyLoss()                                           # assign value to crit",
    "    opt = optim.AdamW(model_f.parameters(), lr=1e-3, weight_decay=5e-5)    # assign value to opt",
    "    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=40)              # assign value to sch",
    "# empty line",
    "    dl_tr = DataLoader(TensorDataset(torch.from_numpy(X_tr).unsqueeze(2), torch.from_numpy(y_tr)), batch_size=256, shuffle=True)  # assign value to dl_tr",
    "    dl_va = DataLoader(TensorDataset(torch.from_numpy(X_va).unsqueeze(2), torch.from_numpy(y_va)), batch_size=256, shuffle=False)  # assign value to dl_va",
    "# empty line",
    "    best, best_state, bad = -1.0, None, 0                                  # assign value to best, best_state, bad",
    "    for ep in range(1, epochs + 1):                                        # loop iteration",
    "        model_f.train()",
    "        for xb, yb in dl_tr:                                               # loop iteration",
    "            opt.zero_grad(set_to_none=True)                                # assign value to opt.zero_grad(set_to_none",
    "            lg = model_f(xb.to(CV_DEVICE))                                 # assign value to lg",
    "            ls = crit(lg, yb.to(CV_DEVICE))                                # assign value to ls",
    "            ls.backward()",
    "            opt.step()",
    "        sch.step()",
    "# empty line",
    "        model_f.eval()",
    "        with torch.no_grad():",
    "            all_lg, all_y = [], []                                         # assign value to all_lg, all_y",
    "            for xb, yb in dl_va:                                           # loop iteration",
    "                all_lg.append(model_f(xb.to(CV_DEVICE)))",
    "                all_y.append(yb.to(CV_DEVICE))",
    "            lg = torch.cat(all_lg, 0)                                      # assign value to lg",
    "            tg = torch.cat(all_y, 0)                                       # assign value to tg",
    "            preds = lg.argmax(1).cpu().numpy()                             # assign value to preds",
    "            true = tg.cpu().numpy()                                        # assign value to true",
    "            f1 = precision_recall_fscore_support(true, preds, labels=np.arange(C_tv), average=\"macro\", zero_division=0)[2]  # assign value to f1",
    "        if f1 > best:                                                      # conditional statement",
    "            best = f1                                                      # assign value to best",
    "            best_state = {k: v.cpu().clone() for k, v in model_f.state_dict().items()}  # assign value to best_state",
    "            bad = 0                                                        # assign value to bad",
    "        else:                                                              # conditional statement",
    "            bad += 1                                                       # assign value to bad +",
    "            if bad >= patience:                                            # assign value to if bad >",
    "                break",
    "# empty line",
    "    model_f.load_state_dict(best_state)",
    "    model_f.eval()",
    "    with torch.no_grad():",
    "        all_lg, all_y = [], []                                             # assign value to all_lg, all_y",
    "        for xb, yb in dl_va:                                               # loop iteration",
    "            all_lg.append(model_f(xb.to(CV_DEVICE)))",
    "            all_y.append(yb.to(CV_DEVICE))",
    "        lg = torch.cat(all_lg, 0)                                          # assign value to lg",
    "        tg = torch.cat(all_y, 0)                                           # assign value to tg",
    "    preds = lg.argmax(1).cpu().numpy()                                     # assign value to preds",
    "    true = tg.cpu().numpy()                                                # assign value to true",
    "    acc = accuracy_score(true, preds)                                      # assign value to acc",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true, preds, labels=np.arange(C_tv), average=\"macro\", zero_division=0)  # assign value to prec, rec, f1, _",
    "    kap = cohen_kappa_score(true, preds)                                   # assign value to kap",
    "    return acc, f1, kap                                                    # return value from function",
    "# empty line",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)           # assign value to skf",
    "accs, f1s, kaps = [], [], []                                               # assign value to accs, f1s, kaps",
    "for fold, (i_tr, i_va) in enumerate(skf.split(X_tv, y_tv), 1):             # loop iteration",
    "    X_tr, y_tr = X_tv[i_tr], y_tv[i_tr]                                    # assign value to X_tr, y_tr",
    "    X_va, y_va = X_tv[i_va], y_tv[i_va]                                    # assign value to X_va, y_va",
    "    acc, f1, kap = train_one_fold_lstm_cpu(X_tr, y_tr, X_va, y_va, hidden=256, layers=2, p_drop=0.3, bidir=True, mean_pool=False)  # assign value to acc, f1, kap",
    "    print(f\"Fold {fold}  acc {acc:.4f}  f1 {f1:.4f}  kappa {kap:.4f}\")",
    "    accs.append(acc); f1s.append(f1); kaps.append(kap)",
    "# empty line",
    "print(\"\\nCV mean acc\", np.mean(accs).round(4), \"std\", np.std(accs).round(4))",
    "print(\"CV mean f1\", np.mean(f1s).round(4), \"std\", np.std(f1s).round(4))",
    "print(\"CV mean kappa\", np.mean(kaps).round(4), \"std\", np.std(kaps).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b1c73-e5b8-420c-b25b-6c98ef50d565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}